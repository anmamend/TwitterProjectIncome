{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I am going to read and transform the data made in the previous notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data_dir='Data/FinalData/'\n",
    "data=pd.read_csv('Data/Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n",
      "1200\n",
      "1201\n",
      "1202\n",
      "1203\n",
      "1204\n",
      "1205\n",
      "1206\n",
      "1207\n",
      "1208\n",
      "1209\n",
      "1210\n",
      "1211\n",
      "1212\n",
      "1213\n",
      "1214\n",
      "1215\n",
      "1216\n",
      "1217\n",
      "1218\n",
      "1219\n",
      "1220\n",
      "1221\n",
      "1222\n",
      "1223\n",
      "1224\n",
      "1225\n",
      "1226\n",
      "1227\n",
      "1228\n",
      "1229\n",
      "1230\n",
      "1231\n",
      "1232\n",
      "1233\n",
      "1234\n",
      "1235\n",
      "1236\n",
      "1237\n",
      "1238\n",
      "1239\n",
      "1240\n",
      "1241\n",
      "1242\n",
      "1243\n",
      "1244\n",
      "1245\n",
      "1246\n",
      "1247\n",
      "1248\n",
      "1249\n",
      "1250\n",
      "1251\n",
      "1252\n",
      "1253\n",
      "1254\n",
      "1255\n",
      "1256\n",
      "1257\n",
      "1258\n",
      "1259\n",
      "1260\n",
      "1261\n",
      "1262\n",
      "1263\n",
      "1264\n",
      "1265\n",
      "1266\n",
      "1267\n",
      "1268\n",
      "1269\n",
      "1270\n",
      "1271\n",
      "1272\n",
      "1273\n",
      "1274\n",
      "1275\n",
      "1276\n",
      "1277\n",
      "1278\n",
      "1279\n",
      "1280\n",
      "1281\n",
      "1282\n",
      "1283\n",
      "1284\n",
      "1285\n",
      "1286\n",
      "1287\n",
      "1288\n",
      "1289\n",
      "1290\n",
      "1291\n",
      "1292\n",
      "1293\n",
      "1294\n",
      "1295\n",
      "1296\n",
      "1297\n",
      "1298\n",
      "1299\n",
      "1300\n",
      "1301\n",
      "1302\n",
      "1303\n",
      "1304\n",
      "1305\n",
      "1306\n",
      "1307\n",
      "1308\n",
      "1309\n",
      "1310\n",
      "1311\n",
      "1312\n",
      "1313\n",
      "1314\n",
      "1315\n",
      "1316\n",
      "1317\n",
      "1318\n",
      "1319\n",
      "1320\n",
      "1321\n",
      "1322\n",
      "1323\n",
      "1324\n",
      "1325\n",
      "1326\n",
      "1327\n",
      "1328\n",
      "1329\n",
      "1330\n",
      "1331\n",
      "1332\n",
      "1333\n",
      "1334\n",
      "1335\n",
      "1336\n",
      "1337\n",
      "1338\n",
      "1339\n",
      "1340\n",
      "1341\n",
      "1342\n",
      "1343\n",
      "1344\n",
      "1345\n",
      "1346\n",
      "1347\n",
      "1348\n",
      "1349\n",
      "1350\n",
      "1351\n",
      "1352\n",
      "1353\n",
      "1354\n",
      "1355\n",
      "1356\n",
      "1357\n",
      "1358\n",
      "1359\n",
      "1360\n",
      "1361\n",
      "1362\n",
      "1363\n",
      "1364\n",
      "1365\n",
      "1366\n",
      "1367\n",
      "1368\n",
      "1369\n",
      "1370\n",
      "1371\n",
      "1372\n",
      "1373\n",
      "1374\n",
      "1375\n",
      "1376\n",
      "1377\n",
      "1378\n",
      "1379\n",
      "1380\n",
      "1381\n",
      "1382\n",
      "1383\n",
      "1384\n",
      "1385\n",
      "1386\n",
      "1387\n",
      "1388\n",
      "1389\n",
      "1390\n",
      "1391\n",
      "1392\n",
      "1393\n",
      "1394\n",
      "1395\n",
      "1396\n",
      "1397\n",
      "1398\n",
      "1399\n",
      "1400\n",
      "1401\n",
      "1402\n",
      "1403\n",
      "1404\n",
      "1405\n",
      "1406\n",
      "1407\n",
      "1408\n",
      "1409\n",
      "1410\n",
      "1411\n",
      "1412\n",
      "1413\n",
      "1414\n",
      "1415\n",
      "1416\n",
      "1417\n",
      "1418\n",
      "1419\n",
      "1420\n",
      "1421\n",
      "1422\n",
      "1423\n",
      "1424\n",
      "1425\n",
      "1426\n",
      "1427\n",
      "1428\n",
      "1429\n",
      "1430\n",
      "1431\n",
      "1432\n",
      "1433\n",
      "1434\n",
      "1435\n",
      "1436\n",
      "1437\n",
      "1438\n",
      "1439\n",
      "1440\n",
      "1441\n",
      "1442\n",
      "1443\n",
      "1444\n",
      "1445\n",
      "1446\n",
      "1447\n",
      "1448\n",
      "1449\n",
      "1450\n",
      "1451\n",
      "1452\n",
      "1453\n",
      "1454\n",
      "1455\n",
      "1456\n",
      "1457\n",
      "1458\n",
      "1459\n",
      "1460\n",
      "1461\n",
      "1462\n",
      "1463\n",
      "1464\n",
      "1465\n",
      "1466\n",
      "1467\n",
      "1468\n",
      "1469\n",
      "1470\n",
      "1471\n",
      "1472\n",
      "1473\n",
      "1474\n",
      "1475\n",
      "1476\n",
      "1477\n",
      "1478\n",
      "1479\n",
      "1480\n",
      "1481\n",
      "1482\n",
      "1483\n",
      "1484\n",
      "1485\n",
      "1486\n",
      "1487\n",
      "1488\n",
      "1489\n",
      "1490\n",
      "1491\n",
      "1492\n",
      "1493\n",
      "1494\n",
      "1495\n",
      "1496\n",
      "1497\n",
      "1498\n",
      "1499\n",
      "1500\n",
      "1501\n",
      "1502\n",
      "1503\n",
      "1504\n",
      "1505\n",
      "1506\n",
      "1507\n",
      "1508\n",
      "1509\n",
      "1510\n",
      "1511\n",
      "1512\n",
      "1513\n",
      "1514\n",
      "1515\n",
      "1516\n",
      "1517\n",
      "1518\n",
      "1519\n",
      "1520\n",
      "1521\n",
      "1522\n",
      "1523\n",
      "1524\n",
      "1525\n",
      "1526\n",
      "1527\n",
      "1528\n",
      "1529\n",
      "1530\n",
      "1531\n",
      "1532\n",
      "1533\n",
      "1534\n",
      "1535\n",
      "1536\n",
      "1537\n",
      "1538\n",
      "1539\n",
      "1540\n",
      "1541\n",
      "1542\n",
      "1543\n",
      "1544\n",
      "1545\n",
      "1546\n",
      "1547\n",
      "1548\n",
      "1549\n",
      "1550\n",
      "1551\n",
      "1552\n",
      "1553\n",
      "1554\n",
      "1555\n",
      "1556\n",
      "1557\n",
      "1558\n",
      "1559\n",
      "1560\n",
      "1561\n",
      "1562\n",
      "1563\n",
      "1564\n",
      "1565\n",
      "1566\n",
      "1567\n",
      "1568\n",
      "1569\n",
      "1570\n",
      "1571\n",
      "1572\n",
      "1573\n",
      "1574\n",
      "1575\n",
      "1576\n",
      "1577\n",
      "1578\n",
      "1579\n",
      "1580\n",
      "1581\n",
      "1582\n",
      "1583\n",
      "1584\n",
      "1585\n",
      "1586\n",
      "1587\n",
      "1588\n",
      "1589\n",
      "1590\n",
      "1591\n",
      "1592\n",
      "1593\n",
      "1594\n",
      "1595\n",
      "1596\n",
      "1597\n",
      "1598\n",
      "1599\n",
      "1600\n",
      "1601\n",
      "1602\n",
      "1603\n",
      "1604\n",
      "1605\n",
      "1606\n",
      "1607\n",
      "1608\n",
      "1609\n",
      "1610\n",
      "1611\n",
      "1612\n",
      "1613\n",
      "1614\n",
      "1615\n",
      "1616\n",
      "1617\n",
      "1618\n",
      "1619\n",
      "1620\n",
      "1621\n",
      "1622\n",
      "1623\n",
      "1624\n",
      "1625\n",
      "1626\n",
      "1627\n",
      "1628\n",
      "1629\n",
      "1630\n",
      "1631\n",
      "1632\n",
      "1633\n",
      "1634\n",
      "1635\n",
      "1636\n",
      "1637\n",
      "1638\n",
      "1639\n",
      "1640\n",
      "1641\n",
      "1642\n",
      "1643\n",
      "1644\n",
      "1645\n",
      "1646\n",
      "1647\n",
      "1648\n",
      "1649\n",
      "1650\n",
      "1651\n",
      "1652\n",
      "1653\n",
      "1654\n",
      "1655\n",
      "1656\n",
      "1657\n",
      "1658\n",
      "1659\n",
      "1660\n",
      "1661\n",
      "1662\n",
      "1663\n",
      "1664\n",
      "1665\n",
      "1666\n",
      "1667\n",
      "1668\n",
      "1669\n",
      "1670\n",
      "1671\n",
      "1672\n",
      "1673\n",
      "1674\n",
      "1675\n",
      "1676\n",
      "1677\n",
      "1678\n",
      "1679\n",
      "1680\n",
      "1681\n",
      "1682\n",
      "1683\n",
      "1684\n",
      "1685\n",
      "1686\n",
      "1687\n",
      "1688\n",
      "1689\n",
      "1690\n",
      "1691\n",
      "1692\n",
      "1693\n",
      "1694\n",
      "1695\n",
      "1696\n",
      "1697\n",
      "1698\n",
      "1699\n",
      "1700\n",
      "1701\n",
      "1702\n",
      "1703\n",
      "1704\n",
      "1705\n",
      "1706\n",
      "1707\n",
      "1708\n",
      "1709\n",
      "1710\n",
      "1711\n",
      "1712\n",
      "1713\n",
      "1714\n",
      "1715\n",
      "1716\n",
      "1717\n",
      "1718\n",
      "1719\n",
      "1720\n",
      "1721\n",
      "1722\n",
      "1723\n",
      "1724\n",
      "1725\n",
      "1726\n",
      "1727\n",
      "1728\n",
      "1729\n",
      "1730\n",
      "1731\n",
      "1732\n",
      "1733\n",
      "1734\n",
      "1735\n",
      "1736\n",
      "1737\n",
      "1738\n",
      "1739\n",
      "1740\n",
      "1741\n",
      "1742\n",
      "1743\n",
      "1744\n",
      "1745\n",
      "1746\n",
      "1747\n",
      "1748\n",
      "1749\n",
      "1750\n",
      "1751\n",
      "1752\n",
      "1753\n",
      "1754\n",
      "1755\n",
      "1756\n",
      "1757\n",
      "1758\n",
      "1759\n",
      "1760\n",
      "1761\n",
      "1762\n",
      "1763\n",
      "1764\n",
      "1765\n",
      "1766\n",
      "1767\n",
      "1768\n",
      "1769\n",
      "1770\n",
      "1771\n",
      "1772\n",
      "1773\n",
      "1774\n",
      "1775\n",
      "1776\n",
      "1777\n",
      "1778\n",
      "1779\n",
      "1780\n",
      "1781\n",
      "1782\n",
      "1783\n",
      "1784\n",
      "1785\n",
      "1786\n",
      "1787\n",
      "1788\n",
      "1789\n",
      "1790\n",
      "1791\n",
      "1792\n",
      "1793\n",
      "1794\n",
      "1795\n",
      "1796\n",
      "1797\n",
      "1798\n",
      "1799\n",
      "1800\n",
      "1801\n",
      "1802\n",
      "1803\n",
      "1804\n",
      "1805\n",
      "1806\n",
      "1807\n",
      "1808\n",
      "1809\n",
      "1810\n",
      "1811\n",
      "1812\n",
      "1813\n",
      "1814\n",
      "1815\n",
      "1816\n",
      "1817\n",
      "1818\n",
      "1819\n",
      "1820\n",
      "1821\n",
      "1822\n",
      "1823\n",
      "1824\n",
      "1825\n",
      "1826\n",
      "1827\n",
      "1828\n",
      "1829\n",
      "1830\n",
      "1831\n",
      "1832\n",
      "1833\n",
      "1834\n",
      "1835\n",
      "1836\n",
      "1837\n",
      "1838\n",
      "1839\n",
      "1840\n",
      "1841\n",
      "1842\n",
      "1843\n",
      "1844\n",
      "1845\n",
      "1846\n",
      "1847\n",
      "1848\n",
      "1849\n",
      "1850\n",
      "1851\n",
      "1852\n",
      "1853\n",
      "1854\n",
      "1855\n",
      "1856\n",
      "1857\n",
      "1858\n",
      "1859\n",
      "1860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1861\n",
      "1862\n",
      "1863\n",
      "1864\n",
      "1865\n",
      "1866\n",
      "1867\n",
      "1868\n",
      "1869\n",
      "1870\n",
      "1871\n",
      "1872\n",
      "1873\n",
      "1874\n",
      "1875\n",
      "1876\n",
      "1877\n",
      "1878\n",
      "1879\n",
      "1880\n",
      "1881\n",
      "1882\n",
      "1883\n",
      "1884\n",
      "1885\n",
      "1886\n",
      "1887\n",
      "1888\n",
      "1889\n",
      "1890\n",
      "1891\n",
      "1892\n",
      "1893\n",
      "1894\n",
      "1895\n",
      "1896\n",
      "1897\n",
      "1898\n",
      "1899\n",
      "1900\n",
      "1901\n",
      "1902\n",
      "1903\n",
      "1904\n",
      "1905\n",
      "1906\n",
      "1907\n",
      "1908\n",
      "1909\n",
      "1910\n",
      "1911\n",
      "1912\n",
      "1913\n",
      "1914\n",
      "1915\n",
      "1916\n",
      "1917\n",
      "1918\n",
      "1919\n",
      "1920\n",
      "1921\n",
      "1922\n",
      "1923\n",
      "1924\n",
      "1925\n",
      "1926\n",
      "1927\n",
      "1928\n",
      "1929\n",
      "1930\n",
      "1931\n",
      "1932\n",
      "1933\n",
      "1934\n",
      "1935\n",
      "1936\n",
      "1937\n",
      "1938\n",
      "1939\n",
      "1940\n",
      "1941\n",
      "1942\n",
      "1943\n",
      "1944\n",
      "1945\n",
      "1946\n",
      "1947\n",
      "1948\n",
      "1949\n",
      "1950\n",
      "1951\n",
      "1952\n",
      "1953\n",
      "1954\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n",
      "2032\n",
      "2033\n",
      "2034\n",
      "2035\n",
      "2036\n",
      "2037\n",
      "2038\n",
      "2039\n",
      "2040\n",
      "2041\n",
      "2042\n",
      "2043\n",
      "2044\n",
      "2045\n",
      "2046\n",
      "2047\n",
      "2048\n",
      "2049\n",
      "2050\n",
      "2051\n",
      "2052\n",
      "2053\n",
      "2054\n",
      "2055\n",
      "2056\n",
      "2057\n",
      "2058\n",
      "2059\n",
      "2060\n",
      "2061\n",
      "2062\n",
      "2063\n",
      "2064\n",
      "2065\n",
      "2066\n",
      "2067\n",
      "2068\n",
      "2069\n",
      "2070\n",
      "2071\n",
      "2072\n",
      "2073\n",
      "2074\n",
      "2075\n",
      "2076\n",
      "2077\n",
      "2078\n",
      "2079\n",
      "2080\n",
      "2081\n",
      "2082\n",
      "2083\n",
      "2084\n",
      "2085\n",
      "2086\n",
      "2087\n",
      "2088\n",
      "2089\n",
      "2090\n",
      "2091\n",
      "2092\n",
      "2093\n",
      "2094\n",
      "2095\n",
      "2096\n",
      "2097\n",
      "2098\n",
      "2099\n",
      "2100\n",
      "2101\n",
      "2102\n",
      "2103\n",
      "2104\n",
      "2105\n",
      "2106\n",
      "2107\n",
      "2108\n",
      "2109\n",
      "2110\n",
      "2111\n",
      "2112\n",
      "2113\n",
      "2114\n",
      "2115\n",
      "2116\n",
      "2117\n",
      "2118\n",
      "2119\n",
      "2120\n",
      "2121\n",
      "2122\n",
      "2123\n",
      "2124\n",
      "2125\n",
      "2126\n",
      "2127\n",
      "2128\n",
      "2129\n",
      "2130\n",
      "2131\n",
      "2132\n",
      "2133\n",
      "2134\n",
      "2135\n",
      "2136\n",
      "2137\n",
      "2138\n",
      "2139\n",
      "2140\n",
      "2141\n",
      "2142\n",
      "2143\n",
      "2144\n",
      "2145\n",
      "2146\n",
      "2147\n",
      "2148\n",
      "2149\n",
      "2150\n",
      "2151\n",
      "2152\n",
      "2153\n",
      "2154\n",
      "2155\n",
      "2156\n",
      "2157\n",
      "2158\n",
      "2159\n",
      "2160\n",
      "2161\n",
      "2162\n",
      "2163\n",
      "2164\n",
      "2165\n",
      "2166\n",
      "2167\n",
      "2168\n",
      "2169\n",
      "2170\n",
      "2171\n",
      "2172\n",
      "2173\n",
      "2174\n",
      "2175\n",
      "2176\n",
      "2177\n",
      "2178\n",
      "2179\n",
      "2180\n",
      "2181\n",
      "2182\n",
      "2183\n",
      "2184\n",
      "2185\n",
      "2186\n",
      "2187\n",
      "2188\n",
      "2189\n",
      "2190\n",
      "2191\n",
      "2192\n",
      "2193\n",
      "2194\n",
      "2195\n",
      "2196\n",
      "2197\n",
      "2198\n",
      "2199\n",
      "2200\n",
      "2201\n",
      "2202\n",
      "2203\n",
      "2204\n",
      "2205\n",
      "2206\n",
      "2207\n",
      "2208\n",
      "2209\n",
      "2210\n",
      "2211\n",
      "2212\n",
      "2213\n",
      "2214\n",
      "2215\n",
      "2216\n",
      "2217\n",
      "2218\n",
      "2219\n",
      "2220\n",
      "2221\n",
      "2222\n",
      "2223\n",
      "2224\n",
      "2225\n",
      "2226\n",
      "2227\n",
      "2228\n",
      "2229\n",
      "2230\n",
      "2231\n",
      "2232\n",
      "2233\n",
      "2234\n",
      "2235\n",
      "2236\n",
      "2237\n",
      "2238\n",
      "2239\n",
      "2240\n",
      "2241\n",
      "2242\n",
      "2243\n",
      "2244\n",
      "2245\n",
      "2246\n",
      "2247\n",
      "2248\n",
      "2249\n",
      "2250\n",
      "2251\n",
      "2252\n",
      "2253\n",
      "2254\n",
      "2255\n",
      "2256\n",
      "2257\n",
      "2258\n",
      "2259\n",
      "2260\n",
      "2261\n",
      "2262\n",
      "2263\n",
      "2264\n",
      "2265\n",
      "2266\n",
      "2267\n",
      "2268\n",
      "2269\n",
      "2270\n",
      "2271\n",
      "2272\n",
      "2273\n",
      "2274\n",
      "2275\n",
      "2276\n",
      "2277\n",
      "2278\n",
      "2279\n",
      "2280\n",
      "2281\n",
      "2282\n",
      "2283\n",
      "2284\n",
      "2285\n",
      "2286\n",
      "2287\n",
      "2288\n",
      "2289\n",
      "2290\n",
      "2291\n",
      "2292\n",
      "2293\n",
      "2294\n",
      "2295\n",
      "2296\n",
      "2297\n",
      "2298\n",
      "2299\n",
      "2300\n",
      "2301\n",
      "2302\n",
      "2303\n",
      "2304\n",
      "2305\n",
      "2306\n",
      "2307\n",
      "2308\n",
      "2309\n",
      "2310\n",
      "2311\n",
      "2312\n",
      "2313\n",
      "2314\n",
      "2315\n",
      "2316\n",
      "2317\n",
      "2318\n",
      "2319\n",
      "2320\n",
      "2321\n",
      "2322\n",
      "2323\n",
      "2324\n",
      "2325\n",
      "2326\n",
      "2327\n",
      "2328\n",
      "2329\n",
      "2330\n",
      "2331\n",
      "2332\n",
      "2333\n",
      "2334\n",
      "2335\n",
      "2336\n",
      "2337\n",
      "2338\n",
      "2339\n",
      "2340\n",
      "2341\n",
      "2342\n",
      "2343\n",
      "2344\n",
      "2345\n",
      "2346\n",
      "2347\n",
      "2348\n",
      "2349\n",
      "2350\n",
      "2351\n",
      "2352\n",
      "2353\n",
      "2354\n",
      "2355\n",
      "2356\n",
      "2357\n",
      "2358\n",
      "2359\n",
      "2360\n",
      "2361\n",
      "2362\n",
      "2363\n",
      "2364\n",
      "2365\n",
      "2366\n",
      "2367\n",
      "2368\n",
      "2369\n",
      "2370\n",
      "2371\n",
      "2372\n",
      "2373\n",
      "2374\n",
      "2375\n",
      "2376\n",
      "2377\n",
      "2378\n",
      "2379\n",
      "2380\n",
      "2381\n",
      "2382\n",
      "2383\n",
      "2384\n",
      "2385\n",
      "2386\n",
      "2387\n",
      "2388\n",
      "2389\n",
      "2390\n",
      "2391\n",
      "2392\n",
      "2393\n",
      "2394\n",
      "2395\n",
      "2396\n",
      "2397\n",
      "2398\n",
      "2399\n",
      "2400\n",
      "2401\n",
      "2402\n",
      "2403\n",
      "2404\n",
      "2405\n",
      "2406\n",
      "2407\n",
      "2408\n",
      "2409\n",
      "2410\n",
      "2411\n",
      "2412\n",
      "2413\n",
      "2414\n",
      "2415\n",
      "2416\n",
      "2417\n",
      "2418\n",
      "2419\n",
      "2420\n",
      "2421\n",
      "2422\n",
      "2423\n",
      "2424\n",
      "2425\n",
      "2426\n",
      "2427\n",
      "2428\n",
      "2429\n",
      "2430\n",
      "2431\n",
      "2432\n",
      "2433\n",
      "2434\n",
      "2435\n",
      "2436\n",
      "2437\n",
      "2438\n",
      "2439\n",
      "2440\n",
      "2441\n",
      "2442\n",
      "2443\n",
      "2444\n",
      "2445\n",
      "2446\n",
      "2447\n",
      "2448\n",
      "2449\n",
      "2450\n",
      "2451\n",
      "2452\n",
      "2453\n",
      "2454\n",
      "2455\n",
      "2456\n",
      "2457\n",
      "2458\n",
      "2459\n",
      "2460\n",
      "2461\n",
      "2462\n",
      "2463\n",
      "2464\n",
      "2465\n",
      "2466\n",
      "2467\n",
      "2468\n",
      "2469\n",
      "2470\n",
      "2471\n",
      "2472\n",
      "2473\n",
      "2474\n",
      "2475\n",
      "2476\n",
      "2477\n",
      "2478\n",
      "2479\n",
      "2480\n",
      "2481\n",
      "2482\n",
      "2483\n",
      "2484\n",
      "2485\n",
      "2486\n",
      "2487\n",
      "2488\n",
      "2489\n",
      "2490\n",
      "2491\n",
      "2492\n",
      "2493\n",
      "2494\n",
      "2495\n",
      "2496\n",
      "2497\n",
      "2498\n",
      "2499\n",
      "2500\n",
      "2501\n",
      "2502\n",
      "2503\n",
      "2504\n",
      "2505\n",
      "2506\n",
      "2507\n",
      "2508\n",
      "2509\n",
      "2510\n",
      "2511\n",
      "2512\n",
      "2513\n",
      "2514\n",
      "2515\n",
      "2516\n",
      "2517\n",
      "2518\n",
      "2519\n",
      "2520\n",
      "2521\n",
      "2522\n",
      "2523\n",
      "2524\n",
      "2525\n",
      "2526\n",
      "2527\n",
      "2528\n",
      "2529\n",
      "2530\n",
      "2531\n",
      "2532\n",
      "2533\n",
      "2534\n",
      "2535\n",
      "2536\n",
      "2537\n",
      "2538\n",
      "2539\n",
      "2540\n",
      "2541\n",
      "2542\n",
      "2543\n",
      "2544\n",
      "2545\n",
      "2546\n",
      "2547\n",
      "2548\n",
      "2549\n",
      "2550\n",
      "2551\n",
      "2552\n",
      "2553\n",
      "2554\n",
      "2555\n",
      "2556\n",
      "2557\n",
      "2558\n",
      "2559\n",
      "2560\n",
      "2561\n",
      "2562\n",
      "2563\n",
      "2564\n",
      "2565\n",
      "2566\n",
      "2567\n",
      "2568\n",
      "2569\n",
      "2570\n",
      "2571\n",
      "2572\n",
      "2573\n",
      "2574\n",
      "2575\n",
      "2576\n",
      "2577\n",
      "2578\n",
      "2579\n",
      "2580\n",
      "2581\n",
      "2582\n",
      "2583\n",
      "2584\n",
      "2585\n",
      "2586\n",
      "2587\n",
      "2588\n",
      "2589\n",
      "2590\n",
      "2591\n",
      "2592\n",
      "2593\n",
      "2594\n",
      "2595\n",
      "2596\n",
      "2597\n",
      "2598\n",
      "2599\n",
      "2600\n",
      "2601\n",
      "2602\n",
      "2603\n",
      "2604\n",
      "2605\n",
      "2606\n",
      "2607\n",
      "2608\n",
      "2609\n",
      "2610\n",
      "2611\n",
      "2612\n",
      "2613\n",
      "2614\n",
      "2615\n",
      "2616\n",
      "2617\n",
      "2618\n",
      "2619\n",
      "2620\n",
      "2621\n",
      "2622\n",
      "2623\n",
      "2624\n",
      "2625\n",
      "2626\n",
      "2627\n",
      "2628\n",
      "2629\n",
      "2630\n",
      "2631\n",
      "2632\n",
      "2633\n",
      "2634\n",
      "2635\n",
      "2636\n",
      "2637\n",
      "2638\n",
      "2639\n",
      "2640\n",
      "2641\n",
      "2642\n",
      "2643\n",
      "2644\n",
      "2645\n",
      "2646\n",
      "2647\n",
      "2648\n",
      "2649\n",
      "2650\n",
      "2651\n",
      "2652\n",
      "2653\n",
      "2654\n",
      "2655\n",
      "2656\n",
      "2657\n",
      "2658\n",
      "2659\n",
      "2660\n",
      "2661\n",
      "2662\n",
      "2663\n",
      "2664\n",
      "2665\n",
      "2666\n",
      "2667\n",
      "2668\n",
      "2669\n",
      "2670\n",
      "2671\n",
      "2672\n",
      "2673\n",
      "2674\n",
      "2675\n",
      "2676\n",
      "2677\n",
      "2678\n",
      "2679\n",
      "2680\n",
      "2681\n",
      "2682\n",
      "2683\n",
      "2684\n",
      "2685\n",
      "2686\n",
      "2687\n",
      "2688\n",
      "2689\n",
      "2690\n",
      "2691\n",
      "2692\n",
      "2693\n",
      "2694\n",
      "2695\n",
      "2696\n",
      "2697\n",
      "2698\n",
      "2699\n",
      "2700\n",
      "2701\n",
      "2702\n",
      "2703\n",
      "2704\n",
      "2705\n",
      "2706\n",
      "2707\n",
      "2708\n",
      "2709\n",
      "2710\n",
      "2711\n",
      "2712\n",
      "2713\n",
      "2714\n",
      "2715\n",
      "2716\n",
      "2717\n",
      "2718\n",
      "2719\n",
      "2720\n",
      "2721\n",
      "2722\n",
      "2723\n",
      "2724\n",
      "2725\n",
      "2726\n",
      "2727\n",
      "2728\n",
      "2729\n",
      "2730\n",
      "2731\n",
      "2732\n",
      "2733\n",
      "2734\n",
      "2735\n",
      "2736\n",
      "2737\n",
      "2738\n",
      "2739\n",
      "2740\n",
      "2741\n",
      "2742\n",
      "2743\n",
      "2744\n",
      "2745\n",
      "2746\n",
      "2747\n",
      "2748\n",
      "2749\n",
      "2750\n",
      "2751\n",
      "2752\n",
      "2753\n",
      "2754\n",
      "2755\n",
      "2756\n",
      "2757\n",
      "2758\n",
      "2759\n",
      "2760\n",
      "2761\n",
      "2762\n",
      "2763\n",
      "2764\n",
      "2765\n",
      "2766\n",
      "2767\n",
      "2768\n",
      "2769\n",
      "2770\n",
      "2771\n",
      "2772\n",
      "2773\n",
      "2774\n",
      "2775\n",
      "2776\n",
      "2777\n",
      "2778\n",
      "2779\n",
      "2780\n",
      "2781\n",
      "2782\n",
      "2783\n",
      "2784\n",
      "2785\n",
      "2786\n",
      "2787\n",
      "2788\n",
      "2789\n",
      "2790\n",
      "2791\n",
      "2792\n",
      "2793\n",
      "2794\n",
      "2795\n",
      "2796\n",
      "2797\n",
      "2798\n",
      "2799\n",
      "2800\n",
      "2801\n",
      "2802\n",
      "2803\n",
      "2804\n",
      "2805\n",
      "2806\n",
      "2807\n",
      "2808\n",
      "2809\n",
      "2810\n",
      "2811\n",
      "2812\n",
      "2813\n",
      "2814\n",
      "2815\n",
      "2816\n",
      "2817\n",
      "2818\n",
      "2819\n",
      "2820\n",
      "2821\n",
      "2822\n",
      "2823\n",
      "2824\n",
      "2825\n",
      "2826\n",
      "2827\n",
      "2828\n",
      "2829\n",
      "2830\n",
      "2831\n",
      "2832\n",
      "2833\n",
      "2834\n",
      "2835\n",
      "2836\n",
      "2837\n",
      "2838\n",
      "2839\n",
      "2840\n",
      "2841\n",
      "2842\n",
      "2843\n",
      "2844\n",
      "2845\n",
      "2846\n",
      "2847\n",
      "2848\n",
      "2849\n",
      "2850\n",
      "2851\n",
      "2852\n",
      "2853\n",
      "2854\n",
      "2855\n",
      "2856\n",
      "2857\n",
      "2858\n",
      "2859\n",
      "2860\n",
      "2861\n",
      "2862\n",
      "2863\n",
      "2864\n",
      "2865\n",
      "2866\n",
      "2867\n",
      "2868\n",
      "2869\n",
      "2870\n",
      "2871\n",
      "2872\n",
      "2873\n",
      "2874\n",
      "2875\n",
      "2876\n",
      "2877\n",
      "2878\n",
      "2879\n",
      "2880\n",
      "2881\n",
      "2882\n",
      "2883\n",
      "2884\n",
      "2885\n",
      "2886\n",
      "2887\n",
      "2888\n",
      "2889\n",
      "2890\n",
      "2891\n",
      "2892\n",
      "2893\n",
      "2894\n",
      "2895\n",
      "2896\n",
      "2897\n",
      "2898\n",
      "2899\n",
      "2900\n",
      "2901\n",
      "2902\n",
      "2903\n",
      "2904\n",
      "2905\n",
      "2906\n",
      "2907\n",
      "2908\n",
      "2909\n",
      "2910\n",
      "2911\n",
      "2912\n",
      "2913\n",
      "2914\n",
      "2915\n",
      "2916\n",
      "2917\n",
      "2918\n",
      "2919\n",
      "2920\n",
      "2921\n",
      "2922\n",
      "2923\n",
      "2924\n",
      "2925\n",
      "2926\n",
      "2927\n",
      "2928\n",
      "2929\n",
      "2930\n",
      "2931\n",
      "2932\n",
      "2933\n",
      "2934\n",
      "2935\n",
      "2936\n",
      "2937\n",
      "2938\n",
      "2939\n",
      "2940\n",
      "2941\n",
      "2942\n",
      "2943\n",
      "2944\n",
      "2945\n",
      "2946\n",
      "2947\n",
      "2948\n",
      "2949\n",
      "2950\n",
      "2951\n",
      "2952\n",
      "2953\n",
      "2954\n",
      "2955\n",
      "2956\n",
      "2957\n",
      "2958\n",
      "2959\n",
      "2960\n",
      "2961\n",
      "2962\n",
      "2963\n",
      "2964\n",
      "2965\n",
      "2966\n",
      "2967\n",
      "2968\n",
      "2969\n",
      "2970\n",
      "2971\n",
      "2972\n",
      "2973\n",
      "2974\n",
      "2975\n",
      "2976\n",
      "2977\n",
      "2978\n",
      "2979\n",
      "2980\n",
      "2981\n",
      "2982\n",
      "2983\n",
      "2984\n",
      "2985\n",
      "2986\n",
      "2987\n",
      "2988\n",
      "2989\n",
      "2990\n",
      "2991\n",
      "2992\n",
      "2993\n",
      "2994\n",
      "2995\n",
      "2996\n",
      "2997\n",
      "2998\n",
      "2999\n",
      "3000\n",
      "3001\n",
      "3002\n",
      "3003\n",
      "3004\n",
      "3005\n",
      "3006\n",
      "3007\n",
      "3008\n",
      "3009\n",
      "3010\n",
      "3011\n",
      "3012\n",
      "3013\n",
      "3014\n",
      "3015\n",
      "3016\n",
      "3017\n",
      "3018\n",
      "3019\n",
      "3020\n",
      "3021\n",
      "3022\n",
      "3023\n",
      "3024\n",
      "3025\n",
      "3026\n",
      "3027\n",
      "3028\n",
      "3029\n",
      "3030\n",
      "3031\n",
      "3032\n",
      "3033\n",
      "3034\n",
      "3035\n",
      "3036\n",
      "3037\n",
      "3038\n",
      "3039\n",
      "3040\n",
      "3041\n",
      "3042\n",
      "3043\n",
      "3044\n",
      "3045\n",
      "3046\n",
      "3047\n",
      "3048\n",
      "3049\n",
      "3050\n",
      "3051\n",
      "3052\n",
      "3053\n",
      "3054\n",
      "3055\n",
      "3056\n",
      "3057\n",
      "3058\n",
      "3059\n",
      "3060\n",
      "3061\n",
      "3062\n",
      "3063\n",
      "3064\n",
      "3065\n",
      "3066\n",
      "3067\n",
      "3068\n",
      "3069\n",
      "3070\n",
      "3071\n",
      "3072\n",
      "3073\n",
      "3074\n",
      "3075\n",
      "3076\n",
      "3077\n",
      "3078\n",
      "3079\n",
      "3080\n",
      "3081\n",
      "3082\n",
      "3083\n",
      "3084\n",
      "3085\n",
      "3086\n",
      "3087\n",
      "3088\n",
      "3089\n",
      "3090\n",
      "3091\n",
      "3092\n",
      "3093\n",
      "3094\n",
      "3095\n",
      "3096\n",
      "3097\n",
      "3098\n",
      "3099\n",
      "3100\n",
      "3101\n",
      "3102\n",
      "3103\n",
      "3104\n",
      "3105\n",
      "3106\n",
      "3107\n",
      "3108\n",
      "3109\n",
      "3110\n",
      "3111\n",
      "3112\n",
      "3113\n",
      "3114\n",
      "3115\n",
      "3116\n",
      "3117\n",
      "3118\n",
      "3119\n",
      "3120\n",
      "3121\n",
      "3122\n",
      "3123\n",
      "3124\n",
      "3125\n",
      "3126\n",
      "3127\n",
      "3128\n",
      "3129\n",
      "3130\n",
      "3131\n",
      "3132\n",
      "3133\n",
      "3134\n",
      "3135\n",
      "3136\n",
      "3137\n",
      "3138\n",
      "3139\n",
      "3140\n",
      "3141\n",
      "3142\n",
      "3143\n",
      "3144\n",
      "3145\n",
      "3146\n",
      "3147\n",
      "3148\n",
      "3149\n",
      "3150\n",
      "3151\n",
      "3152\n",
      "3153\n",
      "3154\n",
      "3155\n",
      "3156\n",
      "3157\n",
      "3158\n",
      "3159\n",
      "3160\n",
      "3161\n",
      "3162\n",
      "3163\n",
      "3164\n",
      "3165\n",
      "3166\n",
      "3167\n",
      "3168\n",
      "3169\n",
      "3170\n",
      "3171\n",
      "3172\n",
      "3173\n",
      "3174\n",
      "3175\n",
      "3176\n",
      "3177\n",
      "3178\n",
      "3179\n",
      "3180\n",
      "3181\n",
      "3182\n",
      "3183\n",
      "3184\n",
      "3185\n",
      "3186\n",
      "3187\n",
      "3188\n",
      "3189\n",
      "3190\n",
      "3191\n",
      "3192\n",
      "3193\n",
      "3194\n",
      "3195\n",
      "3196\n",
      "3197\n",
      "3198\n",
      "3199\n",
      "3200\n",
      "3201\n",
      "3202\n",
      "3203\n",
      "3204\n",
      "3205\n",
      "3206\n",
      "3207\n",
      "3208\n",
      "3209\n",
      "3210\n",
      "3211\n",
      "3212\n",
      "3213\n",
      "3214\n",
      "3215\n",
      "3216\n",
      "3217\n",
      "3218\n",
      "3219\n",
      "3220\n",
      "3221\n",
      "3222\n",
      "3223\n",
      "3224\n",
      "3225\n",
      "3226\n",
      "3227\n",
      "3228\n",
      "3229\n",
      "3230\n",
      "3231\n",
      "3232\n",
      "3233\n",
      "3234\n",
      "3235\n",
      "3236\n",
      "3237\n",
      "3238\n",
      "3239\n",
      "3240\n",
      "3241\n",
      "3242\n",
      "3243\n",
      "3244\n",
      "3245\n",
      "3246\n",
      "3247\n",
      "3248\n",
      "3249\n",
      "3250\n",
      "3251\n",
      "3252\n",
      "3253\n",
      "3254\n",
      "3255\n",
      "3256\n",
      "3257\n",
      "3258\n",
      "3259\n",
      "3260\n",
      "3261\n",
      "3262\n",
      "3263\n",
      "3264\n",
      "3265\n",
      "3266\n",
      "3267\n",
      "3268\n",
      "3269\n",
      "3270\n",
      "3271\n",
      "3272\n",
      "3273\n",
      "3274\n",
      "3275\n",
      "3276\n",
      "3277\n",
      "3278\n",
      "3279\n",
      "3280\n",
      "3281\n",
      "3282\n",
      "3283\n",
      "3284\n",
      "3285\n",
      "3286\n",
      "3287\n",
      "3288\n",
      "3289\n",
      "3290\n",
      "3291\n",
      "3292\n",
      "3293\n",
      "3294\n",
      "3295\n",
      "3296\n",
      "3297\n",
      "3298\n",
      "3299\n",
      "3300\n",
      "3301\n",
      "3302\n",
      "3303\n",
      "3304\n",
      "3305\n",
      "3306\n",
      "3307\n",
      "3308\n",
      "3309\n",
      "3310\n",
      "3311\n",
      "3312\n",
      "3313\n",
      "3314\n",
      "3315\n",
      "3316\n",
      "3317\n",
      "3318\n",
      "3319\n",
      "3320\n",
      "3321\n",
      "3322\n",
      "3323\n",
      "3324\n",
      "3325\n",
      "3326\n",
      "3327\n",
      "3328\n",
      "3329\n",
      "3330\n",
      "3331\n",
      "3332\n",
      "3333\n",
      "3334\n",
      "3335\n",
      "3336\n",
      "3337\n",
      "3338\n",
      "3339\n",
      "3340\n",
      "3341\n",
      "3342\n",
      "3343\n",
      "3344\n",
      "3345\n",
      "3346\n",
      "3347\n",
      "3348\n",
      "3349\n",
      "3350\n",
      "3351\n",
      "3352\n",
      "3353\n",
      "3354\n",
      "3355\n",
      "3356\n",
      "3357\n",
      "3358\n",
      "3359\n",
      "3360\n",
      "3361\n",
      "3362\n",
      "3363\n",
      "3364\n",
      "3365\n",
      "3366\n",
      "3367\n",
      "3368\n",
      "3369\n",
      "3370\n",
      "3371\n",
      "3372\n",
      "3373\n",
      "3374\n",
      "3375\n",
      "3376\n",
      "3377\n",
      "3378\n",
      "3379\n",
      "3380\n",
      "3381\n",
      "3382\n",
      "3383\n",
      "3384\n",
      "3385\n",
      "3386\n",
      "3387\n",
      "3388\n",
      "3389\n",
      "3390\n",
      "3391\n",
      "3392\n",
      "3393\n",
      "3394\n",
      "3395\n",
      "3396\n",
      "3397\n",
      "3398\n",
      "3399\n",
      "3400\n",
      "3401\n",
      "3402\n",
      "3403\n",
      "3404\n",
      "3405\n",
      "3406\n",
      "3407\n",
      "3408\n",
      "3409\n",
      "3410\n",
      "3411\n",
      "3412\n",
      "3413\n",
      "3414\n",
      "3415\n",
      "3416\n",
      "3417\n",
      "3418\n",
      "3419\n",
      "3420\n",
      "3421\n",
      "3422\n",
      "3423\n",
      "3424\n",
      "3425\n",
      "3426\n",
      "3427\n",
      "3428\n",
      "3429\n",
      "3430\n",
      "3431\n",
      "3432\n",
      "3433\n",
      "3434\n",
      "3435\n",
      "3436\n",
      "3437\n",
      "3438\n",
      "3439\n",
      "3440\n",
      "3441\n",
      "3442\n",
      "3443\n",
      "3444\n",
      "3445\n",
      "3446\n",
      "3447\n",
      "3448\n",
      "3449\n",
      "3450\n",
      "3451\n",
      "3452\n",
      "3453\n",
      "3454\n",
      "3455\n",
      "3456\n",
      "3457\n",
      "3458\n",
      "3459\n",
      "3460\n",
      "3461\n",
      "3462\n",
      "3463\n",
      "3464\n",
      "3465\n",
      "3466\n",
      "3467\n",
      "3468\n",
      "3469\n",
      "3470\n",
      "3471\n",
      "3472\n",
      "3473\n",
      "3474\n",
      "3475\n",
      "3476\n",
      "3477\n",
      "3478\n",
      "3479\n",
      "3480\n",
      "3481\n",
      "3482\n",
      "3483\n",
      "3484\n",
      "3485\n",
      "3486\n",
      "3487\n",
      "3488\n",
      "3489\n",
      "3490\n",
      "3491\n",
      "3492\n",
      "3493\n",
      "3494\n",
      "3495\n",
      "3496\n",
      "3497\n",
      "3498\n",
      "3499\n",
      "3500\n",
      "3501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3502\n",
      "3503\n",
      "3504\n",
      "3505\n",
      "3506\n",
      "3507\n",
      "3508\n",
      "3509\n",
      "3510\n",
      "3511\n",
      "3512\n",
      "3513\n",
      "3514\n",
      "3515\n",
      "3516\n",
      "3517\n",
      "3518\n",
      "3519\n",
      "3520\n",
      "3521\n",
      "3522\n",
      "3523\n",
      "3524\n",
      "3525\n",
      "3526\n",
      "3527\n",
      "3528\n",
      "3529\n",
      "3530\n",
      "3531\n",
      "3532\n",
      "3533\n",
      "3534\n",
      "3535\n",
      "3536\n",
      "3537\n",
      "3538\n",
      "3539\n",
      "3540\n",
      "3541\n",
      "3542\n",
      "3543\n",
      "3544\n",
      "3545\n",
      "3546\n",
      "3547\n",
      "3548\n",
      "3549\n",
      "3550\n",
      "3551\n",
      "3552\n",
      "3553\n",
      "3554\n",
      "3555\n",
      "3556\n",
      "3557\n",
      "3558\n",
      "3559\n",
      "3560\n",
      "3561\n",
      "3562\n",
      "3563\n",
      "3564\n",
      "3565\n",
      "3566\n",
      "3567\n",
      "3568\n",
      "3569\n",
      "3570\n",
      "3571\n",
      "3572\n",
      "3573\n",
      "3574\n",
      "3575\n",
      "3576\n",
      "3577\n",
      "3578\n",
      "3579\n",
      "3580\n",
      "3581\n",
      "3582\n",
      "3583\n",
      "3584\n",
      "3585\n",
      "3586\n",
      "3587\n",
      "3588\n",
      "3589\n",
      "3590\n",
      "3591\n",
      "3592\n",
      "3593\n",
      "3594\n",
      "3595\n",
      "3596\n",
      "3597\n",
      "3598\n",
      "3599\n",
      "3600\n",
      "3601\n",
      "3602\n",
      "3603\n",
      "3604\n",
      "3605\n",
      "3606\n",
      "3607\n",
      "3608\n",
      "3609\n",
      "3610\n",
      "3611\n",
      "3612\n",
      "3613\n",
      "3614\n",
      "3615\n",
      "3616\n",
      "3617\n",
      "3618\n",
      "3619\n",
      "3620\n",
      "3621\n",
      "3622\n",
      "3623\n",
      "3624\n",
      "3625\n",
      "3626\n",
      "3627\n",
      "3628\n",
      "3629\n",
      "3630\n",
      "3631\n",
      "3632\n",
      "3633\n",
      "3634\n",
      "3635\n",
      "3636\n",
      "3637\n",
      "3638\n",
      "3639\n",
      "3640\n",
      "3641\n",
      "3642\n",
      "3643\n",
      "3644\n",
      "3645\n",
      "3646\n",
      "3647\n",
      "3648\n",
      "3649\n",
      "3650\n",
      "3651\n",
      "3652\n",
      "3653\n",
      "3654\n",
      "3655\n",
      "3656\n",
      "3657\n",
      "3658\n",
      "3659\n",
      "3660\n",
      "3661\n",
      "3662\n",
      "3663\n",
      "3664\n",
      "3665\n",
      "3666\n",
      "3667\n",
      "3668\n",
      "3669\n",
      "3670\n",
      "3671\n",
      "3672\n",
      "3673\n",
      "3674\n",
      "3675\n",
      "3676\n",
      "3677\n",
      "3678\n",
      "3679\n",
      "3680\n",
      "3681\n",
      "3682\n",
      "3683\n",
      "3684\n",
      "3685\n",
      "3686\n",
      "3687\n",
      "3688\n",
      "3689\n",
      "3690\n",
      "3691\n",
      "3692\n",
      "3693\n",
      "3694\n",
      "3695\n",
      "3696\n",
      "3697\n",
      "3698\n",
      "3699\n",
      "3700\n",
      "3701\n",
      "3702\n",
      "3703\n",
      "3704\n",
      "3705\n",
      "3706\n",
      "3707\n",
      "3708\n",
      "3709\n",
      "3710\n",
      "3711\n",
      "3712\n",
      "3713\n",
      "3714\n",
      "3715\n",
      "3716\n",
      "3717\n",
      "3718\n",
      "3719\n",
      "3720\n",
      "3721\n",
      "3722\n",
      "3723\n",
      "3724\n",
      "3725\n",
      "3726\n",
      "3727\n",
      "3728\n",
      "3729\n",
      "3730\n",
      "3731\n",
      "3732\n",
      "3733\n",
      "3734\n",
      "3735\n",
      "3736\n",
      "3737\n",
      "3738\n",
      "3739\n",
      "3740\n",
      "3741\n",
      "3742\n",
      "3743\n",
      "3744\n",
      "3745\n",
      "3746\n",
      "3747\n",
      "3748\n",
      "3749\n",
      "3750\n",
      "3751\n",
      "3752\n",
      "3753\n",
      "3754\n",
      "3755\n",
      "3756\n",
      "3757\n",
      "3758\n",
      "3759\n",
      "3760\n",
      "3761\n",
      "3762\n",
      "3763\n",
      "3764\n",
      "3765\n",
      "3766\n",
      "3767\n",
      "3768\n",
      "3769\n",
      "3770\n",
      "3771\n",
      "3772\n",
      "3773\n",
      "3774\n",
      "3775\n",
      "3776\n",
      "3777\n",
      "3778\n",
      "3779\n",
      "3780\n",
      "3781\n",
      "3782\n",
      "3783\n",
      "3784\n",
      "3785\n",
      "3786\n",
      "3787\n",
      "3788\n",
      "3789\n",
      "3790\n",
      "3791\n",
      "3792\n",
      "3793\n",
      "3794\n",
      "3795\n",
      "3796\n",
      "3797\n",
      "3798\n",
      "3799\n",
      "3800\n",
      "3801\n",
      "3802\n",
      "3803\n",
      "3804\n",
      "3805\n",
      "3806\n",
      "3807\n",
      "3808\n",
      "3809\n",
      "3810\n",
      "3811\n",
      "3812\n",
      "3813\n",
      "3814\n",
      "3815\n",
      "3816\n",
      "3817\n",
      "3818\n",
      "3819\n",
      "3820\n",
      "3821\n",
      "3822\n",
      "3823\n",
      "3824\n",
      "3825\n",
      "3826\n",
      "3827\n",
      "3828\n",
      "3829\n",
      "3830\n",
      "3831\n",
      "3832\n",
      "3833\n",
      "3834\n",
      "3835\n",
      "3836\n",
      "3837\n",
      "3838\n",
      "3839\n",
      "3840\n",
      "3841\n",
      "3842\n",
      "3843\n",
      "3844\n",
      "3845\n",
      "3846\n",
      "3847\n",
      "3848\n",
      "3849\n",
      "3850\n",
      "3851\n",
      "3852\n",
      "3853\n",
      "3854\n",
      "3855\n",
      "3856\n",
      "3857\n",
      "3858\n",
      "3859\n",
      "3860\n",
      "3861\n",
      "3862\n",
      "3863\n",
      "3864\n",
      "3865\n",
      "3866\n",
      "3867\n",
      "3868\n",
      "3869\n",
      "3870\n",
      "3871\n",
      "3872\n",
      "3873\n",
      "3874\n",
      "3875\n",
      "3876\n",
      "3877\n",
      "3878\n",
      "3879\n",
      "3880\n",
      "3881\n",
      "3882\n",
      "3883\n",
      "3884\n",
      "3885\n",
      "3886\n",
      "3887\n",
      "3888\n",
      "3889\n",
      "3890\n",
      "3891\n",
      "3892\n",
      "3893\n",
      "3894\n",
      "3895\n",
      "3896\n",
      "3897\n",
      "3898\n",
      "3899\n",
      "3900\n",
      "3901\n",
      "3902\n",
      "3903\n",
      "3904\n",
      "3905\n",
      "3906\n",
      "3907\n",
      "3908\n",
      "3909\n",
      "3910\n",
      "3911\n",
      "3912\n",
      "3913\n",
      "3914\n",
      "3915\n",
      "3916\n",
      "3917\n",
      "3918\n",
      "3919\n",
      "3920\n",
      "3921\n",
      "3922\n",
      "3923\n",
      "3924\n",
      "3925\n",
      "3926\n",
      "3927\n",
      "3928\n",
      "3929\n",
      "3930\n",
      "3931\n",
      "3932\n",
      "3933\n",
      "3934\n",
      "3935\n",
      "3936\n",
      "3937\n",
      "3938\n",
      "3939\n",
      "3940\n",
      "3941\n",
      "3942\n",
      "3943\n",
      "3944\n",
      "3945\n",
      "3946\n",
      "3947\n",
      "3948\n",
      "3949\n",
      "3950\n",
      "3951\n",
      "3952\n",
      "3953\n",
      "3954\n",
      "3955\n",
      "3956\n",
      "3957\n",
      "3958\n",
      "3959\n",
      "3960\n",
      "3961\n",
      "3962\n",
      "3963\n",
      "3964\n",
      "3965\n",
      "3966\n",
      "3967\n",
      "3968\n",
      "3969\n",
      "3970\n",
      "3971\n",
      "3972\n",
      "3973\n",
      "3974\n",
      "3975\n",
      "3976\n",
      "3977\n",
      "3978\n",
      "3979\n",
      "3980\n",
      "3981\n",
      "3982\n",
      "3983\n",
      "3984\n",
      "3985\n",
      "3986\n",
      "3987\n",
      "3988\n",
      "3989\n",
      "3990\n",
      "3991\n",
      "3992\n",
      "3993\n",
      "3994\n",
      "3995\n",
      "3996\n",
      "3997\n",
      "3998\n",
      "3999\n",
      "4000\n",
      "4001\n",
      "4002\n",
      "4003\n",
      "4004\n",
      "4005\n",
      "4006\n",
      "4007\n",
      "4008\n",
      "4009\n",
      "4010\n",
      "4011\n",
      "4012\n",
      "4013\n",
      "4014\n",
      "4015\n",
      "4016\n",
      "4017\n",
      "4018\n",
      "4019\n",
      "4020\n",
      "4021\n",
      "4022\n",
      "4023\n",
      "4024\n",
      "4025\n",
      "4026\n",
      "4027\n",
      "4028\n",
      "4029\n",
      "4030\n",
      "4031\n",
      "4032\n",
      "4033\n",
      "4034\n",
      "4035\n",
      "4036\n",
      "4037\n",
      "4038\n",
      "4039\n",
      "4040\n",
      "4041\n",
      "4042\n",
      "4043\n",
      "4044\n",
      "4045\n",
      "4046\n",
      "4047\n",
      "4048\n",
      "4049\n",
      "4050\n",
      "4051\n",
      "4052\n",
      "4053\n",
      "4054\n",
      "4055\n",
      "4056\n",
      "4057\n",
      "4058\n",
      "4059\n",
      "4060\n",
      "4061\n",
      "4062\n",
      "4063\n",
      "4064\n",
      "4065\n",
      "4066\n",
      "4067\n",
      "4068\n",
      "4069\n",
      "4070\n",
      "4071\n",
      "4072\n",
      "4073\n",
      "4074\n",
      "4075\n",
      "4076\n",
      "4077\n",
      "4078\n",
      "4079\n",
      "4080\n",
      "4081\n",
      "4082\n",
      "4083\n",
      "4084\n",
      "4085\n",
      "4086\n",
      "4087\n",
      "4088\n",
      "4089\n",
      "4090\n",
      "4091\n",
      "4092\n",
      "4093\n",
      "4094\n",
      "4095\n",
      "4096\n",
      "4097\n",
      "4098\n",
      "4099\n",
      "4100\n",
      "4101\n",
      "4102\n",
      "4103\n",
      "4104\n",
      "4105\n",
      "4106\n",
      "4107\n",
      "4108\n",
      "4109\n",
      "4110\n",
      "4111\n",
      "4112\n",
      "4113\n",
      "4114\n",
      "4115\n",
      "4116\n",
      "4117\n",
      "4118\n",
      "4119\n",
      "4120\n",
      "4121\n",
      "4122\n",
      "4123\n",
      "4124\n",
      "4125\n",
      "4126\n",
      "4127\n",
      "4128\n",
      "4129\n",
      "4130\n",
      "4131\n",
      "4132\n",
      "4133\n",
      "4134\n",
      "4135\n",
      "4136\n",
      "4137\n",
      "4138\n",
      "4139\n",
      "4140\n",
      "4141\n",
      "4142\n",
      "4143\n",
      "4144\n",
      "4145\n",
      "4146\n",
      "4147\n",
      "4148\n",
      "4149\n",
      "4150\n",
      "4151\n",
      "4152\n",
      "4153\n",
      "4154\n",
      "4155\n",
      "4156\n",
      "4157\n",
      "4158\n",
      "4159\n",
      "4160\n",
      "4161\n",
      "4162\n",
      "4163\n",
      "4164\n",
      "4165\n",
      "4166\n",
      "4167\n",
      "4168\n",
      "4169\n",
      "4170\n",
      "4171\n",
      "4172\n",
      "4173\n",
      "4174\n",
      "4175\n",
      "4176\n",
      "4177\n",
      "4178\n",
      "4179\n",
      "4180\n",
      "4181\n",
      "4182\n",
      "4183\n",
      "4184\n",
      "4185\n",
      "4186\n",
      "4187\n",
      "4188\n",
      "4189\n",
      "4190\n",
      "4191\n",
      "4192\n",
      "4193\n",
      "4194\n",
      "4195\n",
      "4196\n",
      "4197\n",
      "4198\n",
      "4199\n",
      "4200\n",
      "4201\n",
      "4202\n",
      "4203\n",
      "4204\n",
      "4205\n",
      "4206\n",
      "4207\n",
      "4208\n",
      "4209\n",
      "4210\n",
      "4211\n",
      "4212\n",
      "4213\n",
      "4214\n",
      "4215\n",
      "4216\n",
      "4217\n",
      "4218\n",
      "4219\n",
      "4220\n",
      "4221\n",
      "4222\n",
      "4223\n",
      "4224\n",
      "4225\n",
      "4226\n",
      "4227\n",
      "4228\n",
      "4229\n",
      "4230\n",
      "4231\n",
      "4232\n",
      "4233\n",
      "4234\n",
      "4235\n",
      "4236\n",
      "4237\n",
      "4238\n",
      "4239\n",
      "4240\n",
      "4241\n",
      "4242\n",
      "4243\n",
      "4244\n",
      "4245\n",
      "4246\n",
      "4247\n",
      "4248\n",
      "4249\n",
      "4250\n",
      "4251\n",
      "4252\n",
      "4253\n",
      "4254\n",
      "4255\n",
      "4256\n",
      "4257\n",
      "4258\n",
      "4259\n",
      "4260\n",
      "4261\n",
      "4262\n",
      "4263\n",
      "4264\n",
      "4265\n",
      "4266\n",
      "4267\n",
      "4268\n",
      "4269\n",
      "4270\n",
      "4271\n",
      "4272\n",
      "4273\n",
      "4274\n",
      "4275\n",
      "4276\n",
      "4277\n",
      "4278\n",
      "4279\n",
      "4280\n",
      "4281\n",
      "4282\n",
      "4283\n",
      "4284\n",
      "4285\n",
      "4286\n",
      "4287\n",
      "4288\n",
      "4289\n",
      "4290\n",
      "4291\n",
      "4292\n",
      "4293\n",
      "4294\n",
      "4295\n",
      "4296\n",
      "4297\n",
      "4298\n",
      "4299\n",
      "4300\n",
      "4301\n",
      "4302\n",
      "4303\n",
      "4304\n",
      "4305\n",
      "4306\n",
      "4307\n",
      "4308\n",
      "4309\n",
      "4310\n",
      "4311\n",
      "4312\n",
      "4313\n",
      "4314\n",
      "4315\n",
      "4316\n",
      "4317\n",
      "4318\n",
      "4319\n",
      "4320\n",
      "4321\n",
      "4322\n",
      "4323\n",
      "4324\n",
      "4325\n",
      "4326\n",
      "4327\n",
      "4328\n",
      "4329\n",
      "4330\n",
      "4331\n",
      "4332\n",
      "4333\n",
      "4334\n",
      "4335\n",
      "4336\n",
      "4337\n",
      "4338\n",
      "4339\n",
      "4340\n",
      "4341\n",
      "4342\n",
      "4343\n",
      "4344\n",
      "4345\n",
      "4346\n",
      "4347\n",
      "4348\n",
      "4349\n",
      "4350\n",
      "4351\n",
      "4352\n",
      "4353\n",
      "4354\n",
      "4355\n",
      "4356\n",
      "4357\n",
      "4358\n",
      "4359\n",
      "4360\n",
      "4361\n",
      "4362\n",
      "4363\n",
      "4364\n",
      "4365\n",
      "4366\n",
      "4367\n",
      "4368\n",
      "4369\n",
      "4370\n",
      "4371\n",
      "4372\n",
      "4373\n",
      "4374\n",
      "4375\n",
      "4376\n",
      "4377\n",
      "4378\n",
      "4379\n",
      "4380\n",
      "4381\n",
      "4382\n",
      "4383\n",
      "4384\n",
      "4385\n",
      "4386\n",
      "4387\n",
      "4388\n",
      "4389\n",
      "4390\n",
      "4391\n",
      "4392\n",
      "4393\n",
      "4394\n",
      "4395\n",
      "4396\n",
      "4397\n",
      "4398\n",
      "4399\n",
      "4400\n",
      "4401\n",
      "4402\n",
      "4403\n",
      "4404\n",
      "4405\n",
      "4406\n",
      "4407\n",
      "4408\n",
      "4409\n",
      "4410\n",
      "4411\n",
      "4412\n",
      "4413\n",
      "4414\n",
      "4415\n",
      "4416\n",
      "4417\n",
      "4418\n",
      "4419\n",
      "4420\n",
      "4421\n",
      "4422\n",
      "4423\n",
      "4424\n",
      "4425\n",
      "4426\n",
      "4427\n",
      "4428\n",
      "4429\n",
      "4430\n",
      "4431\n",
      "4432\n",
      "4433\n",
      "4434\n",
      "4435\n",
      "4436\n",
      "4437\n",
      "4438\n",
      "4439\n",
      "4440\n",
      "4441\n",
      "4442\n",
      "4443\n",
      "4444\n",
      "4445\n",
      "4446\n",
      "4447\n",
      "4448\n",
      "4449\n",
      "4450\n",
      "4451\n",
      "4452\n",
      "4453\n",
      "4454\n",
      "4455\n",
      "4456\n",
      "4457\n",
      "4458\n",
      "4459\n",
      "4460\n",
      "4461\n",
      "4462\n",
      "4463\n",
      "4464\n",
      "4465\n",
      "4466\n",
      "4467\n",
      "4468\n",
      "4469\n",
      "4470\n",
      "4471\n",
      "4472\n",
      "4473\n",
      "4474\n",
      "4475\n",
      "4476\n",
      "4477\n",
      "4478\n",
      "4479\n",
      "4480\n",
      "4481\n",
      "4482\n",
      "4483\n",
      "4484\n",
      "4485\n",
      "4486\n",
      "4487\n",
      "4488\n",
      "4489\n",
      "4490\n",
      "4491\n",
      "4492\n",
      "4493\n",
      "4494\n",
      "4495\n",
      "4496\n",
      "4497\n",
      "4498\n",
      "4499\n",
      "4500\n",
      "4501\n",
      "4502\n",
      "4503\n",
      "4504\n",
      "4505\n",
      "4506\n",
      "4507\n",
      "4508\n",
      "4509\n",
      "4510\n",
      "4511\n",
      "4512\n",
      "4513\n",
      "4514\n",
      "4515\n",
      "4516\n",
      "4517\n",
      "4518\n",
      "4519\n",
      "4520\n",
      "4521\n",
      "4522\n",
      "4523\n",
      "4524\n",
      "4525\n",
      "4526\n",
      "4527\n",
      "4528\n",
      "4529\n",
      "4530\n",
      "4531\n",
      "4532\n",
      "4533\n",
      "4534\n",
      "4535\n",
      "4536\n",
      "4537\n",
      "4538\n",
      "4539\n",
      "4540\n",
      "4541\n",
      "4542\n",
      "4543\n",
      "4544\n",
      "4545\n",
      "4546\n",
      "4547\n",
      "4548\n",
      "4549\n",
      "4550\n",
      "4551\n",
      "4552\n",
      "4553\n",
      "4554\n",
      "4555\n",
      "4556\n",
      "4557\n",
      "4558\n",
      "4559\n",
      "4560\n",
      "4561\n",
      "4562\n",
      "4563\n",
      "4564\n",
      "4565\n",
      "4566\n",
      "4567\n",
      "4568\n",
      "4569\n",
      "4570\n",
      "4571\n",
      "4572\n",
      "4573\n",
      "4574\n",
      "4575\n",
      "4576\n",
      "4577\n",
      "4578\n",
      "4579\n",
      "4580\n",
      "4581\n",
      "4582\n",
      "4583\n",
      "4584\n",
      "4585\n",
      "4586\n",
      "4587\n",
      "4588\n",
      "4589\n",
      "4590\n",
      "4591\n",
      "4592\n",
      "4593\n",
      "4594\n",
      "4595\n",
      "4596\n",
      "4597\n",
      "4598\n",
      "4599\n",
      "4600\n",
      "4601\n",
      "4602\n",
      "4603\n",
      "4604\n",
      "4605\n",
      "4606\n",
      "4607\n",
      "4608\n",
      "4609\n",
      "4610\n",
      "4611\n",
      "4612\n",
      "4613\n",
      "4614\n",
      "4615\n",
      "4616\n",
      "4617\n",
      "4618\n",
      "4619\n",
      "4620\n",
      "4621\n",
      "4622\n",
      "4623\n",
      "4624\n",
      "4625\n",
      "4626\n",
      "4627\n",
      "4628\n",
      "4629\n",
      "4630\n",
      "4631\n",
      "4632\n",
      "4633\n",
      "4634\n",
      "4635\n",
      "4636\n",
      "4637\n",
      "4638\n",
      "4639\n",
      "4640\n",
      "4641\n",
      "4642\n",
      "4643\n",
      "4644\n",
      "4645\n",
      "4646\n",
      "4647\n",
      "4648\n",
      "4649\n",
      "4650\n",
      "4651\n",
      "4652\n",
      "4653\n",
      "4654\n",
      "4655\n",
      "4656\n",
      "4657\n",
      "4658\n",
      "4659\n",
      "4660\n",
      "4661\n",
      "4662\n",
      "4663\n",
      "4664\n",
      "4665\n",
      "4666\n",
      "4667\n",
      "4668\n",
      "4669\n",
      "4670\n",
      "4671\n",
      "4672\n",
      "4673\n",
      "4674\n",
      "4675\n",
      "4676\n",
      "4677\n",
      "4678\n",
      "4679\n",
      "4680\n",
      "4681\n",
      "4682\n",
      "4683\n",
      "4684\n",
      "4685\n",
      "4686\n",
      "4687\n",
      "4688\n",
      "4689\n",
      "4690\n",
      "4691\n",
      "4692\n",
      "4693\n",
      "4694\n",
      "4695\n",
      "4696\n",
      "4697\n",
      "4698\n",
      "4699\n",
      "4700\n",
      "4701\n",
      "4702\n",
      "4703\n",
      "4704\n",
      "4705\n",
      "4706\n",
      "4707\n",
      "4708\n",
      "4709\n",
      "4710\n",
      "4711\n",
      "4712\n",
      "4713\n",
      "4714\n",
      "4715\n",
      "4716\n",
      "4717\n",
      "4718\n",
      "4719\n",
      "4720\n",
      "4721\n",
      "4722\n",
      "4723\n",
      "4724\n",
      "4725\n",
      "4726\n",
      "4727\n",
      "4728\n",
      "4729\n",
      "4730\n",
      "4731\n",
      "4732\n",
      "4733\n",
      "4734\n",
      "4735\n",
      "4736\n",
      "4737\n",
      "4738\n",
      "4739\n",
      "4740\n",
      "4741\n",
      "4742\n",
      "4743\n",
      "4744\n",
      "4745\n",
      "4746\n",
      "4747\n",
      "4748\n",
      "4749\n",
      "4750\n",
      "4751\n",
      "4752\n",
      "4753\n",
      "4754\n",
      "4755\n",
      "4756\n",
      "4757\n",
      "4758\n",
      "4759\n",
      "4760\n",
      "4761\n",
      "4762\n",
      "4763\n",
      "4764\n",
      "4765\n",
      "4766\n",
      "4767\n",
      "4768\n",
      "4769\n",
      "4770\n",
      "4771\n",
      "4772\n",
      "4773\n",
      "4774\n",
      "4775\n",
      "4776\n",
      "4777\n",
      "4778\n",
      "4779\n",
      "4780\n",
      "4781\n",
      "4782\n",
      "4783\n",
      "4784\n",
      "4785\n",
      "4786\n",
      "4787\n",
      "4788\n",
      "4789\n",
      "4790\n",
      "4791\n",
      "4792\n",
      "4793\n",
      "4794\n",
      "4795\n",
      "4796\n",
      "4797\n",
      "4798\n",
      "4799\n",
      "4800\n",
      "4801\n",
      "4802\n",
      "4803\n",
      "4804\n",
      "4805\n",
      "4806\n",
      "4807\n",
      "4808\n",
      "4809\n",
      "4810\n",
      "4811\n",
      "4812\n",
      "4813\n",
      "4814\n",
      "4815\n",
      "4816\n",
      "4817\n",
      "4818\n",
      "4819\n",
      "4820\n",
      "4821\n",
      "4822\n",
      "4823\n",
      "4824\n",
      "4825\n",
      "4826\n",
      "4827\n",
      "4828\n",
      "4829\n",
      "4830\n",
      "4831\n",
      "4832\n",
      "4833\n",
      "4834\n",
      "4835\n",
      "4836\n",
      "4837\n",
      "4838\n",
      "4839\n",
      "4840\n",
      "4841\n",
      "4842\n",
      "4843\n",
      "4844\n",
      "4845\n",
      "4846\n",
      "4847\n",
      "4848\n",
      "4849\n",
      "4850\n",
      "4851\n",
      "4852\n",
      "4853\n",
      "4854\n",
      "4855\n",
      "4856\n",
      "4857\n",
      "4858\n",
      "4859\n",
      "4860\n",
      "4861\n",
      "4862\n",
      "4863\n",
      "4864\n",
      "4865\n",
      "4866\n",
      "4867\n",
      "4868\n",
      "4869\n",
      "4870\n",
      "4871\n",
      "4872\n",
      "4873\n",
      "4874\n",
      "4875\n",
      "4876\n",
      "4877\n",
      "4878\n",
      "4879\n",
      "4880\n",
      "4881\n",
      "4882\n",
      "4883\n",
      "4884\n",
      "4885\n",
      "4886\n",
      "4887\n",
      "4888\n",
      "4889\n",
      "4890\n",
      "4891\n",
      "4892\n",
      "4893\n",
      "4894\n",
      "4895\n",
      "4896\n",
      "4897\n",
      "4898\n",
      "4899\n",
      "4900\n",
      "4901\n",
      "4902\n",
      "4903\n",
      "4904\n",
      "4905\n",
      "4906\n",
      "4907\n",
      "4908\n",
      "4909\n",
      "4910\n",
      "4911\n",
      "4912\n",
      "4913\n",
      "4914\n",
      "4915\n",
      "4916\n",
      "4917\n",
      "4918\n",
      "4919\n",
      "4920\n",
      "4921\n",
      "4922\n",
      "4923\n",
      "4924\n",
      "4925\n",
      "4926\n",
      "4927\n",
      "4928\n",
      "4929\n",
      "4930\n",
      "4931\n",
      "4932\n",
      "4933\n",
      "4934\n",
      "4935\n",
      "4936\n",
      "4937\n",
      "4938\n",
      "4939\n",
      "4940\n",
      "4941\n",
      "4942\n",
      "4943\n",
      "4944\n",
      "4945\n",
      "4946\n",
      "4947\n",
      "4948\n",
      "4949\n",
      "4950\n",
      "4951\n",
      "4952\n",
      "4953\n",
      "4954\n",
      "4955\n",
      "4956\n",
      "4957\n",
      "4958\n",
      "4959\n",
      "4960\n",
      "4961\n",
      "4962\n",
      "4963\n",
      "4964\n",
      "4965\n",
      "4966\n",
      "4967\n",
      "4968\n",
      "4969\n",
      "4970\n",
      "4971\n",
      "4972\n",
      "4973\n",
      "4974\n",
      "4975\n",
      "4976\n",
      "4977\n",
      "4978\n",
      "4979\n",
      "4980\n",
      "4981\n",
      "4982\n",
      "4983\n",
      "4984\n",
      "4985\n",
      "4986\n",
      "4987\n",
      "4988\n",
      "4989\n",
      "4990\n",
      "4991\n",
      "4992\n",
      "4993\n",
      "4994\n",
      "4995\n",
      "4996\n",
      "4997\n",
      "4998\n",
      "4999\n",
      "5000\n",
      "5001\n",
      "5002\n",
      "5003\n",
      "5004\n",
      "5005\n",
      "5006\n",
      "5007\n",
      "5008\n",
      "5009\n",
      "5010\n",
      "5011\n",
      "5012\n",
      "5013\n",
      "5014\n",
      "5015\n",
      "5016\n",
      "5017\n",
      "5018\n",
      "5019\n",
      "5020\n",
      "5021\n",
      "5022\n",
      "5023\n",
      "5024\n",
      "5025\n",
      "5026\n",
      "5027\n",
      "5028\n",
      "5029\n",
      "5030\n",
      "5031\n",
      "5032\n",
      "5033\n",
      "5034\n",
      "5035\n",
      "5036\n",
      "5037\n",
      "5038\n",
      "5039\n",
      "5040\n",
      "5041\n",
      "5042\n",
      "5043\n",
      "5044\n",
      "5045\n",
      "5046\n",
      "5047\n",
      "5048\n",
      "5049\n",
      "5050\n",
      "5051\n",
      "5052\n",
      "5053\n",
      "5054\n",
      "5055\n",
      "5056\n",
      "5057\n",
      "5058\n",
      "5059\n",
      "5060\n",
      "5061\n",
      "5062\n",
      "5063\n",
      "5064\n",
      "5065\n",
      "5066\n",
      "5067\n",
      "5068\n",
      "5069\n",
      "5070\n",
      "5071\n",
      "5072\n",
      "5073\n",
      "5074\n",
      "5075\n",
      "5076\n",
      "5077\n",
      "5078\n",
      "5079\n",
      "5080\n",
      "5081\n",
      "5082\n",
      "5083\n",
      "5084\n",
      "5085\n",
      "5086\n",
      "5087\n",
      "5088\n",
      "5089\n",
      "5090\n",
      "5091\n",
      "5092\n",
      "5093\n",
      "5094\n",
      "5095\n",
      "5096\n",
      "5097\n",
      "5098\n",
      "5099\n",
      "5100\n",
      "5101\n",
      "5102\n",
      "5103\n",
      "5104\n",
      "5105\n",
      "5106\n",
      "5107\n",
      "5108\n",
      "5109\n",
      "5110\n",
      "5111\n",
      "5112\n",
      "5113\n",
      "5114\n",
      "5115\n",
      "5116\n",
      "5117\n",
      "5118\n",
      "5119\n",
      "5120\n",
      "5121\n",
      "5122\n",
      "5123\n",
      "5124\n",
      "5125\n",
      "5126\n",
      "5127\n",
      "5128\n",
      "5129\n",
      "5130\n",
      "5131\n",
      "5132\n",
      "5133\n",
      "5134\n",
      "5135\n",
      "5136\n",
      "5137\n",
      "5138\n",
      "5139\n",
      "5140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5141\n",
      "5142\n",
      "5143\n",
      "5144\n",
      "5145\n",
      "5146\n",
      "5147\n",
      "5148\n",
      "5149\n",
      "5150\n",
      "5151\n",
      "5152\n",
      "5153\n",
      "5154\n",
      "5155\n",
      "5156\n",
      "5157\n",
      "5158\n",
      "5159\n",
      "5160\n",
      "5161\n",
      "5162\n",
      "5163\n",
      "5164\n",
      "5165\n",
      "5166\n",
      "5167\n",
      "5168\n",
      "5169\n",
      "5170\n",
      "5171\n",
      "5172\n",
      "5173\n",
      "5174\n",
      "5175\n",
      "5176\n",
      "5177\n",
      "5178\n",
      "5179\n",
      "5180\n",
      "5181\n",
      "5182\n",
      "5183\n",
      "5184\n",
      "5185\n",
      "5186\n",
      "5187\n",
      "5188\n",
      "5189\n",
      "5190\n",
      "5191\n",
      "5192\n",
      "5193\n",
      "5194\n",
      "5195\n",
      "5196\n",
      "5197\n",
      "5198\n",
      "5199\n",
      "5200\n",
      "5201\n",
      "5202\n",
      "5203\n",
      "5204\n",
      "5205\n",
      "5206\n",
      "5207\n",
      "5208\n",
      "5209\n",
      "5210\n",
      "5211\n",
      "5212\n",
      "5213\n",
      "5214\n",
      "5215\n",
      "5216\n",
      "5217\n",
      "5218\n",
      "5219\n",
      "5220\n",
      "5221\n",
      "5222\n",
      "5223\n",
      "5224\n",
      "5225\n",
      "5226\n",
      "5227\n",
      "5228\n",
      "5229\n",
      "5230\n",
      "5231\n",
      "5232\n",
      "5233\n",
      "5234\n",
      "5235\n",
      "5236\n",
      "5237\n",
      "5238\n",
      "5239\n",
      "5240\n",
      "5241\n",
      "5242\n",
      "5243\n",
      "5244\n",
      "5245\n",
      "5246\n",
      "5247\n",
      "5248\n",
      "5249\n",
      "5250\n",
      "5251\n",
      "5252\n",
      "5253\n",
      "5254\n",
      "5255\n",
      "5256\n",
      "5257\n",
      "5258\n",
      "5259\n",
      "5260\n",
      "5261\n",
      "5262\n",
      "5263\n",
      "5264\n",
      "5265\n",
      "5266\n",
      "5267\n",
      "5268\n",
      "5269\n",
      "5270\n",
      "5271\n",
      "5272\n",
      "5273\n",
      "5274\n",
      "5275\n",
      "5276\n",
      "5277\n",
      "5278\n",
      "5279\n",
      "5280\n",
      "5281\n",
      "5282\n",
      "5283\n",
      "5284\n",
      "5285\n",
      "5286\n",
      "5287\n",
      "5288\n",
      "5289\n",
      "5290\n",
      "5291\n",
      "5292\n",
      "5293\n",
      "5294\n",
      "5295\n",
      "5296\n",
      "5297\n",
      "5298\n",
      "5299\n",
      "5300\n",
      "5301\n",
      "5302\n",
      "5303\n",
      "5304\n",
      "5305\n",
      "5306\n",
      "5307\n",
      "5308\n",
      "5309\n",
      "5310\n",
      "5311\n",
      "5312\n",
      "5313\n",
      "5314\n",
      "5315\n",
      "5316\n",
      "5317\n",
      "5318\n",
      "5319\n",
      "5320\n",
      "5321\n",
      "5322\n",
      "5323\n",
      "5324\n",
      "5325\n",
      "5326\n",
      "5327\n",
      "5328\n",
      "5329\n",
      "5330\n",
      "5331\n",
      "5332\n",
      "5333\n",
      "5334\n",
      "5335\n",
      "5336\n",
      "5337\n",
      "5338\n",
      "5339\n",
      "5340\n",
      "5341\n",
      "5342\n",
      "5343\n",
      "5344\n",
      "5345\n",
      "5346\n",
      "5347\n",
      "5348\n",
      "5349\n",
      "5350\n",
      "5351\n",
      "5352\n",
      "5353\n",
      "5354\n",
      "5355\n",
      "5356\n",
      "5357\n",
      "5358\n",
      "5359\n",
      "5360\n",
      "5361\n",
      "5362\n",
      "5363\n",
      "5364\n",
      "5365\n",
      "5366\n",
      "5367\n",
      "5368\n",
      "5369\n",
      "5370\n",
      "5371\n",
      "5372\n",
      "5373\n",
      "5374\n",
      "5375\n",
      "5376\n",
      "5377\n",
      "5378\n",
      "5379\n",
      "5380\n",
      "5381\n",
      "5382\n",
      "5383\n",
      "5384\n",
      "5385\n",
      "5386\n",
      "5387\n",
      "5388\n",
      "5389\n",
      "5390\n",
      "5391\n",
      "5392\n",
      "5393\n",
      "5394\n",
      "5395\n",
      "5396\n",
      "5397\n",
      "5398\n",
      "5399\n",
      "5400\n",
      "5401\n",
      "5402\n",
      "5403\n",
      "5404\n",
      "5405\n",
      "5406\n",
      "5407\n",
      "5408\n",
      "5409\n",
      "5410\n",
      "5411\n",
      "5412\n",
      "5413\n",
      "5414\n",
      "5415\n",
      "5416\n",
      "5417\n",
      "5418\n",
      "5419\n",
      "5420\n",
      "5421\n",
      "5422\n",
      "5423\n",
      "5424\n",
      "5425\n",
      "5426\n",
      "5427\n",
      "5428\n",
      "5429\n",
      "5430\n",
      "5431\n",
      "5432\n",
      "5433\n",
      "5434\n",
      "5435\n",
      "5436\n",
      "5437\n",
      "5438\n",
      "5439\n",
      "5440\n",
      "5441\n",
      "5442\n",
      "5443\n",
      "5444\n",
      "5445\n",
      "5446\n",
      "5447\n",
      "5448\n",
      "5449\n",
      "5450\n",
      "5451\n",
      "5452\n",
      "5453\n",
      "5454\n",
      "5455\n",
      "5456\n",
      "5457\n",
      "5458\n",
      "5459\n",
      "5460\n",
      "5461\n",
      "5462\n",
      "5463\n",
      "5464\n",
      "5465\n",
      "5466\n",
      "5467\n",
      "5468\n"
     ]
    }
   ],
   "source": [
    "new_data=pd.DataFrame()\n",
    "cont=0\n",
    "for lista in data['bow_traducido']:\n",
    "    res = lista.strip('][').split(', ')\n",
    "    cont+=1\n",
    "    print(cont)\n",
    "    a1=pd.DataFrame([res])\n",
    "    new_data=pd.concat([new_data,a1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Máximo 34 caracteres\n",
    "new_data=new_data.iloc[:,0:35]\n",
    "new_data=new_data.reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=data['ingresos'].apply(lambda x: 0 if x=='Bajos' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ortog']=data['Ortografia'].apply(lambda x: 0 if not x else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['emoji_sent_transf']=data.emoji_sentiment.fillna(0.5)\n",
    "data['have_emojis']=data['emoji_sentiment'].apply(lambda x: 0 if str(x)=='nan' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_x_data=data[['spanish_sentiment', 'emoji_sent_transf','have_emojis','ortog']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_train=pd.concat([y_train, data['bow_length'], new_data,\n",
    "          other_x_data], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we save the data tranformed, after removing NAs and converting the words of the dictionary to a Data Frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_train.to_csv(data_dir+'train.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the process to upload the data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'sagemaker/twitter_train'\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = sagemaker_session.upload_data(path=data_dir, bucket=bucket, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-2-428747017283/sagemaker/twitter_train'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model that was checked was Embeding+ Neural Network. In this case I used a neural network with three layers.\n",
    "The first one is an embedding layer, the second a lstm layer and the third one a linear layer.\n",
    "I tried to use the variables of spelling and sentiment previously created, but with this new variables the network perfomed worst than when it was just using the vocabulary variables, so at the end the variables of spelling and sentiment were no used to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnn\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mfunctional\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mF\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mLSTMClassifier\u001b[39;49;00m(nn.Module):\r\n",
      "    \u001b[33m\"\"\"\u001b[39;49;00m\r\n",
      "\u001b[33m    This is the simple RNN model we will be using to perform Sentiment Analysis.\u001b[39;49;00m\r\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\r\n",
      "\r\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, embedding_dim, hidden_dim, vocab_size):\r\n",
      "        \u001b[33m\"\"\"\u001b[39;49;00m\r\n",
      "\u001b[33m        Initialize the model by settingg up the various layers.\u001b[39;49;00m\r\n",
      "\u001b[33m        \"\"\"\u001b[39;49;00m\r\n",
      "        \u001b[36msuper\u001b[39;49;00m(LSTMClassifier, \u001b[36mself\u001b[39;49;00m).\u001b[32m__init__\u001b[39;49;00m()\r\n",
      "\r\n",
      "        \u001b[36mself\u001b[39;49;00m.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=\u001b[34m0\u001b[39;49;00m)\r\n",
      "        \u001b[36mself\u001b[39;49;00m.lstm = nn.LSTM(embedding_dim, hidden_dim)\r\n",
      "        \u001b[36mself\u001b[39;49;00m.dense = nn.Linear(in_features=hidden_dim, out_features=\u001b[34m1\u001b[39;49;00m)\r\n",
      "        \u001b[36mself\u001b[39;49;00m.sig = nn.Sigmoid()\r\n",
      "        \u001b[36mself\u001b[39;49;00m.word_dict = \u001b[34mNone\u001b[39;49;00m\r\n",
      "\r\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mforward\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, x):\r\n",
      "        \u001b[33m\"\"\"\u001b[39;49;00m\r\n",
      "\u001b[33m        Perform a forward pass of our model on some input.\u001b[39;49;00m\r\n",
      "\u001b[33m        \"\"\"\u001b[39;49;00m\r\n",
      "        x = x.t()\r\n",
      "        lengths = x[\u001b[34m0\u001b[39;49;00m,:]\r\n",
      "        lengths=lengths.long()\r\n",
      "        reviews = x[\u001b[34m1\u001b[39;49;00m:-\u001b[34m4\u001b[39;49;00m,:]\r\n",
      "        reviews=reviews.long()\r\n",
      "        other_x=x[-\u001b[34m4\u001b[39;49;00m:,:]\r\n",
      "        embeds = \u001b[36mself\u001b[39;49;00m.embedding(reviews)\r\n",
      "        lstm_out, _ = \u001b[36mself\u001b[39;49;00m.lstm(embeds)\r\n",
      "        out = \u001b[36mself\u001b[39;49;00m.dense(lstm_out)\r\n",
      "        out = out[lengths - \u001b[34m1\u001b[39;49;00m, \u001b[36mrange\u001b[39;49;00m(\u001b[36mlen\u001b[39;49;00m(lengths))]\r\n",
      "        \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.sig(out.squeeze())\r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize train/model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I proved that the file \"train.py\" was working correcty, proving the file with a sample of the total data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "import os\n",
    "\n",
    "# Read in only the first 250 rows\n",
    "train_sample = pd.read_csv(os.path.join(data_dir, 'train.csv'), header=None, names=None, nrows=250)\n",
    "#train_sample=train_sample.loc[:,:32]\n",
    "# Turn the input pandas dataframe into tensors\n",
    "train_sample_y = torch.from_numpy(train_sample[[0]].values).float().squeeze()\n",
    "train_sample_X = torch.from_numpy(train_sample.drop([0], axis=1).values).float()\n",
    "\n",
    "# Build the dataset\n",
    "train_sample_ds = torch.utils.data.TensorDataset(train_sample_X, train_sample_y)\n",
    "# Build the dataloader\n",
    "train_sample_dl = torch.utils.data.DataLoader(train_sample_ds, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>632</td>\n",
       "      <td>3665</td>\n",
       "      <td>3666</td>\n",
       "      <td>16</td>\n",
       "      <td>508</td>\n",
       "      <td>633</td>\n",
       "      <td>3667</td>\n",
       "      <td>3668</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.925069</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.504721</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1270</td>\n",
       "      <td>99</td>\n",
       "      <td>239</td>\n",
       "      <td>46</td>\n",
       "      <td>2492</td>\n",
       "      <td>509</td>\n",
       "      <td>469</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.690813</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>3670</td>\n",
       "      <td>470</td>\n",
       "      <td>15</td>\n",
       "      <td>350</td>\n",
       "      <td>299</td>\n",
       "      <td>1271</td>\n",
       "      <td>3671</td>\n",
       "      <td>2493</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.023109</td>\n",
       "      <td>0.7145</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1515</td>\n",
       "      <td>33</td>\n",
       "      <td>316</td>\n",
       "      <td>1891</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.504735</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>638</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.504905</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1014</td>\n",
       "      <td>130</td>\n",
       "      <td>2594</td>\n",
       "      <td>650</td>\n",
       "      <td>891</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.054515</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>659</td>\n",
       "      <td>3845</td>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.504756</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1316</td>\n",
       "      <td>77</td>\n",
       "      <td>491</td>\n",
       "      <td>87</td>\n",
       "      <td>295</td>\n",
       "      <td>1573</td>\n",
       "      <td>1317</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.740318</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.504763</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1     2     3     4     5     6     7     8     9   ...  31  32  33  \\\n",
       "0     1  11   632  3665  3666    16   508   633  3667  3668  ...   0   0   0   \n",
       "1     0   1    88     0     0     0     0     0     0     0  ...   0   0   0   \n",
       "2     0   7  1270    99   239    46  2492   509   469     0  ...   0   0   0   \n",
       "3     1  14  3670   470    15   350   299  1271  3671  2493  ...   0   0   0   \n",
       "4     1   4  1515    33   316  1891     0     0     0     0  ...   0   0   0   \n",
       "..   ..  ..   ...   ...   ...   ...   ...   ...   ...   ...  ...  ..  ..  ..   \n",
       "245   1   2   638   307     0     0     0     0     0     0  ...   0   0   0   \n",
       "246   1   6  1014   130  2594   650   891   110     0     0  ...   0   0   0   \n",
       "247   1   3   659  3845   166     0     0     0     0     0  ...   0   0   0   \n",
       "248   0   7  1316    77   491    87   295  1573  1317     0  ...   0   0   0   \n",
       "249   0   2    54   182     0     0     0     0     0     0  ...   0   0   0   \n",
       "\n",
       "     34  35  36        37      38  39  40  \n",
       "0     0   0   0  0.925069  0.5000   0   1  \n",
       "1     0   0   0  0.504721  0.5000   0   1  \n",
       "2     0   0   0  0.690813  0.5000   0   1  \n",
       "3     0   0   0  0.023109  0.7145   1   0  \n",
       "4     0   0   0  0.504735  0.5000   1   0  \n",
       "..   ..  ..  ..       ...     ...  ..  ..  \n",
       "245   0   0   0  0.504905  0.5000   0   1  \n",
       "246   0   0   0  0.054515  0.5000   0   1  \n",
       "247   0   0   0  0.504756  0.5000   0   1  \n",
       "248   0   0   0  0.740318  0.5000   0   1  \n",
       "249   0   0   0  0.504763  0.5000   0   1  \n",
       "\n",
       "[250 rows x 41 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, epochs, optimizer, loss_fn, device):\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:         \n",
    "            batch_X, batch_y = batch\n",
    "            \n",
    "            batch_X = batch_X.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            \n",
    "            # TODO: Complete this train method to train the model provided.\n",
    "            \n",
    "            model.zero_grad()\n",
    "            out = model.forward(batch_X)\n",
    "            loss = loss_fn(out, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.data.item()\n",
    "        print(\"Epoch: {}, BCELoss: {}\".format(epoch, total_loss / len(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, BCELoss: 0.7210792899131775\n",
      "Epoch: 2, BCELoss: 0.6253195226192474\n",
      "Epoch: 3, BCELoss: 0.23061177134513855\n",
      "Epoch: 4, BCELoss: 0.04597589038312435\n",
      "Epoch: 5, BCELoss: 0.027057170635089278\n",
      "Epoch: 6, BCELoss: 0.026592067151796073\n",
      "Epoch: 7, BCELoss: 0.02063548897858709\n",
      "Epoch: 8, BCELoss: 0.019495148153509945\n",
      "Epoch: 9, BCELoss: 0.018729735747911036\n",
      "Epoch: 10, BCELoss: 0.018407561254571193\n",
      "Epoch: 11, BCELoss: 0.01790951153379865\n",
      "Epoch: 12, BCELoss: 0.017621355669689365\n",
      "Epoch: 13, BCELoss: 0.017465300763433333\n",
      "Epoch: 14, BCELoss: 0.017369585210690274\n",
      "Epoch: 15, BCELoss: 0.017310022706806195\n",
      "Epoch: 16, BCELoss: 0.017251509208290373\n",
      "Epoch: 17, BCELoss: 0.01719156670733355\n",
      "Epoch: 18, BCELoss: 0.017139749178022613\n",
      "Epoch: 19, BCELoss: 0.017100911092711613\n",
      "Epoch: 20, BCELoss: 0.017075949974241666\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from train.model import LSTMClassifier\n",
    "\n",
    "torch.manual_seed(1)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LSTMClassifier(35, 100, 5000).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.05 )\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "\n",
    "train(model, train_sample_dl, 20, optimizer, loss_fn, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I created the Pytorch estimator, the hyperparameters chosen were select according with similar problem results found in the literature, but in the last section of the coumente were calibrated using a drid search and cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(entry_point=\"train.py\",\n",
    "                    source_dir=\"train\",\n",
    "                    role=role,\n",
    "                    framework_version='0.4.0',\n",
    "                    py_version='py3',\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type='ml.p2.xlarge',\n",
    "                    hyperparameters={\n",
    "                        'epochs': 15,\n",
    "                        'hidden_dim': 100,\n",
    "                    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I train the model with the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-10 12:45:55 Starting - Starting the training job...\n",
      "2020-11-10 12:45:56 Starting - Launching requested ML instances......\n",
      "2020-11-10 12:47:00 Starting - Preparing the instances for training......\n",
      "2020-11-10 12:48:19 Downloading - Downloading input data...\n",
      "2020-11-10 12:48:54 Training - Downloading the training image...\n",
      "2020-11-10 12:49:24 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-11-10 12:49:25,581 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-11-10 12:49:25,607 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-11-10 12:49:27,034 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-11-10 12:49:27,277 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-11-10 12:49:27,277 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-11-10 12:49:27,277 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-11-10 12:49:27,277 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pip install -U . -r requirements.txt\u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mCollecting pandas (from -r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/74/24/0cdbf8907e1e3bc5a8da03345c23cbed7044330bb8f73bb12e711a640a00/pandas-0.24.2-cp35-cp35m-manylinux1_x86_64.whl (10.0MB)\u001b[0m\n",
      "\u001b[34mCollecting numpy (from -r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/b5/36/88723426b4ff576809fec7d73594fe17a35c27f8d01f93637637a29ae25b/numpy-1.18.5-cp35-cp35m-manylinux1_x86_64.whl (19.9MB)\u001b[0m\n",
      "\u001b[34mCollecting nltk (from -r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\u001b[0m\n",
      "\u001b[34mCollecting beautifulsoup4 (from -r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/41/e6495bd7d3781cee623ce23ea6ac73282a373088fcd0ddc809a047b18eae/beautifulsoup4-4.9.3-py3-none-any.whl (115kB)\u001b[0m\n",
      "\u001b[34mCollecting html5lib (from -r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/6c/dd/a834df6482147d48e225a49515aabc28974ad5a4ca3215c18a882565b028/html5lib-1.1-py2.py3-none-any.whl (112kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /usr/local/lib/python3.5/dist-packages (from pandas->-r requirements.txt (line 1)) (2.7.5)\u001b[0m\n",
      "\u001b[34mCollecting pytz>=2011k (from pandas->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/12/f8/ff09af6ff61a3efaad5f61ba5facdf17e7722c4393f7d8a66674d2dbd29f/pytz-2020.4-py2.py3-none-any.whl (509kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.5/dist-packages (from nltk->-r requirements.txt (line 3)) (7.0)\u001b[0m\n",
      "\u001b[34mCollecting joblib (from nltk->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/28/5c/cf6a2b65a321c4a209efcdf64c2689efae2cb62661f8f6f4bb28547cf1bf/joblib-0.14.1-py2.py3-none-any.whl (294kB)\u001b[0m\n",
      "\u001b[34mCollecting regex (from nltk->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34m  Downloading https://files.pythonhosted.org/packages/fb/ef/8880ca0f2bc2e51a39aacf62a81947971aea42b3b54ca58111b5a5ba6e05/regex-2020.10.28.tar.gz (694kB)\u001b[0m\n",
      "\u001b[34mCollecting tqdm (from nltk->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/93/3a/96b3dc293aa72443cf9627444c3c221a7ba34bb622e4d8bf1b5d4f2d9d08/tqdm-4.51.0-py2.py3-none-any.whl (70kB)\u001b[0m\n",
      "\u001b[34mCollecting soupsieve>1.2; python_version >= \"3.0\" (from beautifulsoup4->-r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34m  Downloading https://files.pythonhosted.org/packages/6f/8f/457f4a5390eeae1cc3aeab89deb7724c965be841ffca6cfca9197482e470/soupsieve-2.0.1-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mCollecting webencodings (from html5lib->-r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/f4/24/2a3e3df732393fed8b3ebf2ec078f05546de641fe1b667ee316ec1dcf3b7/webencodings-0.5.1-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: six>=1.9 in /usr/local/lib/python3.5/dist-packages (from html5lib->-r requirements.txt (line 5)) (1.11.0)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: nltk, train, regex\n",
      "  Running setup.py bdist_wheel for nltk: started\n",
      "  Running setup.py bdist_wheel for nltk: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for train: started\n",
      "  Running setup.py bdist_wheel for train: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-42s6v1i6/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\n",
      "  Running setup.py bdist_wheel for regex: started\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for regex: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/16/32/f2/87817e06026bddd4f4f63c497c1c9587c028bdf57485e52e0f\u001b[0m\n",
      "\u001b[34mSuccessfully built nltk train regex\u001b[0m\n",
      "\u001b[34mInstalling collected packages: numpy, pytz, pandas, joblib, regex, tqdm, nltk, soupsieve, beautifulsoup4, webencodings, html5lib, train\n",
      "  Found existing installation: numpy 1.15.4\n",
      "    Uninstalling numpy-1.15.4:\n",
      "      Successfully uninstalled numpy-1.15.4\u001b[0m\n",
      "\u001b[34mSuccessfully installed beautifulsoup4-4.9.3 html5lib-1.1 joblib-0.14.1 nltk-3.5 numpy-1.18.5 pandas-0.24.2 pytz-2020.4 regex-2020.10.28 soupsieve-2.0.1 tqdm-4.51.0 train-1.0.0 webencodings-0.5.1\u001b[0m\n",
      "\u001b[34mYou are using pip version 18.1, however version 20.3b1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-11-10 12:49:50,291 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-10-12-45-54-874/source/sourcedir.tar.gz\",\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"job_name\": \"sagemaker-pytorch-2020-11-10-12-45-54-874\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\",\n",
      "            \"TrainingInputMode\": \"File\"\n",
      "        }\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"num_cpus\": 4,\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"log_level\": 20,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"hyperparameters\": {\n",
      "        \"hidden_dim\": 100,\n",
      "        \"epochs\": 15\n",
      "    },\n",
      "    \"module_name\": \"train\",\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=15\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":15,\"hidden_dim\":100}\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":15,\"hidden_dim\":100},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"job_name\":\"sagemaker-pytorch-2020-11-10-12-45-54-874\",\"log_level\":20,\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-10-12-45-54-874/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"15\",\"--hidden_dim\",\"100\"]\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-10-12-45-54-874/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/lib/python35.zip:/usr/lib/python3.5:/usr/lib/python3.5/plat-x86_64-linux-gnu:/usr/lib/python3.5/lib-dynload:/usr/local/lib/python3.5/dist-packages:/usr/lib/python3/dist-packages\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN_DIM=100\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m train --epochs 15 --hidden_dim 100\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing device cuda.\u001b[0m\n",
      "\u001b[34mGet train data loader.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mModel loaded with embedding_dim 35, hidden_dim 100, vocab_size 5000.\u001b[0m\n",
      "\u001b[34mEpoch: 1, BCELoss: 0.6667190194129944\u001b[0m\n",
      "\u001b[34mEpoch: 2, BCELoss: 0.4784893908283927\u001b[0m\n",
      "\u001b[34mEpoch: 3, BCELoss: 0.28363124484365637\u001b[0m\n",
      "\u001b[34mEpoch: 4, BCELoss: 0.13582424006678842\u001b[0m\n",
      "\u001b[34mEpoch: 5, BCELoss: 0.07632480764930899\u001b[0m\n",
      "\u001b[34mEpoch: 6, BCELoss: 0.05438657951625911\u001b[0m\n",
      "\u001b[34mEpoch: 7, BCELoss: 0.049250575798478996\u001b[0m\n",
      "\u001b[34mEpoch: 8, BCELoss: 0.04602062092585997\u001b[0m\n",
      "\u001b[34mEpoch: 9, BCELoss: 0.04170106876302849\u001b[0m\n",
      "\u001b[34mEpoch: 10, BCELoss: 0.041089638051661576\u001b[0m\n",
      "\u001b[34mEpoch: 11, BCELoss: 0.039924177933822975\u001b[0m\n",
      "\u001b[34mEpoch: 12, BCELoss: 0.03944244642149319\u001b[0m\n",
      "\u001b[34mEpoch: 13, BCELoss: 0.039317225190726196\u001b[0m\n",
      "\u001b[34mEpoch: 14, BCELoss: 0.03904684700749137\u001b[0m\n",
      "\u001b[34mEpoch: 15, BCELoss: 0.03896623697470535\u001b[0m\n",
      "\u001b[34m2020-11-10 12:49:59,105 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-11-10 12:50:07 Uploading - Uploading generated training model\n",
      "2020-11-10 12:50:07 Completed - Training job completed\n",
      "Training seconds: 108\n",
      "Billable seconds: 108\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({'training': input_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I transformed the test data in order of being in the same format as the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2=pd.read_csv('Data/Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_test_data(data):\n",
    "    new_data=pd.DataFrame()\n",
    "    cont=0\n",
    "    for lista in data['bow_traducido']:\n",
    "        res = lista.strip('][').split(', ')\n",
    "        cont+=1\n",
    "        a1=pd.DataFrame([res])\n",
    "        new_data=pd.concat([new_data,a1])\n",
    "    \n",
    "    new_data=new_data.iloc[:,0:35]\n",
    "    new_data=new_data.reset_index().drop('index', axis=1)\n",
    "    return new_data\n",
    "\n",
    "def flujo_completo(data):\n",
    "    data['ortog']=data['Ortografia'].apply(lambda x: 0 if not x else 1)\n",
    "    data['emoji_sent_transf']=data.emoji_sentiment.fillna(0.5)\n",
    "    data['have_emojis']=data['emoji_sentiment'].apply(lambda x: 0 if str(x)=='nan' else 1)\n",
    "    other_x_data=data[['spanish_sentiment', 'emoji_sent_transf','have_emojis','ortog']]\n",
    "    new_data=transform_test_data(data)\n",
    "    final_data_train=pd.concat([data['bow_length'], new_data,\n",
    "          other_x_data], axis=1)\n",
    "    return final_data_train\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=flujo_completo(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I created the model based on Pytorch model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing PyTorchModel\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "# Create a model from the trained estimator data\n",
    "# And point to the prediction script\n",
    "model = PyTorchModel(model_data=estimator.model_data,\n",
    "                     role = role,\n",
    "                     framework_version='1.0',\n",
    "                     entry_point='predict.py',\n",
    "                     source_dir='serve',\n",
    "                     py_version='py3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After cerating the model I deploy it with Sagemaker to check the performance and predict based on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "predictor=model.deploy(initial_instance_count = 1, instance_type = 'ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, rows=512):\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = np.array([])\n",
    "    for array in split_array:\n",
    "        predictions = np.append(predictions, predictor.predict(array.astype('float32')))\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.27172708e-05, 5.62620699e-01, 3.56682518e-04, 5.63186258e-02,\n",
       "       9.58132386e-01, 9.97268081e-01, 5.62620699e-01, 2.91791081e-01,\n",
       "       9.98697877e-01, 3.06675196e-01, 7.81844556e-01, 8.19633933e-05,\n",
       "       5.28541059e-05, 9.99761283e-01, 9.97986436e-01, 7.34593850e-05,\n",
       "       5.62620699e-01, 9.99830365e-01, 1.74692494e-03, 9.97928143e-01,\n",
       "       9.99966383e-01, 2.59495378e-01, 9.99996066e-01, 9.97914851e-01,\n",
       "       6.10900283e-01, 2.12608871e-11, 9.99478161e-01, 9.19653893e-01,\n",
       "       4.21647076e-03, 6.42281375e-04, 9.86853004e-01, 8.71281922e-01,\n",
       "       9.85355928e-06, 9.98960733e-01, 1.41616794e-03, 5.48580848e-03,\n",
       "       3.25330358e-04, 1.47736146e-05, 1.78627147e-06, 9.99975324e-01,\n",
       "       4.40287381e-01, 9.97980893e-01, 5.20334695e-04, 1.44310937e-08,\n",
       "       2.23039862e-07, 9.99920964e-01, 3.06675196e-01, 9.62875143e-04,\n",
       "       9.99998569e-01, 9.99761641e-01, 1.89174425e-05, 2.30848582e-05,\n",
       "       2.64645973e-06, 8.99390280e-01, 4.24380321e-03, 9.99869466e-01,\n",
       "       9.99977827e-01, 2.75737752e-04, 6.85332285e-04, 1.03693304e-03,\n",
       "       9.99863982e-01, 1.64355990e-02, 4.50077623e-01, 1.96118176e-01,\n",
       "       3.97854671e-02, 6.53018415e-01, 8.23873506e-06, 9.98464823e-01,\n",
       "       6.42040670e-02, 1.65314472e-04, 9.88687515e-01, 1.06402058e-05,\n",
       "       1.70605941e-04, 5.58487559e-03, 9.99983668e-01, 3.19321686e-07,\n",
       "       1.00000000e+00, 5.62620699e-01, 2.36716098e-03, 8.32478327e-05,\n",
       "       7.18574151e-02, 2.45469346e-06, 9.99985695e-01, 9.62532341e-01,\n",
       "       9.82136786e-01, 6.99152025e-08, 8.30508710e-04, 9.99988556e-01,\n",
       "       7.23935431e-03, 9.99999881e-01, 7.78633296e-01, 7.19810545e-01,\n",
       "       2.79928267e-01, 9.88666296e-01, 1.96385343e-04, 1.00000000e+00,\n",
       "       3.06675196e-01, 9.99993682e-01, 1.30860462e-06, 1.03579706e-03,\n",
       "       5.62620699e-01, 3.58649939e-01, 2.37214100e-03, 9.92467225e-01,\n",
       "       7.12775052e-01, 9.99999285e-01, 5.22966981e-01, 6.06685996e-01,\n",
       "       3.46517282e-07, 3.06675196e-01, 9.48688388e-01, 9.99999285e-01,\n",
       "       5.62620699e-01, 9.92851257e-01, 1.00000000e+00, 1.00000000e+00,\n",
       "       9.93930817e-01, 1.65764883e-01, 2.87869483e-01, 2.16469689e-10,\n",
       "       1.00000000e+00, 9.99977350e-01, 8.50252807e-01, 6.46560133e-01,\n",
       "       4.80976421e-04, 2.42437105e-04, 9.99993563e-01, 5.94467632e-02,\n",
       "       3.06675196e-01, 7.55529523e-01, 6.81704137e-07, 8.13082218e-01,\n",
       "       9.99871850e-01, 1.08284871e-06, 1.47352088e-02, 5.01828210e-04,\n",
       "       2.65833052e-07, 4.65129055e-02, 9.99999166e-01, 9.97389734e-01,\n",
       "       5.57962514e-04, 9.99999881e-01, 2.63634234e-08, 9.99854565e-01,\n",
       "       1.47938444e-08, 8.74467194e-04, 9.98066843e-01, 6.53956833e-10,\n",
       "       2.89535761e-04, 6.53018415e-01, 8.83649528e-01, 1.18693424e-04,\n",
       "       5.26435435e-01, 3.38593721e-02, 8.82806489e-04, 4.17449232e-03,\n",
       "       1.38973643e-04, 9.99988317e-01, 1.01982458e-07, 3.06675196e-01,\n",
       "       9.99996543e-01, 3.02831322e-04, 2.54053026e-01, 2.07333102e-07,\n",
       "       2.50059426e-01, 4.99663413e-01, 9.98993337e-01, 5.06178379e-01,\n",
       "       8.97219658e-01, 8.21064651e-01, 9.99993801e-01, 9.99624372e-01,\n",
       "       9.68516052e-01, 9.99999285e-01, 1.40785033e-07, 9.89044309e-01,\n",
       "       9.99999881e-01, 3.06675196e-01, 3.88326127e-09, 1.97528787e-02,\n",
       "       4.42747369e-05, 9.99426007e-01, 3.28414850e-02, 4.75503981e-01,\n",
       "       9.99999762e-01, 9.99999881e-01, 4.75856721e-01, 4.85672763e-06,\n",
       "       1.00000000e+00, 9.71058488e-01, 3.78768600e-04, 1.87825377e-03,\n",
       "       9.99996901e-01, 4.00112942e-03, 5.75281389e-04, 2.99046660e-05,\n",
       "       3.10165286e-01, 1.00000000e+00, 4.54041004e-01, 7.04802165e-04,\n",
       "       6.70733452e-01, 9.99999523e-01, 9.96263325e-01, 9.99999285e-01,\n",
       "       5.36656044e-02, 4.88363594e-01, 9.57152724e-01, 9.91712809e-01,\n",
       "       1.92838127e-03, 9.99840140e-01, 2.97062704e-03, 5.26709914e-01,\n",
       "       6.31467402e-01, 3.53038195e-04, 6.23186529e-01, 1.40576049e-06,\n",
       "       6.79614365e-01, 9.99999762e-01, 9.98311639e-01, 9.98065054e-01,\n",
       "       8.18952024e-01, 3.59141260e-01, 9.40806806e-01, 9.28539097e-01,\n",
       "       6.46168768e-01, 9.98827755e-01, 1.00821296e-06, 9.99985099e-01,\n",
       "       1.00000000e+00, 5.62620699e-01, 9.00134981e-01, 6.26022875e-01,\n",
       "       6.93551973e-02, 1.87133580e-01, 9.99374211e-01, 5.84909925e-04,\n",
       "       9.99987006e-01, 3.06675196e-01, 6.87317399e-04, 9.97111797e-01,\n",
       "       3.95648357e-07, 8.75776827e-01, 8.62837944e-04, 3.45586304e-04,\n",
       "       7.06613343e-03, 3.33865898e-07, 1.69766812e-10, 9.99999285e-01,\n",
       "       2.57845727e-07, 7.79258668e-01, 1.36256776e-05, 5.62620699e-01,\n",
       "       9.96408165e-01, 7.46053364e-03, 9.94036436e-01, 1.65636744e-03,\n",
       "       1.52887270e-01, 9.17948902e-01, 9.99916792e-01, 9.69746616e-03,\n",
       "       6.18413603e-03, 1.38632117e-07, 7.93172538e-01, 2.48279619e-08,\n",
       "       1.53289790e-08, 5.42329683e-04, 5.68380713e-01, 1.00000000e+00,\n",
       "       9.97719347e-01, 2.09505833e-05, 1.56023949e-01, 9.99866605e-01,\n",
       "       3.06675196e-01, 9.99999404e-01, 9.99065697e-01, 9.99999404e-01,\n",
       "       9.97513652e-01, 2.01025099e-01, 9.99439418e-01, 1.65738413e-04,\n",
       "       1.19628955e-03, 2.73360683e-06, 9.18834507e-01, 2.12507099e-02,\n",
       "       5.63509559e-07, 9.99821126e-01, 3.42225358e-02, 3.76342982e-01,\n",
       "       7.15784967e-01, 9.57734764e-01, 9.99999166e-01, 2.38524533e-09,\n",
       "       1.18946275e-08, 1.63350905e-05, 1.21299930e-01, 9.99999762e-01,\n",
       "       8.61601438e-05, 9.99999642e-01, 1.65559559e-05, 6.48586035e-01,\n",
       "       2.35398374e-02, 9.97413576e-01, 6.73551384e-08, 1.27016264e-03,\n",
       "       9.98726308e-01, 9.99938846e-01, 5.80402193e-05, 6.88427866e-01,\n",
       "       1.55200005e-01, 3.18203893e-05, 2.89207906e-01, 9.98479068e-01,\n",
       "       2.87612893e-05, 1.08399281e-05, 9.39948380e-01, 1.00000000e+00,\n",
       "       3.48840331e-06, 9.96702731e-01, 5.66182367e-04, 8.59008543e-03,\n",
       "       9.96063054e-01, 8.08984220e-01, 1.33350695e-04, 1.66706275e-02,\n",
       "       9.99300003e-01, 5.62620699e-01, 1.33555576e-01, 8.72154534e-02,\n",
       "       9.24468040e-08, 2.47980170e-05, 1.02469278e-08, 3.48832428e-01,\n",
       "       9.99123633e-01, 5.56301748e-05, 8.26567784e-03, 2.07448632e-01,\n",
       "       9.99998450e-01, 5.62620699e-01, 4.95391578e-06, 8.43794364e-03,\n",
       "       8.36028562e-07, 3.06675196e-01, 7.78134250e-08, 6.36553523e-05,\n",
       "       9.99993801e-01, 1.00349449e-02, 5.37069924e-02, 9.97634530e-01,\n",
       "       9.99493957e-01, 9.87198473e-06, 2.00343155e-03, 8.94547403e-02,\n",
       "       9.60160911e-01, 9.99999881e-01, 1.71376654e-04, 7.44282858e-09,\n",
       "       3.20311725e-01, 4.84554050e-03, 9.99632239e-01, 9.99996901e-01,\n",
       "       1.30614831e-06, 5.28460890e-02, 1.00000000e+00, 5.62620699e-01,\n",
       "       7.77949035e-01, 1.62087986e-03, 1.88254253e-05, 9.99955773e-01,\n",
       "       9.79854882e-01, 9.15162265e-01, 9.31958079e-01, 1.87037585e-04,\n",
       "       8.45712260e-04, 5.67258261e-02, 1.95122603e-03, 9.99995232e-01,\n",
       "       9.99963284e-01, 1.26211054e-03, 3.68853274e-04, 1.41011979e-02,\n",
       "       3.43515165e-02, 9.99963760e-01, 9.20242030e-07, 2.37213189e-05,\n",
       "       5.81663277e-04, 4.07724583e-05, 8.92862260e-01, 1.87637568e-07,\n",
       "       9.35752571e-01, 9.95769799e-01, 1.76573787e-02, 3.16327929e-01,\n",
       "       5.62620699e-01, 2.78829336e-02, 1.96629742e-07, 4.20881297e-05,\n",
       "       9.64141011e-01, 1.03630831e-04, 9.99998808e-01, 3.58907891e-05,\n",
       "       1.79688575e-09, 9.99999285e-01, 1.68666379e-08, 7.98317730e-01,\n",
       "       8.82806489e-04, 1.35133266e-02, 2.26605251e-01, 9.78657782e-01,\n",
       "       8.88431623e-06, 9.99960542e-01, 1.66307692e-03, 3.19799183e-05,\n",
       "       9.99987960e-01, 1.02928560e-03, 5.26991425e-05, 1.17425509e-01,\n",
       "       1.04309576e-04, 8.84111226e-01, 1.64575949e-01, 9.80405033e-01,\n",
       "       9.99993801e-01, 3.65052699e-09, 9.99103963e-01, 9.99990702e-01,\n",
       "       2.99969048e-04, 1.33839231e-02, 1.20740615e-05, 2.12082739e-07,\n",
       "       5.31654507e-08, 1.49443233e-03, 3.44126543e-04, 9.99988794e-01,\n",
       "       1.20542438e-07, 1.87249482e-02, 1.19281697e-06, 9.77814376e-01,\n",
       "       8.89887035e-01, 3.94566745e-01, 9.54653263e-01, 2.55966163e-03,\n",
       "       5.75417944e-04, 9.99990106e-01, 5.65667051e-08, 9.99996066e-01,\n",
       "       9.98930275e-01, 7.07986718e-03, 1.26724774e-02, 4.61557835e-01,\n",
       "       3.74747247e-01, 9.99678493e-01, 4.99619953e-02, 9.98351574e-01,\n",
       "       9.93407011e-01, 7.43643522e-01, 5.14097010e-05], dtype=float32)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " predictor.predict(array.astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=predict(test_data, rows=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=data2['ingresos'].apply(lambda x: 0 if x=='Bajos' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I calculate the AUC achieven an AUC of 0.79."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7855582430423688"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test.to_numpy(), predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_roc(y,pred):\n",
    "    import matplotlib.pyplot as plt\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y, pred)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I graphed the ROC curve in the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph_roc(y_test.to_numpy(), predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always is a good idea to delete the endpoint to not be charged more time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accepts a predictor endpoint as input\n",
    "# And deletes the endpoint by name\n",
    "import boto3\n",
    "def delete_endpoint(predictor):\n",
    "        try:\n",
    "            boto3.client('sagemaker').delete_endpoint(EndpointName=predictor.endpoint)\n",
    "            print('Deleted {}'.format(predictor.endpoint))\n",
    "        except:\n",
    "            print('Already deleted: {}'.format(predictor.endpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already deleted: sagemaker-pytorch-2020-11-10-21-14-02-644\n"
     ]
    }
   ],
   "source": [
    "delete_endpoint(predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I made a grid search with 3CV to calibrate the number of epochs and the number of neurons in the hidden dimension.\n",
    "To save time I only proved the grid search changing the epochs with possible values 15 and 50, and changing the hidden dimension of the layer with possible values: 10, 100, 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_train=pd.read_csv(data_dir+'train.csv', header=None)\n",
    "from sklearn.model_selection import KFold\n",
    "kf=KFold(3,shuffle=True,random_state=10000)\n",
    "info_modelo={}\n",
    "contar=0\n",
    "for train_index, test_index in kf.split(final_data_train):\n",
    "        contar+=1\n",
    "        X_train, X_test = final_data_train.loc[train_index], final_data_train.loc[test_index]\n",
    "        info_actual={'x_train':X_train,'x_test':X_test}\n",
    "        info_modelo.update({contar:info_actual})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcularvalores(num,info_modelo):\n",
    "    diccionario_actual=info_modelo[num]\n",
    "    X_train=diccionario_actual['x_train']\n",
    "    X_test=diccionario_actual['x_test'].iloc[:,1:]\n",
    "    y_test=diccionario_actual['x_test'].iloc[:,0]\n",
    "    return X_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-11 11:54:59 Starting - Starting the training job...\n",
      "2020-11-11 11:55:02 Starting - Launching requested ML instances......\n",
      "2020-11-11 11:56:25 Starting - Preparing the instances for training.........\n",
      "2020-11-11 11:57:46 Downloading - Downloading input data...\n",
      "2020-11-11 11:58:23 Training - Downloading the training image...\n",
      "2020-11-11 11:58:52 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-11-11 11:58:53,333 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-11-11 11:58:53,358 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-11-11 11:58:54,772 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-11-11 11:58:55,014 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-11-11 11:58:55,014 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-11-11 11:58:55,014 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-11-11 11:58:55,014 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pip install -U . -r requirements.txt\u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mCollecting pandas (from -r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/74/24/0cdbf8907e1e3bc5a8da03345c23cbed7044330bb8f73bb12e711a640a00/pandas-0.24.2-cp35-cp35m-manylinux1_x86_64.whl (10.0MB)\u001b[0m\n",
      "\u001b[34mCollecting numpy (from -r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34m  Downloading https://files.pythonhosted.org/packages/b5/36/88723426b4ff576809fec7d73594fe17a35c27f8d01f93637637a29ae25b/numpy-1.18.5-cp35-cp35m-manylinux1_x86_64.whl (19.9MB)\u001b[0m\n",
      "\u001b[34mCollecting nltk (from -r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\u001b[0m\n",
      "\u001b[34mCollecting beautifulsoup4 (from -r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/41/e6495bd7d3781cee623ce23ea6ac73282a373088fcd0ddc809a047b18eae/beautifulsoup4-4.9.3-py3-none-any.whl (115kB)\u001b[0m\n",
      "\u001b[34mCollecting html5lib (from -r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/6c/dd/a834df6482147d48e225a49515aabc28974ad5a4ca3215c18a882565b028/html5lib-1.1-py2.py3-none-any.whl (112kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /usr/local/lib/python3.5/dist-packages (from pandas->-r requirements.txt (line 1)) (2.7.5)\u001b[0m\n",
      "\u001b[34mCollecting pytz>=2011k (from pandas->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34m  Downloading https://files.pythonhosted.org/packages/12/f8/ff09af6ff61a3efaad5f61ba5facdf17e7722c4393f7d8a66674d2dbd29f/pytz-2020.4-py2.py3-none-any.whl (509kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.5/dist-packages (from nltk->-r requirements.txt (line 3)) (7.0)\u001b[0m\n",
      "\u001b[34mCollecting joblib (from nltk->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/28/5c/cf6a2b65a321c4a209efcdf64c2689efae2cb62661f8f6f4bb28547cf1bf/joblib-0.14.1-py2.py3-none-any.whl (294kB)\u001b[0m\n",
      "\u001b[34mCollecting regex (from nltk->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/fb/ef/8880ca0f2bc2e51a39aacf62a81947971aea42b3b54ca58111b5a5ba6e05/regex-2020.10.28.tar.gz (694kB)\u001b[0m\n",
      "\u001b[34mCollecting tqdm (from nltk->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/93/3a/96b3dc293aa72443cf9627444c3c221a7ba34bb622e4d8bf1b5d4f2d9d08/tqdm-4.51.0-py2.py3-none-any.whl (70kB)\u001b[0m\n",
      "\u001b[34mCollecting soupsieve>1.2; python_version >= \"3.0\" (from beautifulsoup4->-r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/6f/8f/457f4a5390eeae1cc3aeab89deb7724c965be841ffca6cfca9197482e470/soupsieve-2.0.1-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mCollecting webencodings (from html5lib->-r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/f4/24/2a3e3df732393fed8b3ebf2ec078f05546de641fe1b667ee316ec1dcf3b7/webencodings-0.5.1-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: six>=1.9 in /usr/local/lib/python3.5/dist-packages (from html5lib->-r requirements.txt (line 5)) (1.11.0)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: nltk, train, regex\n",
      "  Running setup.py bdist_wheel for nltk: started\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for nltk: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n",
      "  Running setup.py bdist_wheel for train: started\n",
      "  Running setup.py bdist_wheel for train: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-koio37lz/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\n",
      "  Running setup.py bdist_wheel for regex: started\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for regex: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/16/32/f2/87817e06026bddd4f4f63c497c1c9587c028bdf57485e52e0f\u001b[0m\n",
      "\u001b[34mSuccessfully built nltk train regex\u001b[0m\n",
      "\u001b[34mInstalling collected packages: numpy, pytz, pandas, joblib, regex, tqdm, nltk, soupsieve, beautifulsoup4, webencodings, html5lib, train\n",
      "  Found existing installation: numpy 1.15.4\n",
      "    Uninstalling numpy-1.15.4:\u001b[0m\n",
      "\u001b[34m      Successfully uninstalled numpy-1.15.4\u001b[0m\n",
      "\n",
      "2020-11-11 11:59:28 Uploading - Uploading generated training model\u001b[34mSuccessfully installed beautifulsoup4-4.9.3 html5lib-1.1 joblib-0.14.1 nltk-3.5 numpy-1.18.5 pandas-0.24.2 pytz-2020.4 regex-2020.10.28 soupsieve-2.0.1 tqdm-4.51.0 train-1.0.0 webencodings-0.5.1\u001b[0m\n",
      "\u001b[34mYou are using pip version 18.1, however version 20.3b1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-11-11 11:59:18,186 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"log_level\": 20,\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_gpus\": 1,\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"RecordWrapperType\": \"None\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\"\n",
      "        }\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"resource_config\": {\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"job_name\": \"sagemaker-pytorch-2020-11-11-11-54-59-482\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hyperparameters\": {\n",
      "        \"hidden_dim\": 10,\n",
      "        \"epochs\": 15\n",
      "    },\n",
      "    \"module_name\": \"train\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-11-11-54-59-482/source/sourcedir.tar.gz\",\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"15\",\"--hidden_dim\",\"10\"]\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN_DIM=10\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=15\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":15,\"hidden_dim\":10}\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/lib/python35.zip:/usr/lib/python3.5:/usr/lib/python3.5/plat-x86_64-linux-gnu:/usr/lib/python3.5/lib-dynload:/usr/local/lib/python3.5/dist-packages:/usr/lib/python3/dist-packages\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":15,\"hidden_dim\":10},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"job_name\":\"sagemaker-pytorch-2020-11-11-11-54-59-482\",\"log_level\":20,\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-11-11-54-59-482/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-11-11-54-59-482/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m train --epochs 15 --hidden_dim 10\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing device cuda.\u001b[0m\n",
      "\u001b[34mGet train data loader.\u001b[0m\n",
      "\u001b[34mModel loaded with embedding_dim 35, hidden_dim 10, vocab_size 5000.\u001b[0m\n",
      "\u001b[34mEpoch: 1, BCELoss: 0.6495233449068937\u001b[0m\n",
      "\u001b[34mEpoch: 2, BCELoss: 0.43837050145322626\u001b[0m\n",
      "\u001b[34mEpoch: 3, BCELoss: 0.25550691377032886\u001b[0m\n",
      "\u001b[34mEpoch: 4, BCELoss: 0.16303673996166748\u001b[0m\n",
      "\u001b[34mEpoch: 5, BCELoss: 0.11842383173379031\u001b[0m\n",
      "\u001b[34mEpoch: 6, BCELoss: 0.09110851314934817\u001b[0m\n",
      "\u001b[34mEpoch: 7, BCELoss: 0.07273957607421008\u001b[0m\n",
      "\u001b[34mEpoch: 8, BCELoss: 0.06245845691724257\u001b[0m\n",
      "\u001b[34mEpoch: 9, BCELoss: 0.0542400638488206\u001b[0m\n",
      "\u001b[34mEpoch: 10, BCELoss: 0.050560817969116295\u001b[0m\n",
      "\u001b[34mEpoch: 11, BCELoss: 0.04798758825795217\u001b[0m\n",
      "\u001b[34mEpoch: 12, BCELoss: 0.04747859727252613\u001b[0m\n",
      "\u001b[34mEpoch: 13, BCELoss: 0.04593367993154309\u001b[0m\n",
      "\u001b[34mEpoch: 14, BCELoss: 0.04505312781442295\u001b[0m\n",
      "\u001b[34mEpoch: 15, BCELoss: 0.043990154157985344\u001b[0m\n",
      "\u001b[34m2020-11-11 11:59:25,191 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-11-11 11:59:35 Completed - Training job completed\n",
      "Training seconds: 109\n",
      "Billable seconds: 109\n",
      "---------------!"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted sagemaker-pytorch-2020-11-11-12-00-12-996\n",
      "2020-11-11 12:07:45 Starting - Starting the training job...\n",
      "2020-11-11 12:07:47 Starting - Launching requested ML instances......\n",
      "2020-11-11 12:08:52 Starting - Preparing the instances for training......\n",
      "2020-11-11 12:10:11 Downloading - Downloading input data......\n",
      "2020-11-11 12:10:58 Training - Downloading the training image.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-11-11 12:11:20,939 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-11-11 12:11:20,963 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-11-11 12:11:21,603 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-11-11 12:11:21,879 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-11-11 12:11:21,880 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-11-11 12:11:21,880 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-11-11 12:11:21,880 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pip install -U . -r requirements.txt\u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mCollecting pandas (from -r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/74/24/0cdbf8907e1e3bc5a8da03345c23cbed7044330bb8f73bb12e711a640a00/pandas-0.24.2-cp35-cp35m-manylinux1_x86_64.whl (10.0MB)\u001b[0m\n",
      "\u001b[34mCollecting numpy (from -r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34m  Downloading https://files.pythonhosted.org/packages/b5/36/88723426b4ff576809fec7d73594fe17a35c27f8d01f93637637a29ae25b/numpy-1.18.5-cp35-cp35m-manylinux1_x86_64.whl (19.9MB)\u001b[0m\n",
      "\u001b[34mCollecting nltk (from -r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\u001b[0m\n",
      "\u001b[34mCollecting beautifulsoup4 (from -r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/41/e6495bd7d3781cee623ce23ea6ac73282a373088fcd0ddc809a047b18eae/beautifulsoup4-4.9.3-py3-none-any.whl (115kB)\u001b[0m\n",
      "\u001b[34mCollecting html5lib (from -r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/6c/dd/a834df6482147d48e225a49515aabc28974ad5a4ca3215c18a882565b028/html5lib-1.1-py2.py3-none-any.whl (112kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /usr/local/lib/python3.5/dist-packages (from pandas->-r requirements.txt (line 1)) (2.7.5)\u001b[0m\n",
      "\u001b[34mCollecting pytz>=2011k (from pandas->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34m  Downloading https://files.pythonhosted.org/packages/12/f8/ff09af6ff61a3efaad5f61ba5facdf17e7722c4393f7d8a66674d2dbd29f/pytz-2020.4-py2.py3-none-any.whl (509kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.5/dist-packages (from nltk->-r requirements.txt (line 3)) (7.0)\u001b[0m\n",
      "\u001b[34mCollecting joblib (from nltk->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/28/5c/cf6a2b65a321c4a209efcdf64c2689efae2cb62661f8f6f4bb28547cf1bf/joblib-0.14.1-py2.py3-none-any.whl (294kB)\u001b[0m\n",
      "\u001b[34mCollecting regex (from nltk->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/fb/ef/8880ca0f2bc2e51a39aacf62a81947971aea42b3b54ca58111b5a5ba6e05/regex-2020.10.28.tar.gz (694kB)\u001b[0m\n",
      "\u001b[34mCollecting tqdm (from nltk->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/93/3a/96b3dc293aa72443cf9627444c3c221a7ba34bb622e4d8bf1b5d4f2d9d08/tqdm-4.51.0-py2.py3-none-any.whl (70kB)\u001b[0m\n",
      "\u001b[34mCollecting soupsieve>1.2; python_version >= \"3.0\" (from beautifulsoup4->-r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/6f/8f/457f4a5390eeae1cc3aeab89deb7724c965be841ffca6cfca9197482e470/soupsieve-2.0.1-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mCollecting webencodings (from html5lib->-r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/f4/24/2a3e3df732393fed8b3ebf2ec078f05546de641fe1b667ee316ec1dcf3b7/webencodings-0.5.1-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: six>=1.9 in /usr/local/lib/python3.5/dist-packages (from html5lib->-r requirements.txt (line 5)) (1.11.0)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: nltk, train, regex\n",
      "  Running setup.py bdist_wheel for nltk: started\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for nltk: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n",
      "  Running setup.py bdist_wheel for train: started\n",
      "  Running setup.py bdist_wheel for train: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-6ct7xeai/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\n",
      "  Running setup.py bdist_wheel for regex: started\u001b[0m\n",
      "\n",
      "2020-11-11 12:11:19 Training - Training image download completed. Training in progress.\u001b[34m  Running setup.py bdist_wheel for regex: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/16/32/f2/87817e06026bddd4f4f63c497c1c9587c028bdf57485e52e0f\u001b[0m\n",
      "\u001b[34mSuccessfully built nltk train regex\u001b[0m\n",
      "\u001b[34mInstalling collected packages: numpy, pytz, pandas, joblib, regex, tqdm, nltk, soupsieve, beautifulsoup4, webencodings, html5lib, train\n",
      "  Found existing installation: numpy 1.15.4\n",
      "    Uninstalling numpy-1.15.4:\u001b[0m\n",
      "\u001b[34m      Successfully uninstalled numpy-1.15.4\u001b[0m\n",
      "\u001b[34mSuccessfully installed beautifulsoup4-4.9.3 html5lib-1.1 joblib-0.14.1 nltk-3.5 numpy-1.18.5 pandas-0.24.2 pytz-2020.4 regex-2020.10.28 soupsieve-2.0.1 tqdm-4.51.0 train-1.0.0 webencodings-0.5.1\u001b[0m\n",
      "\u001b[34mYou are using pip version 18.1, however version 20.3b1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-11-11 12:11:45,518 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"job_name\": \"sagemaker-pytorch-2020-11-11-12-07-45-152\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"network_interface_name\": \"eth0\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ]\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\",\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"log_level\": 20,\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 15,\n",
      "        \"hidden_dim\": 100\n",
      "    },\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"RecordWrapperType\": \"None\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-11-12-07-45-152/source/sourcedir.tar.gz\",\n",
      "    \"num_gpus\": 1,\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"num_cpus\": 4,\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"network_interface_name\": \"eth0\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN_DIM=100\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/lib/python35.zip:/usr/lib/python3.5:/usr/lib/python3.5/plat-x86_64-linux-gnu:/usr/lib/python3.5/lib-dynload:/usr/local/lib/python3.5/dist-packages:/usr/lib/python3/dist-packages\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"15\",\"--hidden_dim\",\"100\"]\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":15,\"hidden_dim\":100},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"job_name\":\"sagemaker-pytorch-2020-11-11-12-07-45-152\",\"log_level\":20,\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-11-12-07-45-152/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-11-12-07-45-152/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":15,\"hidden_dim\":100}\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=15\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m train --epochs 15 --hidden_dim 100\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing device cuda.\u001b[0m\n",
      "\u001b[34mGet train data loader.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mModel loaded with embedding_dim 35, hidden_dim 100, vocab_size 5000.\u001b[0m\n",
      "\u001b[34mEpoch: 1, BCELoss: 0.6667190194129944\u001b[0m\n",
      "\u001b[34mEpoch: 2, BCELoss: 0.4784893908283927\u001b[0m\n",
      "\u001b[34mEpoch: 3, BCELoss: 0.28363124484365637\u001b[0m\n",
      "\u001b[34mEpoch: 4, BCELoss: 0.13582424006678842\u001b[0m\n",
      "\u001b[34mEpoch: 5, BCELoss: 0.07632480764930899\u001b[0m\n",
      "\u001b[34mEpoch: 6, BCELoss: 0.05438657951625911\u001b[0m\n",
      "\u001b[34mEpoch: 7, BCELoss: 0.049250575798478996\u001b[0m\n",
      "\u001b[34mEpoch: 8, BCELoss: 0.04602062092585997\u001b[0m\n",
      "\u001b[34mEpoch: 9, BCELoss: 0.04170106876302849\u001b[0m\n",
      "\u001b[34mEpoch: 10, BCELoss: 0.041089638051661576\u001b[0m\n",
      "\u001b[34mEpoch: 11, BCELoss: 0.039924177933822975\u001b[0m\n",
      "\u001b[34mEpoch: 12, BCELoss: 0.03944244642149319\u001b[0m\n",
      "\u001b[34mEpoch: 13, BCELoss: 0.039317225190726196\u001b[0m\n",
      "\u001b[34mEpoch: 14, BCELoss: 0.03904684700749137\u001b[0m\n",
      "\u001b[34mEpoch: 15, BCELoss: 0.03896623697470535\u001b[0m\n",
      "\u001b[34m2020-11-11 12:11:56,194 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-11-11 12:12:07 Uploading - Uploading generated training model\n",
      "2020-11-11 12:12:07 Completed - Training job completed\n",
      "Training seconds: 116\n",
      "Billable seconds: 116\n",
      "-------------!"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted sagemaker-pytorch-2020-11-11-12-12-28-437\n",
      "2020-11-11 12:19:01 Starting - Starting the training job...\n",
      "2020-11-11 12:19:03 Starting - Launching requested ML instances......\n",
      "2020-11-11 12:20:24 Starting - Preparing the instances for training.........\n",
      "2020-11-11 12:21:40 Downloading - Downloading input data...\n",
      "2020-11-11 12:22:13 Training - Downloading the training image..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-11-11 12:22:45,261 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-11-11 12:22:45,287 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-11-11 12:22:48,310 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-11-11 12:22:48,571 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-11-11 12:22:48,571 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-11-11 12:22:48,572 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-11-11 12:22:48,572 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pip install -U . -r requirements.txt\u001b[0m\n",
      "\n",
      "2020-11-11 12:22:44 Training - Training image download completed. Training in progress.\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mCollecting pandas (from -r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34m  Downloading https://files.pythonhosted.org/packages/74/24/0cdbf8907e1e3bc5a8da03345c23cbed7044330bb8f73bb12e711a640a00/pandas-0.24.2-cp35-cp35m-manylinux1_x86_64.whl (10.0MB)\u001b[0m\n",
      "\u001b[34mCollecting numpy (from -r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/b5/36/88723426b4ff576809fec7d73594fe17a35c27f8d01f93637637a29ae25b/numpy-1.18.5-cp35-cp35m-manylinux1_x86_64.whl (19.9MB)\u001b[0m\n",
      "\u001b[34mCollecting nltk (from -r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\u001b[0m\n",
      "\u001b[34mCollecting beautifulsoup4 (from -r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/41/e6495bd7d3781cee623ce23ea6ac73282a373088fcd0ddc809a047b18eae/beautifulsoup4-4.9.3-py3-none-any.whl (115kB)\u001b[0m\n",
      "\u001b[34mCollecting html5lib (from -r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/6c/dd/a834df6482147d48e225a49515aabc28974ad5a4ca3215c18a882565b028/html5lib-1.1-py2.py3-none-any.whl (112kB)\u001b[0m\n",
      "\u001b[34mCollecting pytz>=2011k (from pandas->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34m  Downloading https://files.pythonhosted.org/packages/12/f8/ff09af6ff61a3efaad5f61ba5facdf17e7722c4393f7d8a66674d2dbd29f/pytz-2020.4-py2.py3-none-any.whl (509kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /usr/local/lib/python3.5/dist-packages (from pandas->-r requirements.txt (line 1)) (2.7.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.5/dist-packages (from nltk->-r requirements.txt (line 3)) (7.0)\u001b[0m\n",
      "\u001b[34mCollecting joblib (from nltk->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/28/5c/cf6a2b65a321c4a209efcdf64c2689efae2cb62661f8f6f4bb28547cf1bf/joblib-0.14.1-py2.py3-none-any.whl (294kB)\u001b[0m\n",
      "\u001b[34mCollecting regex (from nltk->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/fb/ef/8880ca0f2bc2e51a39aacf62a81947971aea42b3b54ca58111b5a5ba6e05/regex-2020.10.28.tar.gz (694kB)\u001b[0m\n",
      "\u001b[34mCollecting tqdm (from nltk->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/93/3a/96b3dc293aa72443cf9627444c3c221a7ba34bb622e4d8bf1b5d4f2d9d08/tqdm-4.51.0-py2.py3-none-any.whl (70kB)\u001b[0m\n",
      "\u001b[34mCollecting soupsieve>1.2; python_version >= \"3.0\" (from beautifulsoup4->-r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/6f/8f/457f4a5390eeae1cc3aeab89deb7724c965be841ffca6cfca9197482e470/soupsieve-2.0.1-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mCollecting webencodings (from html5lib->-r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/f4/24/2a3e3df732393fed8b3ebf2ec078f05546de641fe1b667ee316ec1dcf3b7/webencodings-0.5.1-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: six>=1.9 in /usr/local/lib/python3.5/dist-packages (from html5lib->-r requirements.txt (line 5)) (1.11.0)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: nltk, train, regex\n",
      "  Running setup.py bdist_wheel for nltk: started\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for nltk: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n",
      "  Running setup.py bdist_wheel for train: started\n",
      "  Running setup.py bdist_wheel for train: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-eqh998ji/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\n",
      "  Running setup.py bdist_wheel for regex: started\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for regex: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/16/32/f2/87817e06026bddd4f4f63c497c1c9587c028bdf57485e52e0f\u001b[0m\n",
      "\u001b[34mSuccessfully built nltk train regex\u001b[0m\n",
      "\u001b[34mInstalling collected packages: pytz, numpy, pandas, joblib, regex, tqdm, nltk, soupsieve, beautifulsoup4, webencodings, html5lib, train\n",
      "  Found existing installation: numpy 1.15.4\n",
      "    Uninstalling numpy-1.15.4:\u001b[0m\n",
      "\u001b[34m      Successfully uninstalled numpy-1.15.4\u001b[0m\n",
      "\u001b[34mSuccessfully installed beautifulsoup4-4.9.3 html5lib-1.1 joblib-0.14.1 nltk-3.5 numpy-1.18.5 pandas-0.24.2 pytz-2020.4 regex-2020.10.28 soupsieve-2.0.1 tqdm-4.51.0 train-1.0.0 webencodings-0.5.1\u001b[0m\n",
      "\u001b[34mYou are using pip version 18.1, however version 20.3b1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-11-11 12:23:13,503 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-11-12-19-00-908/source/sourcedir.tar.gz\",\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"resource_config\": {\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"hyperparameters\": {\n",
      "        \"hidden_dim\": 200,\n",
      "        \"epochs\": 15\n",
      "    },\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"user_entry_point\": \"train.py\",\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"job_name\": \"sagemaker-pytorch-2020-11-11-12-19-00-908\",\n",
      "    \"log_level\": 20,\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"num_gpus\": 1,\n",
      "    \"network_interface_name\": \"eth0\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=15\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-11-12-19-00-908/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/lib/python35.zip:/usr/lib/python3.5:/usr/lib/python3.5/plat-x86_64-linux-gnu:/usr/lib/python3.5/lib-dynload:/usr/local/lib/python3.5/dist-packages:/usr/lib/python3/dist-packages\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN_DIM=200\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":15,\"hidden_dim\":200},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"job_name\":\"sagemaker-pytorch-2020-11-11-12-19-00-908\",\"log_level\":20,\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-11-12-19-00-908/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":15,\"hidden_dim\":200}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"15\",\"--hidden_dim\",\"200\"]\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m train --epochs 15 --hidden_dim 200\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing device cuda.\u001b[0m\n",
      "\u001b[34mGet train data loader.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-11-11 12:23:30 Uploading - Uploading generated training model\u001b[34mModel loaded with embedding_dim 35, hidden_dim 200, vocab_size 5000.\u001b[0m\n",
      "\u001b[34mEpoch: 1, BCELoss: 0.7832662029699846\u001b[0m\n",
      "\u001b[34mEpoch: 2, BCELoss: 0.7070528810674493\u001b[0m\n",
      "\u001b[34mEpoch: 3, BCELoss: 0.6470508141951128\u001b[0m\n",
      "\u001b[34mEpoch: 4, BCELoss: 0.5651451295072382\u001b[0m\n",
      "\u001b[34mEpoch: 5, BCELoss: 0.4686794172633778\u001b[0m\n",
      "\u001b[34mEpoch: 6, BCELoss: 0.36375353011217987\u001b[0m\n",
      "\u001b[34mEpoch: 7, BCELoss: 0.2807423905892806\u001b[0m\n",
      "\u001b[34mEpoch: 8, BCELoss: 0.21410149200396103\u001b[0m\n",
      "\u001b[34mEpoch: 9, BCELoss: 0.15948683294382962\u001b[0m\n",
      "\u001b[34mEpoch: 10, BCELoss: 0.11766727268695831\u001b[0m\n",
      "\u001b[34mEpoch: 11, BCELoss: 0.09834169664166191\u001b[0m\n",
      "\u001b[34mEpoch: 12, BCELoss: 0.0865608433430845\u001b[0m\n",
      "\u001b[34mEpoch: 13, BCELoss: 0.0749292912131006\u001b[0m\n",
      "\u001b[34mEpoch: 14, BCELoss: 0.06582087820226495\u001b[0m\n",
      "\u001b[34mEpoch: 15, BCELoss: 0.055926820771260696\u001b[0m\n",
      "\u001b[34m2020-11-11 12:23:27,352 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-11-11 12:23:37 Completed - Training job completed\n",
      "Training seconds: 117\n",
      "Billable seconds: 117\n",
      "---------------!"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted sagemaker-pytorch-2020-11-11-12-24-15-463\n",
      "2020-11-11 12:31:49 Starting - Starting the training job...\n",
      "2020-11-11 12:31:51 Starting - Launching requested ML instances......\n",
      "2020-11-11 12:32:54 Starting - Preparing the instances for training......\n",
      "2020-11-11 12:34:05 Downloading - Downloading input data...\n",
      "2020-11-11 12:34:38 Training - Downloading the training image...\n",
      "2020-11-11 12:35:09 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-11-11 12:35:10,176 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-11-11 12:35:10,203 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-11-11 12:35:16,423 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-11-11 12:35:16,673 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-11-11 12:35:16,673 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-11-11 12:35:16,673 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-11-11 12:35:16,674 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pip install -U . -r requirements.txt\u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mCollecting pandas (from -r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/74/24/0cdbf8907e1e3bc5a8da03345c23cbed7044330bb8f73bb12e711a640a00/pandas-0.24.2-cp35-cp35m-manylinux1_x86_64.whl (10.0MB)\u001b[0m\n",
      "\u001b[34mCollecting numpy (from -r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34m  Downloading https://files.pythonhosted.org/packages/b5/36/88723426b4ff576809fec7d73594fe17a35c27f8d01f93637637a29ae25b/numpy-1.18.5-cp35-cp35m-manylinux1_x86_64.whl (19.9MB)\u001b[0m\n",
      "\u001b[34mCollecting nltk (from -r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\u001b[0m\n",
      "\u001b[34mCollecting beautifulsoup4 (from -r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/41/e6495bd7d3781cee623ce23ea6ac73282a373088fcd0ddc809a047b18eae/beautifulsoup4-4.9.3-py3-none-any.whl (115kB)\u001b[0m\n",
      "\u001b[34mCollecting html5lib (from -r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/6c/dd/a834df6482147d48e225a49515aabc28974ad5a4ca3215c18a882565b028/html5lib-1.1-py2.py3-none-any.whl (112kB)\u001b[0m\n",
      "\u001b[34mCollecting pytz>=2011k (from pandas->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34m  Downloading https://files.pythonhosted.org/packages/12/f8/ff09af6ff61a3efaad5f61ba5facdf17e7722c4393f7d8a66674d2dbd29f/pytz-2020.4-py2.py3-none-any.whl (509kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /usr/local/lib/python3.5/dist-packages (from pandas->-r requirements.txt (line 1)) (2.7.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.5/dist-packages (from nltk->-r requirements.txt (line 3)) (7.0)\u001b[0m\n",
      "\u001b[34mCollecting joblib (from nltk->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/28/5c/cf6a2b65a321c4a209efcdf64c2689efae2cb62661f8f6f4bb28547cf1bf/joblib-0.14.1-py2.py3-none-any.whl (294kB)\u001b[0m\n",
      "\u001b[34mCollecting regex (from nltk->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/fb/ef/8880ca0f2bc2e51a39aacf62a81947971aea42b3b54ca58111b5a5ba6e05/regex-2020.10.28.tar.gz (694kB)\u001b[0m\n",
      "\u001b[34mCollecting tqdm (from nltk->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/93/3a/96b3dc293aa72443cf9627444c3c221a7ba34bb622e4d8bf1b5d4f2d9d08/tqdm-4.51.0-py2.py3-none-any.whl (70kB)\u001b[0m\n",
      "\u001b[34mCollecting soupsieve>1.2; python_version >= \"3.0\" (from beautifulsoup4->-r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/6f/8f/457f4a5390eeae1cc3aeab89deb7724c965be841ffca6cfca9197482e470/soupsieve-2.0.1-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: six>=1.9 in /usr/local/lib/python3.5/dist-packages (from html5lib->-r requirements.txt (line 5)) (1.11.0)\u001b[0m\n",
      "\u001b[34mCollecting webencodings (from html5lib->-r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/f4/24/2a3e3df732393fed8b3ebf2ec078f05546de641fe1b667ee316ec1dcf3b7/webencodings-0.5.1-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: nltk, train, regex\n",
      "  Running setup.py bdist_wheel for nltk: started\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for nltk: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n",
      "  Running setup.py bdist_wheel for train: started\n",
      "  Running setup.py bdist_wheel for train: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-nc_njvho/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\n",
      "  Running setup.py bdist_wheel for regex: started\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for regex: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/16/32/f2/87817e06026bddd4f4f63c497c1c9587c028bdf57485e52e0f\u001b[0m\n",
      "\u001b[34mSuccessfully built nltk train regex\u001b[0m\n",
      "\u001b[34mInstalling collected packages: pytz, numpy, pandas, joblib, regex, tqdm, nltk, soupsieve, beautifulsoup4, webencodings, html5lib, train\n",
      "  Found existing installation: numpy 1.15.4\n",
      "    Uninstalling numpy-1.15.4:\u001b[0m\n",
      "\u001b[34m      Successfully uninstalled numpy-1.15.4\u001b[0m\n",
      "\u001b[34mSuccessfully installed beautifulsoup4-4.9.3 html5lib-1.1 joblib-0.14.1 nltk-3.5 numpy-1.18.5 pandas-0.24.2 pytz-2020.4 regex-2020.10.28 soupsieve-2.0.1 tqdm-4.51.0 train-1.0.0 webencodings-0.5.1\u001b[0m\n",
      "\u001b[34mYou are using pip version 18.1, however version 20.3b1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-11-11 12:35:40,886 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"RecordWrapperType\": \"None\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\"\n",
      "        }\n",
      "    },\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-11-12-31-48-796/source/sourcedir.tar.gz\",\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"resource_config\": {\n",
      "        \"network_interface_name\": \"eth0\",\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ]\n",
      "    },\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"user_entry_point\": \"train.py\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"hyperparameters\": {\n",
      "        \"hidden_dim\": 10,\n",
      "        \"epochs\": 50\n",
      "    },\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"log_level\": 20,\n",
      "    \"num_gpus\": 1,\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"job_name\": \"sagemaker-pytorch-2020-11-11-12-31-48-796\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":50,\"hidden_dim\":10},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"job_name\":\"sagemaker-pytorch-2020-11-11-12-31-48-796\",\"log_level\":20,\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-11-12-31-48-796/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=50\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-11-12-31-48-796/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"50\",\"--hidden_dim\",\"10\"]\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":50,\"hidden_dim\":10}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/lib/python35.zip:/usr/lib/python3.5:/usr/lib/python3.5/plat-x86_64-linux-gnu:/usr/lib/python3.5/lib-dynload:/usr/local/lib/python3.5/dist-packages:/usr/lib/python3/dist-packages\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN_DIM=10\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m train --epochs 50 --hidden_dim 10\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing device cuda.\u001b[0m\n",
      "\u001b[34mGet train data loader.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mModel loaded with embedding_dim 35, hidden_dim 10, vocab_size 5000.\u001b[0m\n",
      "\u001b[34mEpoch: 1, BCELoss: 0.6495233449068937\u001b[0m\n",
      "\u001b[34mEpoch: 2, BCELoss: 0.43837050145322626\u001b[0m\n",
      "\u001b[34mEpoch: 3, BCELoss: 0.25550691377032886\u001b[0m\n",
      "\u001b[34mEpoch: 4, BCELoss: 0.16303673996166748\u001b[0m\n",
      "\u001b[34mEpoch: 5, BCELoss: 0.11842383173379031\u001b[0m\n",
      "\u001b[34mEpoch: 6, BCELoss: 0.09110851314934817\u001b[0m\n",
      "\u001b[34mEpoch: 7, BCELoss: 0.07273957607421008\u001b[0m\n",
      "\u001b[34mEpoch: 8, BCELoss: 0.06245845691724257\u001b[0m\n",
      "\u001b[34mEpoch: 9, BCELoss: 0.0542400638488206\u001b[0m\n",
      "\u001b[34mEpoch: 10, BCELoss: 0.050560817969116295\u001b[0m\n",
      "\u001b[34mEpoch: 11, BCELoss: 0.04798758825795217\u001b[0m\n",
      "\u001b[34mEpoch: 12, BCELoss: 0.04747859727252613\u001b[0m\n",
      "\u001b[34mEpoch: 13, BCELoss: 0.04593367993154309\u001b[0m\n",
      "\u001b[34mEpoch: 14, BCELoss: 0.04505312781442295\u001b[0m\n",
      "\u001b[34mEpoch: 15, BCELoss: 0.043990154157985344\u001b[0m\n",
      "\u001b[34mEpoch: 16, BCELoss: 0.0433864871209318\u001b[0m\n",
      "\u001b[34mEpoch: 17, BCELoss: 0.04212340255352584\u001b[0m\n",
      "\u001b[34mEpoch: 18, BCELoss: 0.04202817075631835\u001b[0m\n",
      "\u001b[34mEpoch: 19, BCELoss: 0.041226361793550576\u001b[0m\n",
      "\u001b[34mEpoch: 20, BCELoss: 0.04108494215390899\u001b[0m\n",
      "\u001b[34mEpoch: 21, BCELoss: 0.04057493551888249\u001b[0m\n",
      "\u001b[34mEpoch: 22, BCELoss: 0.04028048213909973\u001b[0m\n",
      "\u001b[34mEpoch: 23, BCELoss: 0.04009426842358979\u001b[0m\n",
      "\u001b[34mEpoch: 24, BCELoss: 0.03993692367591641\u001b[0m\n",
      "\u001b[34mEpoch: 25, BCELoss: 0.03978480178524147\u001b[0m\n",
      "\u001b[34mEpoch: 26, BCELoss: 0.0396968928927725\u001b[0m\n",
      "\u001b[34mEpoch: 27, BCELoss: 0.03953561593185772\u001b[0m\n",
      "\u001b[34mEpoch: 28, BCELoss: 0.03946873308582739\u001b[0m\n",
      "\u001b[34mEpoch: 29, BCELoss: 0.039396374401721085\u001b[0m\n",
      "\u001b[34mEpoch: 30, BCELoss: 0.039296715266325256\u001b[0m\n",
      "\u001b[34mEpoch: 31, BCELoss: 0.03938224606893279\u001b[0m\n",
      "\u001b[34mEpoch: 32, BCELoss: 0.03917126340622252\u001b[0m\n",
      "\u001b[34mEpoch: 33, BCELoss: 0.03914402916350148\u001b[0m\n",
      "\u001b[34mEpoch: 34, BCELoss: 0.03905232098292221\u001b[0m\n",
      "\u001b[34mEpoch: 35, BCELoss: 0.03900772062214938\u001b[0m\n",
      "\u001b[34mEpoch: 36, BCELoss: 0.03908230940049345\u001b[0m\n",
      "\u001b[34mEpoch: 37, BCELoss: 0.03953480703586882\u001b[0m\n",
      "\u001b[34mEpoch: 38, BCELoss: 0.04057952101257714\u001b[0m\n",
      "\u001b[34mEpoch: 39, BCELoss: 0.056052333251996475\u001b[0m\n",
      "\u001b[34mEpoch: 40, BCELoss: 0.11128637939691544\u001b[0m\n",
      "\u001b[34mEpoch: 41, BCELoss: 0.151249884204431\u001b[0m\n",
      "\u001b[34mEpoch: 42, BCELoss: 0.14839452572844244\u001b[0m\n",
      "\u001b[34mEpoch: 43, BCELoss: 0.12053286216475746\u001b[0m\n",
      "\u001b[34mEpoch: 44, BCELoss: 0.09837587888945233\u001b[0m\n",
      "\u001b[34mEpoch: 45, BCELoss: 0.08182852816852657\u001b[0m\n",
      "\u001b[34mEpoch: 46, BCELoss: 0.07192735848101703\u001b[0m\n",
      "\u001b[34mEpoch: 47, BCELoss: 0.06134305250915614\u001b[0m\n",
      "\u001b[34mEpoch: 48, BCELoss: 0.05794009244577451\u001b[0m\n",
      "\u001b[34mEpoch: 49, BCELoss: 0.055261330171064896\u001b[0m\n",
      "\u001b[34mEpoch: 50, BCELoss: 0.051739649339155716\u001b[0m\n",
      "\u001b[34m2020-11-11 12:35:52,039 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-11-11 12:36:02 Uploading - Uploading generated training model\n",
      "2020-11-11 12:36:02 Completed - Training job completed\n",
      "Training seconds: 117\n",
      "Billable seconds: 117\n",
      "---------------!"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted sagemaker-pytorch-2020-11-11-12-36-31-871\n",
      "2020-11-11 12:44:04 Starting - Starting the training job...\n",
      "2020-11-11 12:44:06 Starting - Launching requested ML instances......\n",
      "2020-11-11 12:45:15 Starting - Preparing the instances for training......\n",
      "2020-11-11 12:46:27 Downloading - Downloading input data......\n",
      "2020-11-11 12:47:16 Training - Downloading the training image..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-11-11 12:47:40,273 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-11-11 12:47:40,298 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-11-11 12:47:43,314 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-11-11 12:47:43,619 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-11-11 12:47:43,619 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-11-11 12:47:43,619 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-11-11 12:47:43,620 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pip install -U . -r requirements.txt\u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mCollecting pandas (from -r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34m  Downloading https://files.pythonhosted.org/packages/74/24/0cdbf8907e1e3bc5a8da03345c23cbed7044330bb8f73bb12e711a640a00/pandas-0.24.2-cp35-cp35m-manylinux1_x86_64.whl (10.0MB)\u001b[0m\n",
      "\u001b[34mCollecting numpy (from -r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/b5/36/88723426b4ff576809fec7d73594fe17a35c27f8d01f93637637a29ae25b/numpy-1.18.5-cp35-cp35m-manylinux1_x86_64.whl (19.9MB)\u001b[0m\n",
      "\u001b[34mCollecting nltk (from -r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\u001b[0m\n",
      "\u001b[34mCollecting beautifulsoup4 (from -r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/41/e6495bd7d3781cee623ce23ea6ac73282a373088fcd0ddc809a047b18eae/beautifulsoup4-4.9.3-py3-none-any.whl (115kB)\u001b[0m\n",
      "\u001b[34mCollecting html5lib (from -r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/6c/dd/a834df6482147d48e225a49515aabc28974ad5a4ca3215c18a882565b028/html5lib-1.1-py2.py3-none-any.whl (112kB)\u001b[0m\n",
      "\u001b[34mCollecting pytz>=2011k (from pandas->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/12/f8/ff09af6ff61a3efaad5f61ba5facdf17e7722c4393f7d8a66674d2dbd29f/pytz-2020.4-py2.py3-none-any.whl (509kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /usr/local/lib/python3.5/dist-packages (from pandas->-r requirements.txt (line 1)) (2.7.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.5/dist-packages (from nltk->-r requirements.txt (line 3)) (7.0)\u001b[0m\n",
      "\u001b[34mCollecting joblib (from nltk->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/28/5c/cf6a2b65a321c4a209efcdf64c2689efae2cb62661f8f6f4bb28547cf1bf/joblib-0.14.1-py2.py3-none-any.whl (294kB)\u001b[0m\n",
      "\u001b[34mCollecting regex (from nltk->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34m  Downloading https://files.pythonhosted.org/packages/fb/ef/8880ca0f2bc2e51a39aacf62a81947971aea42b3b54ca58111b5a5ba6e05/regex-2020.10.28.tar.gz (694kB)\u001b[0m\n",
      "\u001b[34mCollecting tqdm (from nltk->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/93/3a/96b3dc293aa72443cf9627444c3c221a7ba34bb622e4d8bf1b5d4f2d9d08/tqdm-4.51.0-py2.py3-none-any.whl (70kB)\u001b[0m\n",
      "\u001b[34mCollecting soupsieve>1.2; python_version >= \"3.0\" (from beautifulsoup4->-r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/6f/8f/457f4a5390eeae1cc3aeab89deb7724c965be841ffca6cfca9197482e470/soupsieve-2.0.1-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mCollecting webencodings (from html5lib->-r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/f4/24/2a3e3df732393fed8b3ebf2ec078f05546de641fe1b667ee316ec1dcf3b7/webencodings-0.5.1-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: six>=1.9 in /usr/local/lib/python3.5/dist-packages (from html5lib->-r requirements.txt (line 5)) (1.11.0)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: nltk, train, regex\n",
      "  Running setup.py bdist_wheel for nltk: started\n",
      "  Running setup.py bdist_wheel for nltk: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\u001b[0m\n",
      "\n",
      "2020-11-11 12:47:39 Training - Training image download completed. Training in progress.\u001b[34m  Running setup.py bdist_wheel for train: started\n",
      "  Running setup.py bdist_wheel for train: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-dgyiqo8e/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\n",
      "  Running setup.py bdist_wheel for regex: started\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for regex: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/16/32/f2/87817e06026bddd4f4f63c497c1c9587c028bdf57485e52e0f\u001b[0m\n",
      "\u001b[34mSuccessfully built nltk train regex\u001b[0m\n",
      "\u001b[34mInstalling collected packages: numpy, pytz, pandas, joblib, regex, tqdm, nltk, soupsieve, beautifulsoup4, webencodings, html5lib, train\n",
      "  Found existing installation: numpy 1.15.4\n",
      "    Uninstalling numpy-1.15.4:\u001b[0m\n",
      "\u001b[34m      Successfully uninstalled numpy-1.15.4\u001b[0m\n",
      "\u001b[34mSuccessfully installed beautifulsoup4-4.9.3 html5lib-1.1 joblib-0.14.1 nltk-3.5 numpy-1.18.5 pandas-0.24.2 pytz-2020.4 regex-2020.10.28 soupsieve-2.0.1 tqdm-4.51.0 train-1.0.0 webencodings-0.5.1\u001b[0m\n",
      "\u001b[34mYou are using pip version 18.1, however version 20.3b1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-11-11 12:48:07,434 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"RecordWrapperType\": \"None\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\"\n",
      "        }\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-11-12-44-03-997/source/sourcedir.tar.gz\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"num_gpus\": 1,\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"network_interface_name\": \"eth0\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ]\n",
      "    },\n",
      "    \"hyperparameters\": {\n",
      "        \"hidden_dim\": 100,\n",
      "        \"epochs\": 50\n",
      "    },\n",
      "    \"log_level\": 20,\n",
      "    \"module_name\": \"train\",\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"job_name\": \"sagemaker-pytorch-2020-11-11-12-44-03-997\",\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=50\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":50,\"hidden_dim\":100}\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN_DIM=100\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":50,\"hidden_dim\":100},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"job_name\":\"sagemaker-pytorch-2020-11-11-12-44-03-997\",\"log_level\":20,\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-11-12-44-03-997/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-11-12-44-03-997/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/lib/python35.zip:/usr/lib/python3.5:/usr/lib/python3.5/plat-x86_64-linux-gnu:/usr/lib/python3.5/lib-dynload:/usr/local/lib/python3.5/dist-packages:/usr/lib/python3/dist-packages\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"50\",\"--hidden_dim\",\"100\"]\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m train --epochs 50 --hidden_dim 100\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing device cuda.\u001b[0m\n",
      "\u001b[34mGet train data loader.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mModel loaded with embedding_dim 35, hidden_dim 100, vocab_size 5000.\u001b[0m\n",
      "\u001b[34mEpoch: 1, BCELoss: 0.6667190194129944\u001b[0m\n",
      "\u001b[34mEpoch: 2, BCELoss: 0.4784893908283927\u001b[0m\n",
      "\u001b[34mEpoch: 3, BCELoss: 0.28363124484365637\u001b[0m\n",
      "\u001b[34mEpoch: 4, BCELoss: 0.13582424006678842\u001b[0m\n",
      "\u001b[34mEpoch: 5, BCELoss: 0.07632480764930899\u001b[0m\n",
      "\u001b[34mEpoch: 6, BCELoss: 0.05438657951625911\u001b[0m\n",
      "\u001b[34mEpoch: 7, BCELoss: 0.049250575798478996\u001b[0m\n",
      "\u001b[34mEpoch: 8, BCELoss: 0.04602062092585997\u001b[0m\n",
      "\u001b[34mEpoch: 9, BCELoss: 0.04170106876302849\u001b[0m\n",
      "\u001b[34mEpoch: 10, BCELoss: 0.041089638051661576\u001b[0m\n",
      "\u001b[34mEpoch: 11, BCELoss: 0.039924177933822975\u001b[0m\n",
      "\u001b[34mEpoch: 12, BCELoss: 0.03944244642149319\u001b[0m\n",
      "\u001b[34mEpoch: 13, BCELoss: 0.039317225190726196\u001b[0m\n",
      "\u001b[34mEpoch: 14, BCELoss: 0.03904684700749137\u001b[0m\n",
      "\u001b[34mEpoch: 15, BCELoss: 0.03896623697470535\u001b[0m\n",
      "\u001b[34mEpoch: 16, BCELoss: 0.03883494470607151\u001b[0m\n",
      "\u001b[34mEpoch: 17, BCELoss: 0.038811511444774544\u001b[0m\n",
      "\u001b[34mEpoch: 18, BCELoss: 0.03868978910825469\u001b[0m\n",
      "\u001b[34mEpoch: 19, BCELoss: 0.03868700597773899\u001b[0m\n",
      "\u001b[34mEpoch: 20, BCELoss: 0.03856699608943679\u001b[0m\n",
      "\u001b[34mEpoch: 21, BCELoss: 0.03858704780313102\u001b[0m\n",
      "\u001b[34mEpoch: 22, BCELoss: 0.0384720540182157\u001b[0m\n",
      "\u001b[34mEpoch: 23, BCELoss: 0.038518319922414695\u001b[0m\n",
      "\u001b[34mEpoch: 24, BCELoss: 0.038400874388488854\u001b[0m\n",
      "\u001b[34mEpoch: 25, BCELoss: 0.03846805915236473\u001b[0m\n",
      "\u001b[34mEpoch: 26, BCELoss: 0.03833675469187173\u001b[0m\n",
      "\u001b[34mEpoch: 27, BCELoss: 0.03841184672306885\u001b[0m\n",
      "\u001b[34mEpoch: 28, BCELoss: 0.03827736357396299\u001b[0m\n",
      "\u001b[34mEpoch: 29, BCELoss: 0.03838069432161071\u001b[0m\n",
      "\u001b[34mEpoch: 30, BCELoss: 0.03822610120881687\u001b[0m\n",
      "\u001b[34mEpoch: 31, BCELoss: 0.038251910866661507\u001b[0m\n",
      "\u001b[34mEpoch: 32, BCELoss: 0.03815455819395455\u001b[0m\n",
      "\u001b[34mEpoch: 33, BCELoss: 0.03816565210846337\u001b[0m\n",
      "\u001b[34mEpoch: 34, BCELoss: 0.03810613450001587\u001b[0m\n",
      "\u001b[34mEpoch: 35, BCELoss: 0.03812423551624471\u001b[0m\n",
      "\u001b[34mEpoch: 36, BCELoss: 0.03807250545783476\u001b[0m\n",
      "\u001b[34mEpoch: 37, BCELoss: 0.03809132477776571\u001b[0m\n",
      "\u001b[34mEpoch: 38, BCELoss: 0.03804490630599586\u001b[0m\n",
      "\u001b[34mEpoch: 39, BCELoss: 0.038063949312676086\u001b[0m\n",
      "\u001b[34mEpoch: 40, BCELoss: 0.03801885789090937\u001b[0m\n",
      "\u001b[34mEpoch: 41, BCELoss: 0.038039404221556404\u001b[0m\n",
      "\u001b[34mEpoch: 42, BCELoss: 0.03799422931942073\u001b[0m\n",
      "\u001b[34mEpoch: 43, BCELoss: 0.038015377961776474\u001b[0m\n",
      "\u001b[34mEpoch: 44, BCELoss: 0.03797121142799204\u001b[0m\n",
      "\u001b[34mEpoch: 45, BCELoss: 0.03799167309295048\u001b[0m\n",
      "\u001b[34mEpoch: 46, BCELoss: 0.03795031051744114\u001b[0m\n",
      "\n",
      "2020-11-11 12:48:32 Uploading - Uploading generated training model\n",
      "2020-11-11 12:48:32 Completed - Training job completed\n",
      "\u001b[34mEpoch: 47, BCELoss: 0.03796906870874492\u001b[0m\n",
      "\u001b[34mEpoch: 48, BCELoss: 0.037931954826820984\u001b[0m\n",
      "\u001b[34mEpoch: 49, BCELoss: 0.0379483008926565\u001b[0m\n",
      "\u001b[34mEpoch: 50, BCELoss: 0.03791608170352199\u001b[0m\n",
      "\u001b[34m2020-11-11 12:48:23,772 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "Training seconds: 125\n",
      "Billable seconds: 125\n",
      "-------------!"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted sagemaker-pytorch-2020-11-11-12-48-47-441\n",
      "2020-11-11 12:55:21 Starting - Starting the training job...\n",
      "2020-11-11 12:55:23 Starting - Launching requested ML instances......\n",
      "2020-11-11 12:56:29 Starting - Preparing the instances for training......\n",
      "2020-11-11 12:57:49 Downloading - Downloading input data......\n",
      "2020-11-11 12:58:31 Training - Downloading the training image..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-11-11 12:58:55,364 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-11-11 12:58:55,390 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-11-11 12:58:55,395 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-11-11 12:58:55,643 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-11-11 12:58:55,643 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-11-11 12:58:55,644 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-11-11 12:58:55,644 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pip install -U . -r requirements.txt\u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mCollecting pandas (from -r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/74/24/0cdbf8907e1e3bc5a8da03345c23cbed7044330bb8f73bb12e711a640a00/pandas-0.24.2-cp35-cp35m-manylinux1_x86_64.whl (10.0MB)\u001b[0m\n",
      "\u001b[34mCollecting numpy (from -r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34m  Downloading https://files.pythonhosted.org/packages/b5/36/88723426b4ff576809fec7d73594fe17a35c27f8d01f93637637a29ae25b/numpy-1.18.5-cp35-cp35m-manylinux1_x86_64.whl (19.9MB)\u001b[0m\n",
      "\u001b[34mCollecting nltk (from -r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34m  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\u001b[0m\n",
      "\u001b[34mCollecting beautifulsoup4 (from -r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/41/e6495bd7d3781cee623ce23ea6ac73282a373088fcd0ddc809a047b18eae/beautifulsoup4-4.9.3-py3-none-any.whl (115kB)\u001b[0m\n",
      "\u001b[34mCollecting html5lib (from -r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/6c/dd/a834df6482147d48e225a49515aabc28974ad5a4ca3215c18a882565b028/html5lib-1.1-py2.py3-none-any.whl (112kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /usr/local/lib/python3.5/dist-packages (from pandas->-r requirements.txt (line 1)) (2.7.5)\u001b[0m\n",
      "\u001b[34mCollecting pytz>=2011k (from pandas->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/12/f8/ff09af6ff61a3efaad5f61ba5facdf17e7722c4393f7d8a66674d2dbd29f/pytz-2020.4-py2.py3-none-any.whl (509kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.5/dist-packages (from nltk->-r requirements.txt (line 3)) (7.0)\u001b[0m\n",
      "\u001b[34mCollecting joblib (from nltk->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/28/5c/cf6a2b65a321c4a209efcdf64c2689efae2cb62661f8f6f4bb28547cf1bf/joblib-0.14.1-py2.py3-none-any.whl (294kB)\u001b[0m\n",
      "\u001b[34mCollecting regex (from nltk->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/fb/ef/8880ca0f2bc2e51a39aacf62a81947971aea42b3b54ca58111b5a5ba6e05/regex-2020.10.28.tar.gz (694kB)\u001b[0m\n",
      "\u001b[34mCollecting tqdm (from nltk->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/93/3a/96b3dc293aa72443cf9627444c3c221a7ba34bb622e4d8bf1b5d4f2d9d08/tqdm-4.51.0-py2.py3-none-any.whl (70kB)\u001b[0m\n",
      "\u001b[34mCollecting soupsieve>1.2; python_version >= \"3.0\" (from beautifulsoup4->-r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/6f/8f/457f4a5390eeae1cc3aeab89deb7724c965be841ffca6cfca9197482e470/soupsieve-2.0.1-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: six>=1.9 in /usr/local/lib/python3.5/dist-packages (from html5lib->-r requirements.txt (line 5)) (1.11.0)\u001b[0m\n",
      "\u001b[34mCollecting webencodings (from html5lib->-r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/f4/24/2a3e3df732393fed8b3ebf2ec078f05546de641fe1b667ee316ec1dcf3b7/webencodings-0.5.1-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: nltk, train, regex\n",
      "  Running setup.py bdist_wheel for nltk: started\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for nltk: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n",
      "  Running setup.py bdist_wheel for train: started\n",
      "  Running setup.py bdist_wheel for train: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-gwc1pw18/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\n",
      "  Running setup.py bdist_wheel for regex: started\u001b[0m\n",
      "\n",
      "2020-11-11 12:58:54 Training - Training image download completed. Training in progress.\u001b[34m  Running setup.py bdist_wheel for regex: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/16/32/f2/87817e06026bddd4f4f63c497c1c9587c028bdf57485e52e0f\u001b[0m\n",
      "\u001b[34mSuccessfully built nltk train regex\u001b[0m\n",
      "\u001b[34mInstalling collected packages: numpy, pytz, pandas, joblib, regex, tqdm, nltk, soupsieve, beautifulsoup4, webencodings, html5lib, train\n",
      "  Found existing installation: numpy 1.15.4\n",
      "    Uninstalling numpy-1.15.4:\u001b[0m\n",
      "\u001b[34m      Successfully uninstalled numpy-1.15.4\u001b[0m\n",
      "\u001b[34mSuccessfully installed beautifulsoup4-4.9.3 html5lib-1.1 joblib-0.14.1 nltk-3.5 numpy-1.18.5 pandas-0.24.2 pytz-2020.4 regex-2020.10.28 soupsieve-2.0.1 tqdm-4.51.0 train-1.0.0 webencodings-0.5.1\u001b[0m\n",
      "\u001b[34mYou are using pip version 18.1, however version 20.3b1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-11-11 12:59:19,232 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\",\n",
      "            \"TrainingInputMode\": \"File\"\n",
      "        }\n",
      "    },\n",
      "    \"job_name\": \"sagemaker-pytorch-2020-11-11-12-55-20-767\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"log_level\": 20,\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-11-12-55-20-767/source/sourcedir.tar.gz\",\n",
      "    \"num_gpus\": 1,\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"user_entry_point\": \"train.py\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"network_interface_name\": \"eth0\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ]\n",
      "    },\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 50,\n",
      "        \"hidden_dim\": 200\n",
      "    },\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=50\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"50\",\"--hidden_dim\",\"200\"]\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":50,\"hidden_dim\":200}\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":50,\"hidden_dim\":200},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"job_name\":\"sagemaker-pytorch-2020-11-11-12-55-20-767\",\"log_level\":20,\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-11-12-55-20-767/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/lib/python35.zip:/usr/lib/python3.5:/usr/lib/python3.5/plat-x86_64-linux-gnu:/usr/lib/python3.5/lib-dynload:/usr/local/lib/python3.5/dist-packages:/usr/lib/python3/dist-packages\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN_DIM=200\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-11-12-55-20-767/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m train --epochs 50 --hidden_dim 200\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing device cuda.\u001b[0m\n",
      "\u001b[34mGet train data loader.\u001b[0m\n",
      "\u001b[34mModel loaded with embedding_dim 35, hidden_dim 200, vocab_size 5000.\u001b[0m\n",
      "\u001b[34mEpoch: 1, BCELoss: 0.7832662029699846\u001b[0m\n",
      "\u001b[34mEpoch: 2, BCELoss: 0.7070528810674493\u001b[0m\n",
      "\u001b[34mEpoch: 3, BCELoss: 0.6470508141951128\u001b[0m\n",
      "\u001b[34mEpoch: 4, BCELoss: 0.5651451295072382\u001b[0m\n",
      "\u001b[34mEpoch: 5, BCELoss: 0.4686794172633778\u001b[0m\n",
      "\u001b[34mEpoch: 6, BCELoss: 0.36375353011217987\u001b[0m\n",
      "\u001b[34mEpoch: 7, BCELoss: 0.2807423905892806\u001b[0m\n",
      "\u001b[34mEpoch: 8, BCELoss: 0.21410149200396103\u001b[0m\n",
      "\u001b[34mEpoch: 9, BCELoss: 0.15948683294382962\u001b[0m\n",
      "\u001b[34mEpoch: 10, BCELoss: 0.11766727268695831\u001b[0m\n",
      "\u001b[34mEpoch: 11, BCELoss: 0.09834169664166191\u001b[0m\n",
      "\u001b[34mEpoch: 12, BCELoss: 0.0865608433430845\u001b[0m\n",
      "\u001b[34mEpoch: 13, BCELoss: 0.0749292912131006\u001b[0m\n",
      "\u001b[34mEpoch: 14, BCELoss: 0.06582087820226495\u001b[0m\n",
      "\u001b[34mEpoch: 15, BCELoss: 0.055926820771260696\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mEpoch: 16, BCELoss: 0.05506278032606298\u001b[0m\n",
      "\u001b[34mEpoch: 17, BCELoss: 0.054085819897326554\u001b[0m\n",
      "\u001b[34mEpoch: 18, BCELoss: 0.04841971092603423\u001b[0m\n",
      "\u001b[34mEpoch: 19, BCELoss: 0.045265369286591355\u001b[0m\n",
      "\u001b[34mEpoch: 20, BCELoss: 0.04483982954512943\u001b[0m\n",
      "\u001b[34mEpoch: 21, BCELoss: 0.04398900829255581\u001b[0m\n",
      "\u001b[34mEpoch: 22, BCELoss: 0.04323760707947341\u001b[0m\n",
      "\u001b[34mEpoch: 23, BCELoss: 0.04289130087603222\u001b[0m\n",
      "\u001b[34mEpoch: 24, BCELoss: 0.04284912110729651\u001b[0m\n",
      "\u001b[34mEpoch: 25, BCELoss: 0.042413878847252236\u001b[0m\n",
      "\u001b[34mEpoch: 26, BCELoss: 0.04214295677163384\u001b[0m\n",
      "\u001b[34mEpoch: 27, BCELoss: 0.041958019476045265\u001b[0m\n",
      "\u001b[34mEpoch: 28, BCELoss: 0.04178814945573157\u001b[0m\n",
      "\u001b[34mEpoch: 29, BCELoss: 0.04172372970391403\u001b[0m\n",
      "\u001b[34mEpoch: 30, BCELoss: 0.04187325676056472\u001b[0m\n",
      "\u001b[34mEpoch: 31, BCELoss: 0.04142087223854932\u001b[0m\n",
      "\u001b[34mEpoch: 32, BCELoss: 0.04115864194252274\u001b[0m\n",
      "\u001b[34mEpoch: 33, BCELoss: 0.041225133294408974\u001b[0m\n",
      "\u001b[34mEpoch: 34, BCELoss: 0.04104086570441723\u001b[0m\n",
      "\u001b[34mEpoch: 35, BCELoss: 0.040912146934054115\u001b[0m\n",
      "\u001b[34mEpoch: 36, BCELoss: 0.04085039313543926\u001b[0m\n",
      "\u001b[34mEpoch: 37, BCELoss: 0.04078879342837767\u001b[0m\n",
      "\u001b[34mEpoch: 38, BCELoss: 0.04073509319939397\u001b[0m\n",
      "\u001b[34mEpoch: 39, BCELoss: 0.040708399123766205\u001b[0m\n",
      "\u001b[34mEpoch: 40, BCELoss: 0.04065127518366684\u001b[0m\n",
      "\u001b[34mEpoch: 41, BCELoss: 0.040653811767697334\u001b[0m\n",
      "\u001b[34mEpoch: 42, BCELoss: 0.04060733758590438\u001b[0m\n",
      "\u001b[34mEpoch: 43, BCELoss: 0.04062587022781372\u001b[0m\n",
      "\u001b[34mEpoch: 44, BCELoss: 0.0405677157369527\u001b[0m\n",
      "\u001b[34mEpoch: 45, BCELoss: 0.04057075083255768\u001b[0m\n",
      "\u001b[34mEpoch: 46, BCELoss: 0.040520590814677154\u001b[0m\n",
      "\n",
      "2020-11-11 12:59:52 Uploading - Uploading generated training model\n",
      "2020-11-11 12:59:52 Completed - Training job completed\n",
      "\u001b[34mEpoch: 47, BCELoss: 0.040517246519977394\u001b[0m\n",
      "\u001b[34mEpoch: 48, BCELoss: 0.04049528288570317\u001b[0m\n",
      "\u001b[34mEpoch: 49, BCELoss: 0.04049213687804612\u001b[0m\n",
      "\u001b[34mEpoch: 50, BCELoss: 0.040482424199581146\u001b[0m\n",
      "\u001b[34m2020-11-11 12:59:42,304 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "Training seconds: 123\n",
      "Billable seconds: 123\n",
      "---.\n",
      "2020-11-11 13:09:17 Training - Downloading the training image...\n",
      "2020-11-11 13:09:57 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-11-11 13:09:57,777 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-11-11 13:09:57,804 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-11-11 13:10:04,025 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-11-11 13:10:04,262 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-11-11 13:10:04,262 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-11-11 13:10:04,262 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-11-11 13:10:04,263 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pip install -U . -r requirements.txt\u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mCollecting pandas (from -r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/74/24/0cdbf8907e1e3bc5a8da03345c23cbed7044330bb8f73bb12e711a640a00/pandas-0.24.2-cp35-cp35m-manylinux1_x86_64.whl (10.0MB)\u001b[0m\n",
      "\u001b[34mCollecting numpy (from -r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34m  Downloading https://files.pythonhosted.org/packages/b5/36/88723426b4ff576809fec7d73594fe17a35c27f8d01f93637637a29ae25b/numpy-1.18.5-cp35-cp35m-manylinux1_x86_64.whl (19.9MB)\u001b[0m\n",
      "\u001b[34mCollecting nltk (from -r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\u001b[0m\n",
      "\u001b[34mCollecting beautifulsoup4 (from -r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/41/e6495bd7d3781cee623ce23ea6ac73282a373088fcd0ddc809a047b18eae/beautifulsoup4-4.9.3-py3-none-any.whl (115kB)\u001b[0m\n",
      "\u001b[34mCollecting html5lib (from -r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/6c/dd/a834df6482147d48e225a49515aabc28974ad5a4ca3215c18a882565b028/html5lib-1.1-py2.py3-none-any.whl (112kB)\u001b[0m\n",
      "\u001b[34mCollecting pytz>=2011k (from pandas->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/12/f8/ff09af6ff61a3efaad5f61ba5facdf17e7722c4393f7d8a66674d2dbd29f/pytz-2020.4-py2.py3-none-any.whl (509kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /usr/local/lib/python3.5/dist-packages (from pandas->-r requirements.txt (line 1)) (2.7.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.5/dist-packages (from nltk->-r requirements.txt (line 3)) (7.0)\u001b[0m\n",
      "\u001b[34mCollecting joblib (from nltk->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/28/5c/cf6a2b65a321c4a209efcdf64c2689efae2cb62661f8f6f4bb28547cf1bf/joblib-0.14.1-py2.py3-none-any.whl (294kB)\u001b[0m\n",
      "\u001b[34mCollecting regex (from nltk->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34m  Downloading https://files.pythonhosted.org/packages/fb/ef/8880ca0f2bc2e51a39aacf62a81947971aea42b3b54ca58111b5a5ba6e05/regex-2020.10.28.tar.gz (694kB)\u001b[0m\n",
      "\u001b[34mCollecting tqdm (from nltk->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/93/3a/96b3dc293aa72443cf9627444c3c221a7ba34bb622e4d8bf1b5d4f2d9d08/tqdm-4.51.0-py2.py3-none-any.whl (70kB)\u001b[0m\n",
      "\u001b[34mCollecting soupsieve>1.2; python_version >= \"3.0\" (from beautifulsoup4->-r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/6f/8f/457f4a5390eeae1cc3aeab89deb7724c965be841ffca6cfca9197482e470/soupsieve-2.0.1-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mCollecting webencodings (from html5lib->-r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/f4/24/2a3e3df732393fed8b3ebf2ec078f05546de641fe1b667ee316ec1dcf3b7/webencodings-0.5.1-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: six>=1.9 in /usr/local/lib/python3.5/dist-packages (from html5lib->-r requirements.txt (line 5)) (1.11.0)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: nltk, train, regex\n",
      "  Running setup.py bdist_wheel for nltk: started\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for nltk: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n",
      "  Running setup.py bdist_wheel for train: started\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for train: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-t9th1a8b/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\n",
      "  Running setup.py bdist_wheel for regex: started\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for regex: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/16/32/f2/87817e06026bddd4f4f63c497c1c9587c028bdf57485e52e0f\u001b[0m\n",
      "\u001b[34mSuccessfully built nltk train regex\u001b[0m\n",
      "\u001b[34mInstalling collected packages: numpy, pytz, pandas, joblib, regex, tqdm, nltk, soupsieve, beautifulsoup4, webencodings, html5lib, train\n",
      "  Found existing installation: numpy 1.15.4\n",
      "    Uninstalling numpy-1.15.4:\u001b[0m\n",
      "\u001b[34m      Successfully uninstalled numpy-1.15.4\u001b[0m\n",
      "\n",
      "2020-11-11 13:10:38 Uploading - Uploading generated training model\u001b[34mSuccessfully installed beautifulsoup4-4.9.3 html5lib-1.1 joblib-0.14.1 nltk-3.5 numpy-1.18.5 pandas-0.24.2 pytz-2020.4 regex-2020.10.28 soupsieve-2.0.1 tqdm-4.51.0 train-1.0.0 webencodings-0.5.1\u001b[0m\n",
      "\u001b[34mYou are using pip version 18.1, however version 20.3b1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-11-11 13:10:28,903 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 15,\n",
      "        \"hidden_dim\": 10\n",
      "    },\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"RecordWrapperType\": \"None\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"num_gpus\": 1,\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"log_level\": 20,\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-11-13-06-38-382/source/sourcedir.tar.gz\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"job_name\": \"sagemaker-pytorch-2020-11-11-13-06-38-382\",\n",
      "    \"user_entry_point\": \"train.py\",\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"resource_config\": {\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\",\n",
      "        \"current_host\": \"algo-1\"\n",
      "    },\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"num_cpus\": 4,\n",
      "    \"module_name\": \"train\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"output_dir\": \"/opt/ml/output\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":15,\"hidden_dim\":10}\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/lib/python35.zip:/usr/lib/python3.5:/usr/lib/python3.5/plat-x86_64-linux-gnu:/usr/lib/python3.5/lib-dynload:/usr/local/lib/python3.5/dist-packages:/usr/lib/python3/dist-packages\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN_DIM=10\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"15\",\"--hidden_dim\",\"10\"]\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=15\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":15,\"hidden_dim\":10},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"job_name\":\"sagemaker-pytorch-2020-11-11-13-06-38-382\",\"log_level\":20,\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-11-13-06-38-382/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-11-13-06-38-382/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m train --epochs 15 --hidden_dim 10\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing device cuda.\u001b[0m\n",
      "\u001b[34mGet train data loader.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mModel loaded with embedding_dim 35, hidden_dim 10, vocab_size 5000.\u001b[0m\n",
      "\u001b[34mEpoch: 1, BCELoss: 0.6495233449068937\u001b[0m\n",
      "\u001b[34mEpoch: 2, BCELoss: 0.43837050145322626\u001b[0m\n",
      "\u001b[34mEpoch: 3, BCELoss: 0.25550691377032886\u001b[0m\n",
      "\u001b[34mEpoch: 4, BCELoss: 0.16303673996166748\u001b[0m\n",
      "\u001b[34mEpoch: 5, BCELoss: 0.11842383173379031\u001b[0m\n",
      "\u001b[34mEpoch: 6, BCELoss: 0.09110851314934817\u001b[0m\n",
      "\u001b[34mEpoch: 7, BCELoss: 0.07273957607421008\u001b[0m\n",
      "\u001b[34mEpoch: 8, BCELoss: 0.06245845691724257\u001b[0m\n",
      "\u001b[34mEpoch: 9, BCELoss: 0.0542400638488206\u001b[0m\n",
      "\u001b[34mEpoch: 10, BCELoss: 0.050560817969116295\u001b[0m\n",
      "\u001b[34mEpoch: 11, BCELoss: 0.04798758825795217\u001b[0m\n",
      "\u001b[34mEpoch: 12, BCELoss: 0.04747859727252613\u001b[0m\n",
      "\u001b[34mEpoch: 13, BCELoss: 0.04593367993154309\u001b[0m\n",
      "\u001b[34mEpoch: 14, BCELoss: 0.04505312781442295\u001b[0m\n",
      "\u001b[34mEpoch: 15, BCELoss: 0.043990154157985344\u001b[0m\n",
      "\u001b[34m2020-11-11 13:10:37,260 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-11-11 13:10:45 Completed - Training job completed\n",
      "Training seconds: 115\n",
      "Billable seconds: 115\n",
      "-----------------!"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted sagemaker-pytorch-2020-11-11-13-11-22-205\n",
      "2020-11-11 13:19:54 Starting - Starting the training job...\n",
      "2020-11-11 13:19:56 Starting - Launching requested ML instances......\n",
      "2020-11-11 13:21:04 Starting - Preparing the instances for training............\n",
      "2020-11-11 13:23:07 Downloading - Downloading input data...\n",
      "2020-11-11 13:23:53 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-11-11 13:23:54,035 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-11-11 13:23:54,060 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-11-11 13:23:57,078 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-11-11 13:23:57,315 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-11-11 13:23:57,316 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-11-11 13:23:57,316 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-11-11 13:23:57,316 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pip install -U . -r requirements.txt\u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mCollecting pandas (from -r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34m  Downloading https://files.pythonhosted.org/packages/74/24/0cdbf8907e1e3bc5a8da03345c23cbed7044330bb8f73bb12e711a640a00/pandas-0.24.2-cp35-cp35m-manylinux1_x86_64.whl (10.0MB)\u001b[0m\n",
      "\u001b[34mCollecting numpy (from -r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/b5/36/88723426b4ff576809fec7d73594fe17a35c27f8d01f93637637a29ae25b/numpy-1.18.5-cp35-cp35m-manylinux1_x86_64.whl (19.9MB)\u001b[0m\n",
      "\u001b[34mCollecting nltk (from -r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\u001b[0m\n",
      "\u001b[34mCollecting beautifulsoup4 (from -r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/41/e6495bd7d3781cee623ce23ea6ac73282a373088fcd0ddc809a047b18eae/beautifulsoup4-4.9.3-py3-none-any.whl (115kB)\u001b[0m\n",
      "\u001b[34mCollecting html5lib (from -r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/6c/dd/a834df6482147d48e225a49515aabc28974ad5a4ca3215c18a882565b028/html5lib-1.1-py2.py3-none-any.whl (112kB)\u001b[0m\n",
      "\u001b[34mCollecting pytz>=2011k (from pandas->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/12/f8/ff09af6ff61a3efaad5f61ba5facdf17e7722c4393f7d8a66674d2dbd29f/pytz-2020.4-py2.py3-none-any.whl (509kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /usr/local/lib/python3.5/dist-packages (from pandas->-r requirements.txt (line 1)) (2.7.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.5/dist-packages (from nltk->-r requirements.txt (line 3)) (7.0)\u001b[0m\n",
      "\u001b[34mCollecting joblib (from nltk->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/28/5c/cf6a2b65a321c4a209efcdf64c2689efae2cb62661f8f6f4bb28547cf1bf/joblib-0.14.1-py2.py3-none-any.whl (294kB)\u001b[0m\n",
      "\u001b[34mCollecting regex (from nltk->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34m  Downloading https://files.pythonhosted.org/packages/fb/ef/8880ca0f2bc2e51a39aacf62a81947971aea42b3b54ca58111b5a5ba6e05/regex-2020.10.28.tar.gz (694kB)\u001b[0m\n",
      "\u001b[34mCollecting tqdm (from nltk->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/93/3a/96b3dc293aa72443cf9627444c3c221a7ba34bb622e4d8bf1b5d4f2d9d08/tqdm-4.51.0-py2.py3-none-any.whl (70kB)\u001b[0m\n",
      "\u001b[34mCollecting soupsieve>1.2; python_version >= \"3.0\" (from beautifulsoup4->-r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/6f/8f/457f4a5390eeae1cc3aeab89deb7724c965be841ffca6cfca9197482e470/soupsieve-2.0.1-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mCollecting webencodings (from html5lib->-r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/f4/24/2a3e3df732393fed8b3ebf2ec078f05546de641fe1b667ee316ec1dcf3b7/webencodings-0.5.1-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: six>=1.9 in /usr/local/lib/python3.5/dist-packages (from html5lib->-r requirements.txt (line 5)) (1.11.0)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: nltk, train, regex\n",
      "  Running setup.py bdist_wheel for nltk: started\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for nltk: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n",
      "  Running setup.py bdist_wheel for train: started\n",
      "  Running setup.py bdist_wheel for train: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-abh984i1/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\n",
      "  Running setup.py bdist_wheel for regex: started\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for regex: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/16/32/f2/87817e06026bddd4f4f63c497c1c9587c028bdf57485e52e0f\u001b[0m\n",
      "\u001b[34mSuccessfully built nltk train regex\u001b[0m\n",
      "\u001b[34mInstalling collected packages: pytz, numpy, pandas, joblib, regex, tqdm, nltk, soupsieve, beautifulsoup4, webencodings, html5lib, train\n",
      "  Found existing installation: numpy 1.15.4\n",
      "    Uninstalling numpy-1.15.4:\u001b[0m\n",
      "\u001b[34m      Successfully uninstalled numpy-1.15.4\u001b[0m\n",
      "\u001b[34mSuccessfully installed beautifulsoup4-4.9.3 html5lib-1.1 joblib-0.14.1 nltk-3.5 numpy-1.18.5 pandas-0.24.2 pytz-2020.4 regex-2020.10.28 soupsieve-2.0.1 tqdm-4.51.0 train-1.0.0 webencodings-0.5.1\u001b[0m\n",
      "\u001b[34mYou are using pip version 18.1, however version 20.3b1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-11-11 13:24:20,973 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"user_entry_point\": \"train.py\",\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"job_name\": \"sagemaker-pytorch-2020-11-11-13-19-54-407\",\n",
      "    \"num_gpus\": 1,\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"hyperparameters\": {\n",
      "        \"hidden_dim\": 100,\n",
      "        \"epochs\": 15\n",
      "    },\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-11-13-19-54-407/source/sourcedir.tar.gz\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"log_level\": 20,\n",
      "    \"module_name\": \"train\",\n",
      "    \"resource_config\": {\n",
      "        \"network_interface_name\": \"eth0\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"current_host\": \"algo-1\"\n",
      "    },\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"RecordWrapperType\": \"None\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\"\n",
      "        }\n",
      "    },\n",
      "    \"additional_framework_parameters\": {}\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=15\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/lib/python35.zip:/usr/lib/python3.5:/usr/lib/python3.5/plat-x86_64-linux-gnu:/usr/lib/python3.5/lib-dynload:/usr/local/lib/python3.5/dist-packages:/usr/lib/python3/dist-packages\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":15,\"hidden_dim\":100},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"job_name\":\"sagemaker-pytorch-2020-11-11-13-19-54-407\",\"log_level\":20,\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-11-13-19-54-407/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN_DIM=100\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":15,\"hidden_dim\":100}\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"15\",\"--hidden_dim\",\"100\"]\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-11-13-19-54-407/source/sourcedir.tar.gz\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m train --epochs 15 --hidden_dim 100\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing device cuda.\u001b[0m\n",
      "\u001b[34mGet train data loader.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mModel loaded with embedding_dim 35, hidden_dim 100, vocab_size 5000.\u001b[0m\n",
      "\u001b[34mEpoch: 1, BCELoss: 0.6667190194129944\u001b[0m\n",
      "\u001b[34mEpoch: 2, BCELoss: 0.4784893908283927\u001b[0m\n",
      "\u001b[34mEpoch: 3, BCELoss: 0.28363124484365637\u001b[0m\n",
      "\u001b[34mEpoch: 4, BCELoss: 0.13582424006678842\u001b[0m\n",
      "\u001b[34mEpoch: 5, BCELoss: 0.07632480764930899\u001b[0m\n",
      "\u001b[34mEpoch: 6, BCELoss: 0.05438657951625911\u001b[0m\n",
      "\u001b[34mEpoch: 7, BCELoss: 0.049250575798478996\u001b[0m\n",
      "\u001b[34mEpoch: 8, BCELoss: 0.04602062092585997\u001b[0m\n",
      "\u001b[34mEpoch: 9, BCELoss: 0.04170106876302849\u001b[0m\n",
      "\u001b[34mEpoch: 10, BCELoss: 0.041089638051661576\u001b[0m\n",
      "\u001b[34mEpoch: 11, BCELoss: 0.039924177933822975\u001b[0m\n",
      "\u001b[34mEpoch: 12, BCELoss: 0.03944244642149319\u001b[0m\n",
      "\u001b[34mEpoch: 13, BCELoss: 0.039317225190726196\u001b[0m\n",
      "\u001b[34mEpoch: 14, BCELoss: 0.03904684700749137\u001b[0m\n",
      "\u001b[34mEpoch: 15, BCELoss: 0.03896623697470535\u001b[0m\n",
      "\u001b[34m2020-11-11 13:24:29,673 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-11-11 13:24:41 Uploading - Uploading generated training model\n",
      "2020-11-11 13:24:41 Completed - Training job completed\n",
      "Training seconds: 94\n",
      "Billable seconds: 94\n",
      "---------------!"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted sagemaker-pytorch-2020-11-11-13-25-08-582\n",
      "2020-11-11 13:32:41 Starting - Starting the training job...\n",
      "2020-11-11 13:32:43 Starting - Launching requested ML instances......\n",
      "2020-11-11 13:34:05 Starting - Preparing the instances for training.........\n",
      "2020-11-11 13:35:23 Downloading - Downloading input data...\n",
      "2020-11-11 13:36:03 Training - Downloading the training image...\n",
      "2020-11-11 13:36:28 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-11-11 13:36:29,074 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-11-11 13:36:29,097 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-11-11 13:36:32,110 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-11-11 13:36:32,362 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-11-11 13:36:32,362 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-11-11 13:36:32,362 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-11-11 13:36:32,362 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pip install -U . -r requirements.txt\u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mCollecting pandas (from -r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/74/24/0cdbf8907e1e3bc5a8da03345c23cbed7044330bb8f73bb12e711a640a00/pandas-0.24.2-cp35-cp35m-manylinux1_x86_64.whl (10.0MB)\u001b[0m\n",
      "\u001b[34mCollecting numpy (from -r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34m  Downloading https://files.pythonhosted.org/packages/b5/36/88723426b4ff576809fec7d73594fe17a35c27f8d01f93637637a29ae25b/numpy-1.18.5-cp35-cp35m-manylinux1_x86_64.whl (19.9MB)\u001b[0m\n",
      "\u001b[34mCollecting nltk (from -r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\u001b[0m\n",
      "\u001b[34mCollecting beautifulsoup4 (from -r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/41/e6495bd7d3781cee623ce23ea6ac73282a373088fcd0ddc809a047b18eae/beautifulsoup4-4.9.3-py3-none-any.whl (115kB)\u001b[0m\n",
      "\u001b[34mCollecting html5lib (from -r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/6c/dd/a834df6482147d48e225a49515aabc28974ad5a4ca3215c18a882565b028/html5lib-1.1-py2.py3-none-any.whl (112kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /usr/local/lib/python3.5/dist-packages (from pandas->-r requirements.txt (line 1)) (2.7.5)\u001b[0m\n",
      "\u001b[34mCollecting pytz>=2011k (from pandas->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/12/f8/ff09af6ff61a3efaad5f61ba5facdf17e7722c4393f7d8a66674d2dbd29f/pytz-2020.4-py2.py3-none-any.whl (509kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.5/dist-packages (from nltk->-r requirements.txt (line 3)) (7.0)\u001b[0m\n",
      "\u001b[34mCollecting joblib (from nltk->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/28/5c/cf6a2b65a321c4a209efcdf64c2689efae2cb62661f8f6f4bb28547cf1bf/joblib-0.14.1-py2.py3-none-any.whl (294kB)\u001b[0m\n",
      "\u001b[34mCollecting regex (from nltk->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34m  Downloading https://files.pythonhosted.org/packages/fb/ef/8880ca0f2bc2e51a39aacf62a81947971aea42b3b54ca58111b5a5ba6e05/regex-2020.10.28.tar.gz (694kB)\u001b[0m\n",
      "\u001b[34mCollecting tqdm (from nltk->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/93/3a/96b3dc293aa72443cf9627444c3c221a7ba34bb622e4d8bf1b5d4f2d9d08/tqdm-4.51.0-py2.py3-none-any.whl (70kB)\u001b[0m\n",
      "\u001b[34mCollecting soupsieve>1.2; python_version >= \"3.0\" (from beautifulsoup4->-r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/6f/8f/457f4a5390eeae1cc3aeab89deb7724c965be841ffca6cfca9197482e470/soupsieve-2.0.1-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mCollecting webencodings (from html5lib->-r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/f4/24/2a3e3df732393fed8b3ebf2ec078f05546de641fe1b667ee316ec1dcf3b7/webencodings-0.5.1-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: six>=1.9 in /usr/local/lib/python3.5/dist-packages (from html5lib->-r requirements.txt (line 5)) (1.11.0)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: nltk, train, regex\n",
      "  Running setup.py bdist_wheel for nltk: started\n",
      "  Running setup.py bdist_wheel for nltk: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n",
      "  Running setup.py bdist_wheel for train: started\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for train: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-umnn14nn/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\n",
      "  Running setup.py bdist_wheel for regex: started\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for regex: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/16/32/f2/87817e06026bddd4f4f63c497c1c9587c028bdf57485e52e0f\u001b[0m\n",
      "\u001b[34mSuccessfully built nltk train regex\u001b[0m\n",
      "\u001b[34mInstalling collected packages: numpy, pytz, pandas, joblib, regex, tqdm, nltk, soupsieve, beautifulsoup4, webencodings, html5lib, train\n",
      "  Found existing installation: numpy 1.15.4\n",
      "    Uninstalling numpy-1.15.4:\u001b[0m\n",
      "\u001b[34m      Successfully uninstalled numpy-1.15.4\u001b[0m\n",
      "\u001b[34mSuccessfully installed beautifulsoup4-4.9.3 html5lib-1.1 joblib-0.14.1 nltk-3.5 numpy-1.18.5 pandas-0.24.2 pytz-2020.4 regex-2020.10.28 soupsieve-2.0.1 tqdm-4.51.0 train-1.0.0 webencodings-0.5.1\u001b[0m\n",
      "\u001b[34mYou are using pip version 18.1, however version 20.3b1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-11-11 13:36:55,203 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-11-13-32-41-149/source/sourcedir.tar.gz\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"hyperparameters\": {\n",
      "        \"hidden_dim\": 200,\n",
      "        \"epochs\": 15\n",
      "    },\n",
      "    \"job_name\": \"sagemaker-pytorch-2020-11-11-13-32-41-149\",\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"log_level\": 20,\n",
      "    \"user_entry_point\": \"train.py\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"num_gpus\": 1,\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"resource_config\": {\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    }\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN_DIM=200\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":15,\"hidden_dim\":200},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"job_name\":\"sagemaker-pytorch-2020-11-11-13-32-41-149\",\"log_level\":20,\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-11-13-32-41-149/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-11-13-32-41-149/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/lib/python35.zip:/usr/lib/python3.5:/usr/lib/python3.5/plat-x86_64-linux-gnu:/usr/lib/python3.5/lib-dynload:/usr/local/lib/python3.5/dist-packages:/usr/lib/python3/dist-packages\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=15\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"15\",\"--hidden_dim\",\"200\"]\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":15,\"hidden_dim\":200}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m train --epochs 15 --hidden_dim 200\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing device cuda.\u001b[0m\n",
      "\u001b[34mGet train data loader.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-11-11 13:37:08 Uploading - Uploading generated training model\u001b[34mModel loaded with embedding_dim 35, hidden_dim 200, vocab_size 5000.\u001b[0m\n",
      "\u001b[34mEpoch: 1, BCELoss: 0.7832662029699846\u001b[0m\n",
      "\u001b[34mEpoch: 2, BCELoss: 0.7070528810674493\u001b[0m\n",
      "\u001b[34mEpoch: 3, BCELoss: 0.6470508141951128\u001b[0m\n",
      "\u001b[34mEpoch: 4, BCELoss: 0.5651451295072382\u001b[0m\n",
      "\u001b[34mEpoch: 5, BCELoss: 0.4686794172633778\u001b[0m\n",
      "\u001b[34mEpoch: 6, BCELoss: 0.36375353011217987\u001b[0m\n",
      "\u001b[34mEpoch: 7, BCELoss: 0.2807423905892806\u001b[0m\n",
      "\u001b[34mEpoch: 8, BCELoss: 0.21410149200396103\u001b[0m\n",
      "\u001b[34mEpoch: 9, BCELoss: 0.15948683294382962\u001b[0m\n",
      "\u001b[34mEpoch: 10, BCELoss: 0.11766727268695831\u001b[0m\n",
      "\u001b[34mEpoch: 11, BCELoss: 0.09834169664166191\u001b[0m\n",
      "\u001b[34mEpoch: 12, BCELoss: 0.0865608433430845\u001b[0m\n",
      "\u001b[34mEpoch: 13, BCELoss: 0.0749292912131006\u001b[0m\n",
      "\u001b[34mEpoch: 14, BCELoss: 0.06582087820226495\u001b[0m\n",
      "\u001b[34mEpoch: 15, BCELoss: 0.055926820771260696\u001b[0m\n",
      "\u001b[34m2020-11-11 13:37:06,300 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-11-11 13:37:15 Completed - Training job completed\n",
      "Training seconds: 112\n",
      "Billable seconds: 112\n",
      "-------------!"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted sagemaker-pytorch-2020-11-11-13-37-54-296\n",
      "2020-11-11 13:44:27 Starting - Starting the training job...\n",
      "2020-11-11 13:44:29 Starting - Launching requested ML instances......\n",
      "2020-11-11 13:45:33 Starting - Preparing the instances for training......\n",
      "2020-11-11 13:46:41 Downloading - Downloading input data...\n",
      "2020-11-11 13:47:27 Training - Downloading the training image...\n",
      "2020-11-11 13:47:50 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-11-11 13:47:51,192 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-11-11 13:47:51,220 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-11-11 13:47:52,635 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-11-11 13:47:52,915 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-11-11 13:47:52,916 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-11-11 13:47:52,916 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-11-11 13:47:52,916 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pip install -U . -r requirements.txt\u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mCollecting pandas (from -r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/74/24/0cdbf8907e1e3bc5a8da03345c23cbed7044330bb8f73bb12e711a640a00/pandas-0.24.2-cp35-cp35m-manylinux1_x86_64.whl (10.0MB)\u001b[0m\n",
      "\u001b[34mCollecting numpy (from -r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/b5/36/88723426b4ff576809fec7d73594fe17a35c27f8d01f93637637a29ae25b/numpy-1.18.5-cp35-cp35m-manylinux1_x86_64.whl (19.9MB)\u001b[0m\n",
      "\u001b[34mCollecting nltk (from -r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\u001b[0m\n",
      "\u001b[34mCollecting beautifulsoup4 (from -r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/41/e6495bd7d3781cee623ce23ea6ac73282a373088fcd0ddc809a047b18eae/beautifulsoup4-4.9.3-py3-none-any.whl (115kB)\u001b[0m\n",
      "\u001b[34mCollecting html5lib (from -r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/6c/dd/a834df6482147d48e225a49515aabc28974ad5a4ca3215c18a882565b028/html5lib-1.1-py2.py3-none-any.whl (112kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /usr/local/lib/python3.5/dist-packages (from pandas->-r requirements.txt (line 1)) (2.7.5)\u001b[0m\n",
      "\u001b[34mCollecting pytz>=2011k (from pandas->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/12/f8/ff09af6ff61a3efaad5f61ba5facdf17e7722c4393f7d8a66674d2dbd29f/pytz-2020.4-py2.py3-none-any.whl (509kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.5/dist-packages (from nltk->-r requirements.txt (line 3)) (7.0)\u001b[0m\n",
      "\u001b[34mCollecting joblib (from nltk->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/28/5c/cf6a2b65a321c4a209efcdf64c2689efae2cb62661f8f6f4bb28547cf1bf/joblib-0.14.1-py2.py3-none-any.whl (294kB)\u001b[0m\n",
      "\u001b[34mCollecting regex (from nltk->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34m  Downloading https://files.pythonhosted.org/packages/fb/ef/8880ca0f2bc2e51a39aacf62a81947971aea42b3b54ca58111b5a5ba6e05/regex-2020.10.28.tar.gz (694kB)\u001b[0m\n",
      "\u001b[34mCollecting tqdm (from nltk->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34m  Downloading https://files.pythonhosted.org/packages/93/3a/96b3dc293aa72443cf9627444c3c221a7ba34bb622e4d8bf1b5d4f2d9d08/tqdm-4.51.0-py2.py3-none-any.whl (70kB)\u001b[0m\n",
      "\u001b[34mCollecting soupsieve>1.2; python_version >= \"3.0\" (from beautifulsoup4->-r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/6f/8f/457f4a5390eeae1cc3aeab89deb7724c965be841ffca6cfca9197482e470/soupsieve-2.0.1-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mCollecting webencodings (from html5lib->-r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/f4/24/2a3e3df732393fed8b3ebf2ec078f05546de641fe1b667ee316ec1dcf3b7/webencodings-0.5.1-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: six>=1.9 in /usr/local/lib/python3.5/dist-packages (from html5lib->-r requirements.txt (line 5)) (1.11.0)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: nltk, train, regex\n",
      "  Running setup.py bdist_wheel for nltk: started\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for nltk: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n",
      "  Running setup.py bdist_wheel for train: started\n",
      "  Running setup.py bdist_wheel for train: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-96tbzkk7/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\n",
      "  Running setup.py bdist_wheel for regex: started\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for regex: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/16/32/f2/87817e06026bddd4f4f63c497c1c9587c028bdf57485e52e0f\u001b[0m\n",
      "\u001b[34mSuccessfully built nltk train regex\u001b[0m\n",
      "\u001b[34mInstalling collected packages: pytz, numpy, pandas, joblib, regex, tqdm, nltk, soupsieve, beautifulsoup4, webencodings, html5lib, train\n",
      "  Found existing installation: numpy 1.15.4\n",
      "    Uninstalling numpy-1.15.4:\n",
      "      Successfully uninstalled numpy-1.15.4\u001b[0m\n",
      "\u001b[34mSuccessfully installed beautifulsoup4-4.9.3 html5lib-1.1 joblib-0.14.1 nltk-3.5 numpy-1.18.5 pandas-0.24.2 pytz-2020.4 regex-2020.10.28 soupsieve-2.0.1 tqdm-4.51.0 train-1.0.0 webencodings-0.5.1\u001b[0m\n",
      "\u001b[34mYou are using pip version 18.1, however version 20.3b1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-11-11 13:48:20,136 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-11-13-44-27-176/source/sourcedir.tar.gz\",\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"log_level\": 20,\n",
      "    \"job_name\": \"sagemaker-pytorch-2020-11-11-13-44-27-176\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"num_gpus\": 1,\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"user_entry_point\": \"train.py\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"hyperparameters\": {\n",
      "        \"hidden_dim\": 10,\n",
      "        \"epochs\": 50\n",
      "    },\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"network_interface_name\": \"eth0\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ]\n",
      "    },\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"RecordWrapperType\": \"None\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\"\n",
      "        }\n",
      "    }\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":50,\"hidden_dim\":10},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"job_name\":\"sagemaker-pytorch-2020-11-11-13-44-27-176\",\"log_level\":20,\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-11-13-44-27-176/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/lib/python35.zip:/usr/lib/python3.5:/usr/lib/python3.5/plat-x86_64-linux-gnu:/usr/lib/python3.5/lib-dynload:/usr/local/lib/python3.5/dist-packages:/usr/lib/python3/dist-packages\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-11-13-44-27-176/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN_DIM=10\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":50,\"hidden_dim\":10}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"50\",\"--hidden_dim\",\"10\"]\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=50\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m train --epochs 50 --hidden_dim 10\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing device cuda.\u001b[0m\n",
      "\u001b[34mGet train data loader.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mModel loaded with embedding_dim 35, hidden_dim 10, vocab_size 5000.\u001b[0m\n",
      "\u001b[34mEpoch: 1, BCELoss: 0.6495233449068937\u001b[0m\n",
      "\u001b[34mEpoch: 2, BCELoss: 0.43837050145322626\u001b[0m\n",
      "\u001b[34mEpoch: 3, BCELoss: 0.25550691377032886\u001b[0m\n",
      "\u001b[34mEpoch: 4, BCELoss: 0.16303673996166748\u001b[0m\n",
      "\u001b[34mEpoch: 5, BCELoss: 0.11842383173379031\u001b[0m\n",
      "\u001b[34mEpoch: 6, BCELoss: 0.09110851314934817\u001b[0m\n",
      "\u001b[34mEpoch: 7, BCELoss: 0.07273957607421008\u001b[0m\n",
      "\u001b[34mEpoch: 8, BCELoss: 0.06245845691724257\u001b[0m\n",
      "\u001b[34mEpoch: 9, BCELoss: 0.0542400638488206\u001b[0m\n",
      "\u001b[34mEpoch: 10, BCELoss: 0.050560817969116295\u001b[0m\n",
      "\u001b[34mEpoch: 11, BCELoss: 0.04798758825795217\u001b[0m\n",
      "\u001b[34mEpoch: 12, BCELoss: 0.04747859727252613\u001b[0m\n",
      "\u001b[34mEpoch: 13, BCELoss: 0.04593367993154309\u001b[0m\n",
      "\u001b[34mEpoch: 14, BCELoss: 0.04505312781442295\u001b[0m\n",
      "\u001b[34mEpoch: 15, BCELoss: 0.043990154157985344\u001b[0m\n",
      "\u001b[34mEpoch: 16, BCELoss: 0.0433864871209318\u001b[0m\n",
      "\u001b[34mEpoch: 17, BCELoss: 0.04212340255352584\u001b[0m\n",
      "\u001b[34mEpoch: 18, BCELoss: 0.04202817075631835\u001b[0m\n",
      "\u001b[34mEpoch: 19, BCELoss: 0.041226361793550576\u001b[0m\n",
      "\u001b[34mEpoch: 20, BCELoss: 0.04108494215390899\u001b[0m\n",
      "\u001b[34mEpoch: 21, BCELoss: 0.04057493551888249\u001b[0m\n",
      "\u001b[34mEpoch: 22, BCELoss: 0.04028048213909973\u001b[0m\n",
      "\u001b[34mEpoch: 23, BCELoss: 0.04009426842358979\u001b[0m\n",
      "\u001b[34mEpoch: 24, BCELoss: 0.03993692367591641\u001b[0m\n",
      "\u001b[34mEpoch: 25, BCELoss: 0.03978480178524147\u001b[0m\n",
      "\u001b[34mEpoch: 26, BCELoss: 0.0396968928927725\u001b[0m\n",
      "\u001b[34mEpoch: 27, BCELoss: 0.03953561593185772\u001b[0m\n",
      "\u001b[34mEpoch: 28, BCELoss: 0.03946873308582739\u001b[0m\n",
      "\u001b[34mEpoch: 29, BCELoss: 0.039396374401721085\u001b[0m\n",
      "\u001b[34mEpoch: 30, BCELoss: 0.039296715266325256\u001b[0m\n",
      "\u001b[34mEpoch: 31, BCELoss: 0.03938224606893279\u001b[0m\n",
      "\u001b[34mEpoch: 32, BCELoss: 0.03917126340622252\u001b[0m\n",
      "\u001b[34mEpoch: 33, BCELoss: 0.03914402916350148\u001b[0m\n",
      "\u001b[34mEpoch: 34, BCELoss: 0.03905232098292221\u001b[0m\n",
      "\u001b[34mEpoch: 35, BCELoss: 0.03900772062214938\u001b[0m\n",
      "\u001b[34mEpoch: 36, BCELoss: 0.03908230940049345\u001b[0m\n",
      "\u001b[34mEpoch: 37, BCELoss: 0.03953480703586882\u001b[0m\n",
      "\u001b[34mEpoch: 38, BCELoss: 0.04057952101257714\u001b[0m\n",
      "\u001b[34mEpoch: 39, BCELoss: 0.056052333251996475\u001b[0m\n",
      "\u001b[34mEpoch: 40, BCELoss: 0.11128637939691544\u001b[0m\n",
      "\u001b[34mEpoch: 41, BCELoss: 0.151249884204431\u001b[0m\n",
      "\u001b[34mEpoch: 42, BCELoss: 0.14839452572844244\u001b[0m\n",
      "\u001b[34mEpoch: 43, BCELoss: 0.12053286216475746\u001b[0m\n",
      "\u001b[34mEpoch: 44, BCELoss: 0.09837587888945233\u001b[0m\n",
      "\u001b[34mEpoch: 45, BCELoss: 0.08182852816852657\u001b[0m\n",
      "\u001b[34mEpoch: 46, BCELoss: 0.07192735848101703\u001b[0m\n",
      "\u001b[34mEpoch: 47, BCELoss: 0.06134305250915614\u001b[0m\n",
      "\u001b[34mEpoch: 48, BCELoss: 0.05794009244577451\u001b[0m\n",
      "\u001b[34mEpoch: 49, BCELoss: 0.055261330171064896\u001b[0m\n",
      "\u001b[34mEpoch: 50, BCELoss: 0.051739649339155716\u001b[0m\n",
      "\u001b[34m2020-11-11 13:48:32,538 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-11-11 13:48:43 Uploading - Uploading generated training model\n",
      "2020-11-11 13:48:43 Completed - Training job completed\n",
      "Training seconds: 122\n",
      "Billable seconds: 122\n",
      "-------------!"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted sagemaker-pytorch-2020-11-11-13-49-10-025\n",
      "2020-11-11 13:55:43 Starting - Starting the training job...\n",
      "2020-11-11 13:55:45 Starting - Launching requested ML instances......\n",
      "2020-11-11 13:57:06 Starting - Preparing the instances for training.........\n",
      "2020-11-11 13:58:18 Downloading - Downloading input data...\n",
      "2020-11-11 13:58:54 Training - Downloading the training image..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-11-11 13:59:24,927 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-11-11 13:59:24,952 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-11-11 13:59:24,956 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-11-11 13:59:25,230 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-11-11 13:59:25,230 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-11-11 13:59:25,231 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-11-11 13:59:25,231 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pip install -U . -r requirements.txt\u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mCollecting pandas (from -r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/74/24/0cdbf8907e1e3bc5a8da03345c23cbed7044330bb8f73bb12e711a640a00/pandas-0.24.2-cp35-cp35m-manylinux1_x86_64.whl (10.0MB)\u001b[0m\n",
      "\u001b[34mCollecting numpy (from -r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/b5/36/88723426b4ff576809fec7d73594fe17a35c27f8d01f93637637a29ae25b/numpy-1.18.5-cp35-cp35m-manylinux1_x86_64.whl (19.9MB)\u001b[0m\n",
      "\u001b[34mCollecting nltk (from -r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\u001b[0m\n",
      "\u001b[34mCollecting beautifulsoup4 (from -r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/41/e6495bd7d3781cee623ce23ea6ac73282a373088fcd0ddc809a047b18eae/beautifulsoup4-4.9.3-py3-none-any.whl (115kB)\u001b[0m\n",
      "\u001b[34mCollecting html5lib (from -r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/6c/dd/a834df6482147d48e225a49515aabc28974ad5a4ca3215c18a882565b028/html5lib-1.1-py2.py3-none-any.whl (112kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /usr/local/lib/python3.5/dist-packages (from pandas->-r requirements.txt (line 1)) (2.7.5)\u001b[0m\n",
      "\u001b[34mCollecting pytz>=2011k (from pandas->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/12/f8/ff09af6ff61a3efaad5f61ba5facdf17e7722c4393f7d8a66674d2dbd29f/pytz-2020.4-py2.py3-none-any.whl (509kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.5/dist-packages (from nltk->-r requirements.txt (line 3)) (7.0)\u001b[0m\n",
      "\u001b[34mCollecting joblib (from nltk->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/28/5c/cf6a2b65a321c4a209efcdf64c2689efae2cb62661f8f6f4bb28547cf1bf/joblib-0.14.1-py2.py3-none-any.whl (294kB)\u001b[0m\n",
      "\u001b[34mCollecting regex (from nltk->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34m  Downloading https://files.pythonhosted.org/packages/fb/ef/8880ca0f2bc2e51a39aacf62a81947971aea42b3b54ca58111b5a5ba6e05/regex-2020.10.28.tar.gz (694kB)\u001b[0m\n",
      "\u001b[34mCollecting tqdm (from nltk->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/93/3a/96b3dc293aa72443cf9627444c3c221a7ba34bb622e4d8bf1b5d4f2d9d08/tqdm-4.51.0-py2.py3-none-any.whl (70kB)\u001b[0m\n",
      "\u001b[34mCollecting soupsieve>1.2; python_version >= \"3.0\" (from beautifulsoup4->-r requirements.txt (line 4))\u001b[0m\n",
      "\n",
      "2020-11-11 13:59:24 Training - Training image download completed. Training in progress.\u001b[34m  Downloading https://files.pythonhosted.org/packages/6f/8f/457f4a5390eeae1cc3aeab89deb7724c965be841ffca6cfca9197482e470/soupsieve-2.0.1-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mCollecting webencodings (from html5lib->-r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/f4/24/2a3e3df732393fed8b3ebf2ec078f05546de641fe1b667ee316ec1dcf3b7/webencodings-0.5.1-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: six>=1.9 in /usr/local/lib/python3.5/dist-packages (from html5lib->-r requirements.txt (line 5)) (1.11.0)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: nltk, train, regex\n",
      "  Running setup.py bdist_wheel for nltk: started\n",
      "  Running setup.py bdist_wheel for nltk: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n",
      "  Running setup.py bdist_wheel for train: started\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for train: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-onxnx650/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\n",
      "  Running setup.py bdist_wheel for regex: started\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for regex: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/16/32/f2/87817e06026bddd4f4f63c497c1c9587c028bdf57485e52e0f\u001b[0m\n",
      "\u001b[34mSuccessfully built nltk train regex\u001b[0m\n",
      "\u001b[34mInstalling collected packages: numpy, pytz, pandas, joblib, regex, tqdm, nltk, soupsieve, beautifulsoup4, webencodings, html5lib, train\n",
      "  Found existing installation: numpy 1.15.4\u001b[0m\n",
      "\u001b[34m    Uninstalling numpy-1.15.4:\n",
      "      Successfully uninstalled numpy-1.15.4\u001b[0m\n",
      "\u001b[34mSuccessfully installed beautifulsoup4-4.9.3 html5lib-1.1 joblib-0.14.1 nltk-3.5 numpy-1.18.5 pandas-0.24.2 pytz-2020.4 regex-2020.10.28 soupsieve-2.0.1 tqdm-4.51.0 train-1.0.0 webencodings-0.5.1\u001b[0m\n",
      "\u001b[34mYou are using pip version 18.1, however version 20.3b1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-11-11 13:59:47,965 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"resource_config\": {\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\",\n",
      "        \"current_host\": \"algo-1\"\n",
      "    },\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"job_name\": \"sagemaker-pytorch-2020-11-11-13-55-43-125\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"num_gpus\": 1,\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\",\n",
      "            \"TrainingInputMode\": \"File\"\n",
      "        }\n",
      "    },\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 50,\n",
      "        \"hidden_dim\": 100\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\",\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-11-13-55-43-125/source/sourcedir.tar.gz\",\n",
      "    \"log_level\": 20,\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=50\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":50,\"hidden_dim\":100}\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/lib/python35.zip:/usr/lib/python3.5:/usr/lib/python3.5/plat-x86_64-linux-gnu:/usr/lib/python3.5/lib-dynload:/usr/local/lib/python3.5/dist-packages:/usr/lib/python3/dist-packages\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN_DIM=100\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-11-13-55-43-125/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"50\",\"--hidden_dim\",\"100\"]\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":50,\"hidden_dim\":100},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"job_name\":\"sagemaker-pytorch-2020-11-11-13-55-43-125\",\"log_level\":20,\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-11-13-55-43-125/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m train --epochs 50 --hidden_dim 100\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing device cuda.\u001b[0m\n",
      "\u001b[34mGet train data loader.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mModel loaded with embedding_dim 35, hidden_dim 100, vocab_size 5000.\u001b[0m\n",
      "\u001b[34mEpoch: 1, BCELoss: 0.6667190194129944\u001b[0m\n",
      "\u001b[34mEpoch: 2, BCELoss: 0.4784893908283927\u001b[0m\n",
      "\u001b[34mEpoch: 3, BCELoss: 0.28363124484365637\u001b[0m\n",
      "\u001b[34mEpoch: 4, BCELoss: 0.13582424006678842\u001b[0m\n",
      "\u001b[34mEpoch: 5, BCELoss: 0.07632480764930899\u001b[0m\n",
      "\u001b[34mEpoch: 6, BCELoss: 0.05438657951625911\u001b[0m\n",
      "\u001b[34mEpoch: 7, BCELoss: 0.049250575798478996\u001b[0m\n",
      "\u001b[34mEpoch: 8, BCELoss: 0.04602062092585997\u001b[0m\n",
      "\u001b[34mEpoch: 9, BCELoss: 0.04170106876302849\u001b[0m\n",
      "\u001b[34mEpoch: 10, BCELoss: 0.041089638051661576\u001b[0m\n",
      "\u001b[34mEpoch: 11, BCELoss: 0.039924177933822975\u001b[0m\n",
      "\u001b[34mEpoch: 12, BCELoss: 0.03944244642149319\u001b[0m\n",
      "\u001b[34mEpoch: 13, BCELoss: 0.039317225190726196\u001b[0m\n",
      "\u001b[34mEpoch: 14, BCELoss: 0.03904684700749137\u001b[0m\n",
      "\u001b[34mEpoch: 15, BCELoss: 0.03896623697470535\u001b[0m\n",
      "\u001b[34mEpoch: 16, BCELoss: 0.03883494470607151\u001b[0m\n",
      "\u001b[34mEpoch: 17, BCELoss: 0.038811511444774544\u001b[0m\n",
      "\u001b[34mEpoch: 18, BCELoss: 0.03868978910825469\u001b[0m\n",
      "\u001b[34mEpoch: 19, BCELoss: 0.03868700597773899\u001b[0m\n",
      "\u001b[34mEpoch: 20, BCELoss: 0.03856699608943679\u001b[0m\n",
      "\u001b[34mEpoch: 21, BCELoss: 0.03858704780313102\u001b[0m\n",
      "\u001b[34mEpoch: 22, BCELoss: 0.0384720540182157\u001b[0m\n",
      "\n",
      "2020-11-11 14:00:12 Uploading - Uploading generated training model\n",
      "2020-11-11 14:00:12 Completed - Training job completed\n",
      "\u001b[34mEpoch: 23, BCELoss: 0.038518319922414695\u001b[0m\n",
      "\u001b[34mEpoch: 24, BCELoss: 0.038400874388488854\u001b[0m\n",
      "\u001b[34mEpoch: 25, BCELoss: 0.03846805915236473\u001b[0m\n",
      "\u001b[34mEpoch: 26, BCELoss: 0.03833675469187173\u001b[0m\n",
      "\u001b[34mEpoch: 27, BCELoss: 0.03841184672306885\u001b[0m\n",
      "\u001b[34mEpoch: 28, BCELoss: 0.03827736357396299\u001b[0m\n",
      "\u001b[34mEpoch: 29, BCELoss: 0.03838069432161071\u001b[0m\n",
      "\u001b[34mEpoch: 30, BCELoss: 0.03822610120881687\u001b[0m\n",
      "\u001b[34mEpoch: 31, BCELoss: 0.038251910866661507\u001b[0m\n",
      "\u001b[34mEpoch: 32, BCELoss: 0.03815455819395455\u001b[0m\n",
      "\u001b[34mEpoch: 33, BCELoss: 0.03816565210846337\u001b[0m\n",
      "\u001b[34mEpoch: 34, BCELoss: 0.03810613450001587\u001b[0m\n",
      "\u001b[34mEpoch: 35, BCELoss: 0.03812423551624471\u001b[0m\n",
      "\u001b[34mEpoch: 36, BCELoss: 0.03807250545783476\u001b[0m\n",
      "\u001b[34mEpoch: 37, BCELoss: 0.03809132477776571\u001b[0m\n",
      "\u001b[34mEpoch: 38, BCELoss: 0.03804490630599586\u001b[0m\n",
      "\u001b[34mEpoch: 39, BCELoss: 0.038063949312676086\u001b[0m\n",
      "\u001b[34mEpoch: 40, BCELoss: 0.03801885789090937\u001b[0m\n",
      "\u001b[34mEpoch: 41, BCELoss: 0.038039404221556404\u001b[0m\n",
      "\u001b[34mEpoch: 42, BCELoss: 0.03799422931942073\u001b[0m\n",
      "\u001b[34mEpoch: 43, BCELoss: 0.038015377961776474\u001b[0m\n",
      "\u001b[34mEpoch: 44, BCELoss: 0.03797121142799204\u001b[0m\n",
      "\u001b[34mEpoch: 45, BCELoss: 0.03799167309295048\u001b[0m\n",
      "\u001b[34mEpoch: 46, BCELoss: 0.03795031051744114\u001b[0m\n",
      "\u001b[34mEpoch: 47, BCELoss: 0.03796906870874492\u001b[0m\n",
      "\u001b[34mEpoch: 48, BCELoss: 0.037931954826820984\u001b[0m\n",
      "\u001b[34mEpoch: 49, BCELoss: 0.0379483008926565\u001b[0m\n",
      "\u001b[34mEpoch: 50, BCELoss: 0.03791608170352199\u001b[0m\n",
      "\u001b[34m2020-11-11 14:00:04,824 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "Training seconds: 114\n",
      "Billable seconds: 114\n",
      "-----------------!"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted sagemaker-pytorch-2020-11-11-14-00-26-149\n",
      "2020-11-11 14:09:00 Starting - Starting the training job...\n",
      "2020-11-11 14:09:02 Starting - Launching requested ML instances......\n",
      "2020-11-11 14:10:06 Starting - Preparing the instances for training......-!"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted sagemaker-pytorch-2020-11-11-14-13-43-457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-11 14:20:17 Starting - Starting the training job...\n",
      "2020-11-11 14:20:19 Starting - Launching requested ML instances......\n",
      "2020-11-11 14:21:38 Starting - Preparing the instances for training.........\n",
      "2020-11-11 14:23:02 Downloading - Downloading input data...\n",
      "2020-11-11 14:23:38 Training - Downloading the training image...\n",
      "2020-11-11 14:24:10 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-11-11 14:24:11,024 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-11-11 14:24:11,052 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-11-11 14:24:11,056 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-11-11 14:24:11,324 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-11-11 14:24:11,324 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-11-11 14:24:11,324 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-11-11 14:24:11,325 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pip install -U . -r requirements.txt\u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mCollecting pandas (from -r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/74/24/0cdbf8907e1e3bc5a8da03345c23cbed7044330bb8f73bb12e711a640a00/pandas-0.24.2-cp35-cp35m-manylinux1_x86_64.whl (10.0MB)\u001b[0m\n",
      "\u001b[34mCollecting numpy (from -r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/b5/36/88723426b4ff576809fec7d73594fe17a35c27f8d01f93637637a29ae25b/numpy-1.18.5-cp35-cp35m-manylinux1_x86_64.whl (19.9MB)\u001b[0m\n",
      "\u001b[34mCollecting nltk (from -r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\u001b[0m\n",
      "\u001b[34mCollecting beautifulsoup4 (from -r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/41/e6495bd7d3781cee623ce23ea6ac73282a373088fcd0ddc809a047b18eae/beautifulsoup4-4.9.3-py3-none-any.whl (115kB)\u001b[0m\n",
      "\u001b[34mCollecting html5lib (from -r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/6c/dd/a834df6482147d48e225a49515aabc28974ad5a4ca3215c18a882565b028/html5lib-1.1-py2.py3-none-any.whl (112kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /usr/local/lib/python3.5/dist-packages (from pandas->-r requirements.txt (line 1)) (2.7.5)\u001b[0m\n",
      "\u001b[34mCollecting pytz>=2011k (from pandas->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/12/f8/ff09af6ff61a3efaad5f61ba5facdf17e7722c4393f7d8a66674d2dbd29f/pytz-2020.4-py2.py3-none-any.whl (509kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.5/dist-packages (from nltk->-r requirements.txt (line 3)) (7.0)\u001b[0m\n",
      "\u001b[34mCollecting joblib (from nltk->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/28/5c/cf6a2b65a321c4a209efcdf64c2689efae2cb62661f8f6f4bb28547cf1bf/joblib-0.14.1-py2.py3-none-any.whl (294kB)\u001b[0m\n",
      "\u001b[34mCollecting regex (from nltk->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/fb/ef/8880ca0f2bc2e51a39aacf62a81947971aea42b3b54ca58111b5a5ba6e05/regex-2020.10.28.tar.gz (694kB)\u001b[0m\n",
      "\u001b[34mCollecting tqdm (from nltk->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/93/3a/96b3dc293aa72443cf9627444c3c221a7ba34bb622e4d8bf1b5d4f2d9d08/tqdm-4.51.0-py2.py3-none-any.whl (70kB)\u001b[0m\n",
      "\u001b[34mCollecting soupsieve>1.2; python_version >= \"3.0\" (from beautifulsoup4->-r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/6f/8f/457f4a5390eeae1cc3aeab89deb7724c965be841ffca6cfca9197482e470/soupsieve-2.0.1-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mCollecting webencodings (from html5lib->-r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/f4/24/2a3e3df732393fed8b3ebf2ec078f05546de641fe1b667ee316ec1dcf3b7/webencodings-0.5.1-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: six>=1.9 in /usr/local/lib/python3.5/dist-packages (from html5lib->-r requirements.txt (line 5)) (1.11.0)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: nltk, train, regex\n",
      "  Running setup.py bdist_wheel for nltk: started\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for nltk: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n",
      "  Running setup.py bdist_wheel for train: started\n",
      "  Running setup.py bdist_wheel for train: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-tc39lloq/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\n",
      "  Running setup.py bdist_wheel for regex: started\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for regex: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/16/32/f2/87817e06026bddd4f4f63c497c1c9587c028bdf57485e52e0f\u001b[0m\n",
      "\u001b[34mSuccessfully built nltk train regex\u001b[0m\n",
      "\u001b[34mInstalling collected packages: numpy, pytz, pandas, joblib, regex, tqdm, nltk, soupsieve, beautifulsoup4, webencodings, html5lib, train\n",
      "  Found existing installation: numpy 1.15.4\n",
      "    Uninstalling numpy-1.15.4:\n",
      "      Successfully uninstalled numpy-1.15.4\u001b[0m\n",
      "\u001b[34mSuccessfully installed beautifulsoup4-4.9.3 html5lib-1.1 joblib-0.14.1 nltk-3.5 numpy-1.18.5 pandas-0.24.2 pytz-2020.4 regex-2020.10.28 soupsieve-2.0.1 tqdm-4.51.0 train-1.0.0 webencodings-0.5.1\u001b[0m\n",
      "\u001b[34mYou are using pip version 18.1, however version 20.3b1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-11-11 14:24:37,281 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_gpus\": 1,\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\",\n",
      "            \"TrainingInputMode\": \"File\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"hyperparameters\": {\n",
      "        \"hidden_dim\": 10,\n",
      "        \"epochs\": 15\n",
      "    },\n",
      "    \"num_cpus\": 4,\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"user_entry_point\": \"train.py\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-11-14-20-16-988/source/sourcedir.tar.gz\",\n",
      "    \"job_name\": \"sagemaker-pytorch-2020-11-11-14-20-16-988\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"resource_config\": {\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\",\n",
      "        \"current_host\": \"algo-1\"\n",
      "    },\n",
      "    \"log_level\": 20,\n",
      "    \"module_name\": \"train\",\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"current_host\": \"algo-1\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"15\",\"--hidden_dim\",\"10\"]\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=15\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":15,\"hidden_dim\":10}\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":15,\"hidden_dim\":10},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"job_name\":\"sagemaker-pytorch-2020-11-11-14-20-16-988\",\"log_level\":20,\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-11-14-20-16-988/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/lib/python35.zip:/usr/lib/python3.5:/usr/lib/python3.5/plat-x86_64-linux-gnu:/usr/lib/python3.5/lib-dynload:/usr/local/lib/python3.5/dist-packages:/usr/lib/python3/dist-packages\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-11-14-20-16-988/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN_DIM=10\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m train --epochs 15 --hidden_dim 10\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing device cuda.\u001b[0m\n",
      "\u001b[34mGet train data loader.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mModel loaded with embedding_dim 35, hidden_dim 10, vocab_size 5000.\u001b[0m\n",
      "\u001b[34mEpoch: 1, BCELoss: 0.6495233449068937\u001b[0m\n",
      "\u001b[34mEpoch: 2, BCELoss: 0.43837050145322626\u001b[0m\n",
      "\u001b[34mEpoch: 3, BCELoss: 0.25550691377032886\u001b[0m\n",
      "\u001b[34mEpoch: 4, BCELoss: 0.16303673996166748\u001b[0m\n",
      "\u001b[34mEpoch: 5, BCELoss: 0.11842383173379031\u001b[0m\n",
      "\u001b[34mEpoch: 6, BCELoss: 0.09110851314934817\u001b[0m\n",
      "\u001b[34mEpoch: 7, BCELoss: 0.07273957607421008\u001b[0m\n",
      "\u001b[34mEpoch: 8, BCELoss: 0.06245845691724257\u001b[0m\n",
      "\u001b[34mEpoch: 9, BCELoss: 0.0542400638488206\u001b[0m\n",
      "\u001b[34mEpoch: 10, BCELoss: 0.050560817969116295\u001b[0m\n",
      "\u001b[34mEpoch: 11, BCELoss: 0.04798758825795217\u001b[0m\n",
      "\u001b[34mEpoch: 12, BCELoss: 0.04747859727252613\u001b[0m\n",
      "\u001b[34mEpoch: 13, BCELoss: 0.04593367993154309\u001b[0m\n",
      "\u001b[34mEpoch: 14, BCELoss: 0.04505312781442295\u001b[0m\n",
      "\u001b[34mEpoch: 15, BCELoss: 0.043990154157985344\u001b[0m\n",
      "\u001b[34m2020-11-11 14:24:46,994 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-11-11 14:24:58 Uploading - Uploading generated training model\n",
      "2020-11-11 14:24:58 Completed - Training job completed\n",
      "Training seconds: 116\n",
      "Billable seconds: 116\n",
      "-------------!"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted sagemaker-pytorch-2020-11-11-14-25-31-432\n",
      "2020-11-11 14:32:04 Starting - Starting the training job...\n",
      "2020-11-11 14:32:05 Starting - Launching requested ML instances......\n",
      "2020-11-11 14:33:10 Starting - Preparing the instances for training......\n",
      "2020-11-11 14:34:15 Downloading - Downloading input data...\n",
      "2020-11-11 14:34:54 Training - Downloading the training image...\n",
      "2020-11-11 14:35:23 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-11-11 14:35:24,049 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-11-11 14:35:24,078 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-11-11 14:35:24,706 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-11-11 14:35:24,983 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-11-11 14:35:24,984 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-11-11 14:35:24,984 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-11-11 14:35:24,984 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pip install -U . -r requirements.txt\u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mCollecting pandas (from -r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34m  Downloading https://files.pythonhosted.org/packages/74/24/0cdbf8907e1e3bc5a8da03345c23cbed7044330bb8f73bb12e711a640a00/pandas-0.24.2-cp35-cp35m-manylinux1_x86_64.whl (10.0MB)\u001b[0m\n",
      "\u001b[34mCollecting numpy (from -r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/b5/36/88723426b4ff576809fec7d73594fe17a35c27f8d01f93637637a29ae25b/numpy-1.18.5-cp35-cp35m-manylinux1_x86_64.whl (19.9MB)\u001b[0m\n",
      "\u001b[34mCollecting nltk (from -r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\u001b[0m\n",
      "\u001b[34mCollecting beautifulsoup4 (from -r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/41/e6495bd7d3781cee623ce23ea6ac73282a373088fcd0ddc809a047b18eae/beautifulsoup4-4.9.3-py3-none-any.whl (115kB)\u001b[0m\n",
      "\u001b[34mCollecting html5lib (from -r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/6c/dd/a834df6482147d48e225a49515aabc28974ad5a4ca3215c18a882565b028/html5lib-1.1-py2.py3-none-any.whl (112kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /usr/local/lib/python3.5/dist-packages (from pandas->-r requirements.txt (line 1)) (2.7.5)\u001b[0m\n",
      "\u001b[34mCollecting pytz>=2011k (from pandas->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/12/f8/ff09af6ff61a3efaad5f61ba5facdf17e7722c4393f7d8a66674d2dbd29f/pytz-2020.4-py2.py3-none-any.whl (509kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.5/dist-packages (from nltk->-r requirements.txt (line 3)) (7.0)\u001b[0m\n",
      "\u001b[34mCollecting joblib (from nltk->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/28/5c/cf6a2b65a321c4a209efcdf64c2689efae2cb62661f8f6f4bb28547cf1bf/joblib-0.14.1-py2.py3-none-any.whl (294kB)\u001b[0m\n",
      "\u001b[34mCollecting regex (from nltk->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/fb/ef/8880ca0f2bc2e51a39aacf62a81947971aea42b3b54ca58111b5a5ba6e05/regex-2020.10.28.tar.gz (694kB)\u001b[0m\n",
      "\u001b[34mCollecting tqdm (from nltk->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/93/3a/96b3dc293aa72443cf9627444c3c221a7ba34bb622e4d8bf1b5d4f2d9d08/tqdm-4.51.0-py2.py3-none-any.whl (70kB)\u001b[0m\n",
      "\u001b[34mCollecting soupsieve>1.2; python_version >= \"3.0\" (from beautifulsoup4->-r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/6f/8f/457f4a5390eeae1cc3aeab89deb7724c965be841ffca6cfca9197482e470/soupsieve-2.0.1-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mCollecting webencodings (from html5lib->-r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/f4/24/2a3e3df732393fed8b3ebf2ec078f05546de641fe1b667ee316ec1dcf3b7/webencodings-0.5.1-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: six>=1.9 in /usr/local/lib/python3.5/dist-packages (from html5lib->-r requirements.txt (line 5)) (1.11.0)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: nltk, train, regex\n",
      "  Running setup.py bdist_wheel for nltk: started\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for nltk: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n",
      "  Running setup.py bdist_wheel for train: started\n",
      "  Running setup.py bdist_wheel for train: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-r_ic02oa/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\n",
      "  Running setup.py bdist_wheel for regex: started\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for regex: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/16/32/f2/87817e06026bddd4f4f63c497c1c9587c028bdf57485e52e0f\u001b[0m\n",
      "\u001b[34mSuccessfully built nltk train regex\u001b[0m\n",
      "\u001b[34mInstalling collected packages: numpy, pytz, pandas, joblib, regex, tqdm, nltk, soupsieve, beautifulsoup4, webencodings, html5lib, train\n",
      "  Found existing installation: numpy 1.15.4\n",
      "    Uninstalling numpy-1.15.4:\u001b[0m\n",
      "\u001b[34m      Successfully uninstalled numpy-1.15.4\u001b[0m\n",
      "\u001b[34mSuccessfully installed beautifulsoup4-4.9.3 html5lib-1.1 joblib-0.14.1 nltk-3.5 numpy-1.18.5 pandas-0.24.2 pytz-2020.4 regex-2020.10.28 soupsieve-2.0.1 tqdm-4.51.0 train-1.0.0 webencodings-0.5.1\u001b[0m\n",
      "\u001b[34mYou are using pip version 18.1, however version 20.3b1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-11-11 14:35:48,575 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-11-14-32-03-574/source/sourcedir.tar.gz\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"user_entry_point\": \"train.py\",\n",
      "    \"log_level\": 20,\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 15,\n",
      "        \"hidden_dim\": 100\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"job_name\": \"sagemaker-pytorch-2020-11-11-14-32-03-574\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"num_gpus\": 1,\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"resource_config\": {\n",
      "        \"network_interface_name\": \"eth0\",\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ]\n",
      "    },\n",
      "    \"module_name\": \"train\",\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":15,\"hidden_dim\":100},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"job_name\":\"sagemaker-pytorch-2020-11-11-14-32-03-574\",\"log_level\":20,\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-11-14-32-03-574/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"15\",\"--hidden_dim\",\"100\"]\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":15,\"hidden_dim\":100}\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN_DIM=100\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-11-14-32-03-574/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/lib/python35.zip:/usr/lib/python3.5:/usr/lib/python3.5/plat-x86_64-linux-gnu:/usr/lib/python3.5/lib-dynload:/usr/local/lib/python3.5/dist-packages:/usr/lib/python3/dist-packages\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=15\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m train --epochs 15 --hidden_dim 100\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing device cuda.\u001b[0m\n",
      "\u001b[34mGet train data loader.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-11-11 14:36:04 Uploading - Uploading generated training model\u001b[34mModel loaded with embedding_dim 35, hidden_dim 100, vocab_size 5000.\u001b[0m\n",
      "\u001b[34mEpoch: 1, BCELoss: 0.6667190194129944\u001b[0m\n",
      "\u001b[34mEpoch: 2, BCELoss: 0.4784893908283927\u001b[0m\n",
      "\u001b[34mEpoch: 3, BCELoss: 0.28363124484365637\u001b[0m\n",
      "\u001b[34mEpoch: 4, BCELoss: 0.13582424006678842\u001b[0m\n",
      "\u001b[34mEpoch: 5, BCELoss: 0.07632480764930899\u001b[0m\n",
      "\u001b[34mEpoch: 6, BCELoss: 0.05438657951625911\u001b[0m\n",
      "\u001b[34mEpoch: 7, BCELoss: 0.049250575798478996\u001b[0m\n",
      "\u001b[34mEpoch: 8, BCELoss: 0.04602062092585997\u001b[0m\n",
      "\u001b[34mEpoch: 9, BCELoss: 0.04170106876302849\u001b[0m\n",
      "\u001b[34mEpoch: 10, BCELoss: 0.041089638051661576\u001b[0m\n",
      "\u001b[34mEpoch: 11, BCELoss: 0.039924177933822975\u001b[0m\n",
      "\u001b[34mEpoch: 12, BCELoss: 0.03944244642149319\u001b[0m\n",
      "\u001b[34mEpoch: 13, BCELoss: 0.039317225190726196\u001b[0m\n",
      "\u001b[34mEpoch: 14, BCELoss: 0.03904684700749137\u001b[0m\n",
      "\u001b[34mEpoch: 15, BCELoss: 0.03896623697470535\u001b[0m\n",
      "\u001b[34m2020-11-11 14:35:59,520 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-11-11 14:36:11 Completed - Training job completed\n",
      "Training seconds: 116\n",
      "Billable seconds: 116\n",
      "-------------!"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted sagemaker-pytorch-2020-11-11-14-36-46-821\n",
      "2020-11-11 14:43:19 Starting - Starting the training job...\n",
      "2020-11-11 14:43:21 Starting - Launching requested ML instances......\n",
      "2020-11-11 14:44:47 Starting - Preparing the instances for training.........\n",
      "2020-11-11 14:46:00 Downloading - Downloading input data...\n",
      "2020-11-11 14:46:35 Training - Downloading the training image...\n",
      "2020-11-11 14:47:06 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-11-11 14:47:06,720 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-11-11 14:47:06,744 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-11-11 14:47:06,747 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-11-11 14:47:06,977 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-11-11 14:47:06,977 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-11-11 14:47:06,977 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-11-11 14:47:06,977 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pip install -U . -r requirements.txt\u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mCollecting pandas (from -r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/74/24/0cdbf8907e1e3bc5a8da03345c23cbed7044330bb8f73bb12e711a640a00/pandas-0.24.2-cp35-cp35m-manylinux1_x86_64.whl (10.0MB)\u001b[0m\n",
      "\u001b[34mCollecting numpy (from -r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34m  Downloading https://files.pythonhosted.org/packages/b5/36/88723426b4ff576809fec7d73594fe17a35c27f8d01f93637637a29ae25b/numpy-1.18.5-cp35-cp35m-manylinux1_x86_64.whl (19.9MB)\u001b[0m\n",
      "\u001b[34mCollecting nltk (from -r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34m  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\u001b[0m\n",
      "\u001b[34mCollecting beautifulsoup4 (from -r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/41/e6495bd7d3781cee623ce23ea6ac73282a373088fcd0ddc809a047b18eae/beautifulsoup4-4.9.3-py3-none-any.whl (115kB)\u001b[0m\n",
      "\u001b[34mCollecting html5lib (from -r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/6c/dd/a834df6482147d48e225a49515aabc28974ad5a4ca3215c18a882565b028/html5lib-1.1-py2.py3-none-any.whl (112kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /usr/local/lib/python3.5/dist-packages (from pandas->-r requirements.txt (line 1)) (2.7.5)\u001b[0m\n",
      "\u001b[34mCollecting pytz>=2011k (from pandas->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/12/f8/ff09af6ff61a3efaad5f61ba5facdf17e7722c4393f7d8a66674d2dbd29f/pytz-2020.4-py2.py3-none-any.whl (509kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.5/dist-packages (from nltk->-r requirements.txt (line 3)) (7.0)\u001b[0m\n",
      "\u001b[34mCollecting joblib (from nltk->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34m  Downloading https://files.pythonhosted.org/packages/28/5c/cf6a2b65a321c4a209efcdf64c2689efae2cb62661f8f6f4bb28547cf1bf/joblib-0.14.1-py2.py3-none-any.whl (294kB)\u001b[0m\n",
      "\u001b[34mCollecting regex (from nltk->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/fb/ef/8880ca0f2bc2e51a39aacf62a81947971aea42b3b54ca58111b5a5ba6e05/regex-2020.10.28.tar.gz (694kB)\u001b[0m\n",
      "\u001b[34mCollecting tqdm (from nltk->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/93/3a/96b3dc293aa72443cf9627444c3c221a7ba34bb622e4d8bf1b5d4f2d9d08/tqdm-4.51.0-py2.py3-none-any.whl (70kB)\u001b[0m\n",
      "\u001b[34mCollecting soupsieve>1.2; python_version >= \"3.0\" (from beautifulsoup4->-r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/6f/8f/457f4a5390eeae1cc3aeab89deb7724c965be841ffca6cfca9197482e470/soupsieve-2.0.1-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mCollecting webencodings (from html5lib->-r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/f4/24/2a3e3df732393fed8b3ebf2ec078f05546de641fe1b667ee316ec1dcf3b7/webencodings-0.5.1-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: six>=1.9 in /usr/local/lib/python3.5/dist-packages (from html5lib->-r requirements.txt (line 5)) (1.11.0)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: nltk, train, regex\n",
      "  Running setup.py bdist_wheel for nltk: started\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for nltk: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n",
      "  Running setup.py bdist_wheel for train: started\n",
      "  Running setup.py bdist_wheel for train: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-tdtwhxju/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\n",
      "  Running setup.py bdist_wheel for regex: started\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for regex: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/16/32/f2/87817e06026bddd4f4f63c497c1c9587c028bdf57485e52e0f\u001b[0m\n",
      "\u001b[34mSuccessfully built nltk train regex\u001b[0m\n",
      "\u001b[34mInstalling collected packages: pytz, numpy, pandas, joblib, regex, tqdm, nltk, soupsieve, beautifulsoup4, webencodings, html5lib, train\u001b[0m\n",
      "\u001b[34m  Found existing installation: numpy 1.15.4\n",
      "    Uninstalling numpy-1.15.4:\n",
      "      Successfully uninstalled numpy-1.15.4\u001b[0m\n",
      "\u001b[34mSuccessfully installed beautifulsoup4-4.9.3 html5lib-1.1 joblib-0.14.1 nltk-3.5 numpy-1.18.5 pandas-0.24.2 pytz-2020.4 regex-2020.10.28 soupsieve-2.0.1 tqdm-4.51.0 train-1.0.0 webencodings-0.5.1\u001b[0m\n",
      "\u001b[34mYou are using pip version 18.1, however version 20.3b1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-11-11 14:47:29,391 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"resource_config\": {\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 15,\n",
      "        \"hidden_dim\": 200\n",
      "    },\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"num_gpus\": 1,\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-11-14-43-19-271/source/sourcedir.tar.gz\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"user_entry_point\": \"train.py\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"log_level\": 20,\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"RecordWrapperType\": \"None\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\"\n",
      "        }\n",
      "    },\n",
      "    \"job_name\": \"sagemaker-pytorch-2020-11-11-14-43-19-271\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"15\",\"--hidden_dim\",\"200\"]\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/lib/python35.zip:/usr/lib/python3.5:/usr/lib/python3.5/plat-x86_64-linux-gnu:/usr/lib/python3.5/lib-dynload:/usr/local/lib/python3.5/dist-packages:/usr/lib/python3/dist-packages\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-11-14-43-19-271/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN_DIM=200\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":15,\"hidden_dim\":200}\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":15,\"hidden_dim\":200},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"job_name\":\"sagemaker-pytorch-2020-11-11-14-43-19-271\",\"log_level\":20,\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-11-14-43-19-271/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=15\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m train --epochs 15 --hidden_dim 200\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing device cuda.\u001b[0m\n",
      "\u001b[34mGet train data loader.\u001b[0m\n",
      "\u001b[34mModel loaded with embedding_dim 35, hidden_dim 200, vocab_size 5000.\u001b[0m\n",
      "\u001b[34mEpoch: 1, BCELoss: 0.7832662029699846\u001b[0m\n",
      "\u001b[34mEpoch: 2, BCELoss: 0.7070528810674493\u001b[0m\n",
      "\u001b[34mEpoch: 3, BCELoss: 0.6470508141951128\u001b[0m\n",
      "\u001b[34mEpoch: 4, BCELoss: 0.5651451295072382\u001b[0m\n",
      "\u001b[34mEpoch: 5, BCELoss: 0.4686794172633778\u001b[0m\n",
      "\u001b[34mEpoch: 6, BCELoss: 0.36375353011217987\u001b[0m\n",
      "\u001b[34mEpoch: 7, BCELoss: 0.2807423905892806\u001b[0m\n",
      "\u001b[34mEpoch: 8, BCELoss: 0.21410149200396103\u001b[0m\n",
      "\u001b[34mEpoch: 9, BCELoss: 0.15948683294382962\u001b[0m\n",
      "\u001b[34mEpoch: 10, BCELoss: 0.11766727268695831\u001b[0m\n",
      "\u001b[34mEpoch: 11, BCELoss: 0.09834169664166191\u001b[0m\n",
      "\u001b[34mEpoch: 12, BCELoss: 0.0865608433430845\u001b[0m\n",
      "\u001b[34mEpoch: 13, BCELoss: 0.0749292912131006\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-11-11 14:47:48 Uploading - Uploading generated training model\n",
      "2020-11-11 14:47:48 Completed - Training job completed\n",
      "\u001b[34mEpoch: 14, BCELoss: 0.06582087820226495\u001b[0m\n",
      "\u001b[34mEpoch: 15, BCELoss: 0.055926820771260696\u001b[0m\n",
      "\u001b[34m2020-11-11 14:47:39,588 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "Training seconds: 108\n",
      "Billable seconds: 108\n",
      "-------------!"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted sagemaker-pytorch-2020-11-11-14-48-02-278\n",
      "2020-11-11 14:54:39 Starting - Starting the training job...\n",
      "2020-11-11 14:54:41 Starting - Launching requested ML instances......\n",
      "2020-11-11 14:55:48 Starting - Preparing the instances for training.........\n",
      "2020-11-11 14:57:24 Downloading - Downloading input data...\n",
      "2020-11-11 14:58:10 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-11-11 14:58:11,935 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-11-11 14:58:11,959 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-11-11 14:58:12,594 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-11-11 14:58:12,845 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-11-11 14:58:12,845 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-11-11 14:58:12,845 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-11-11 14:58:12,846 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pip install -U . -r requirements.txt\u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mCollecting pandas (from -r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34m  Downloading https://files.pythonhosted.org/packages/74/24/0cdbf8907e1e3bc5a8da03345c23cbed7044330bb8f73bb12e711a640a00/pandas-0.24.2-cp35-cp35m-manylinux1_x86_64.whl (10.0MB)\u001b[0m\n",
      "\u001b[34mCollecting numpy (from -r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/b5/36/88723426b4ff576809fec7d73594fe17a35c27f8d01f93637637a29ae25b/numpy-1.18.5-cp35-cp35m-manylinux1_x86_64.whl (19.9MB)\u001b[0m\n",
      "\u001b[34mCollecting nltk (from -r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\u001b[0m\n",
      "\u001b[34mCollecting beautifulsoup4 (from -r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/41/e6495bd7d3781cee623ce23ea6ac73282a373088fcd0ddc809a047b18eae/beautifulsoup4-4.9.3-py3-none-any.whl (115kB)\u001b[0m\n",
      "\u001b[34mCollecting html5lib (from -r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/6c/dd/a834df6482147d48e225a49515aabc28974ad5a4ca3215c18a882565b028/html5lib-1.1-py2.py3-none-any.whl (112kB)\u001b[0m\n",
      "\u001b[34mCollecting pytz>=2011k (from pandas->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/12/f8/ff09af6ff61a3efaad5f61ba5facdf17e7722c4393f7d8a66674d2dbd29f/pytz-2020.4-py2.py3-none-any.whl (509kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /usr/local/lib/python3.5/dist-packages (from pandas->-r requirements.txt (line 1)) (2.7.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.5/dist-packages (from nltk->-r requirements.txt (line 3)) (7.0)\u001b[0m\n",
      "\u001b[34mCollecting joblib (from nltk->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/28/5c/cf6a2b65a321c4a209efcdf64c2689efae2cb62661f8f6f4bb28547cf1bf/joblib-0.14.1-py2.py3-none-any.whl (294kB)\u001b[0m\n",
      "\u001b[34mCollecting regex (from nltk->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34m  Downloading https://files.pythonhosted.org/packages/fb/ef/8880ca0f2bc2e51a39aacf62a81947971aea42b3b54ca58111b5a5ba6e05/regex-2020.10.28.tar.gz (694kB)\u001b[0m\n",
      "\u001b[34mCollecting tqdm (from nltk->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/93/3a/96b3dc293aa72443cf9627444c3c221a7ba34bb622e4d8bf1b5d4f2d9d08/tqdm-4.51.0-py2.py3-none-any.whl (70kB)\u001b[0m\n",
      "\u001b[34mCollecting soupsieve>1.2; python_version >= \"3.0\" (from beautifulsoup4->-r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/6f/8f/457f4a5390eeae1cc3aeab89deb7724c965be841ffca6cfca9197482e470/soupsieve-2.0.1-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: six>=1.9 in /usr/local/lib/python3.5/dist-packages (from html5lib->-r requirements.txt (line 5)) (1.11.0)\u001b[0m\n",
      "\u001b[34mCollecting webencodings (from html5lib->-r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/f4/24/2a3e3df732393fed8b3ebf2ec078f05546de641fe1b667ee316ec1dcf3b7/webencodings-0.5.1-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: nltk, train, regex\n",
      "  Running setup.py bdist_wheel for nltk: started\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for nltk: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n",
      "  Running setup.py bdist_wheel for train: started\n",
      "  Running setup.py bdist_wheel for train: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-9mskgid3/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\n",
      "  Running setup.py bdist_wheel for regex: started\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for regex: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/16/32/f2/87817e06026bddd4f4f63c497c1c9587c028bdf57485e52e0f\u001b[0m\n",
      "\u001b[34mSuccessfully built nltk train regex\u001b[0m\n",
      "\u001b[34mInstalling collected packages: numpy, pytz, pandas, joblib, regex, tqdm, nltk, soupsieve, beautifulsoup4, webencodings, html5lib, train\n",
      "  Found existing installation: numpy 1.15.4\n",
      "    Uninstalling numpy-1.15.4:\u001b[0m\n",
      "\u001b[34m      Successfully uninstalled numpy-1.15.4\u001b[0m\n",
      "\u001b[34mSuccessfully installed beautifulsoup4-4.9.3 html5lib-1.1 joblib-0.14.1 nltk-3.5 numpy-1.18.5 pandas-0.24.2 pytz-2020.4 regex-2020.10.28 soupsieve-2.0.1 tqdm-4.51.0 train-1.0.0 webencodings-0.5.1\u001b[0m\n",
      "\u001b[34mYou are using pip version 18.1, however version 20.3b1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-11-11 14:58:36,034 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"job_name\": \"sagemaker-pytorch-2020-11-11-14-54-38-973\",\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\",\n",
      "            \"TrainingInputMode\": \"File\"\n",
      "        }\n",
      "    },\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"user_entry_point\": \"train.py\",\n",
      "    \"num_gpus\": 1,\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 50,\n",
      "        \"hidden_dim\": 10\n",
      "    },\n",
      "    \"resource_config\": {\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-11-14-54-38-973/source/sourcedir.tar.gz\",\n",
      "    \"log_level\": 20,\n",
      "    \"module_name\": \"train\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"num_cpus\": 4\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/lib/python35.zip:/usr/lib/python3.5:/usr/lib/python3.5/plat-x86_64-linux-gnu:/usr/lib/python3.5/lib-dynload:/usr/local/lib/python3.5/dist-packages:/usr/lib/python3/dist-packages\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=50\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"50\",\"--hidden_dim\",\"10\"]\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-11-14-54-38-973/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN_DIM=10\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":50,\"hidden_dim\":10}\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":50,\"hidden_dim\":10},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"job_name\":\"sagemaker-pytorch-2020-11-11-14-54-38-973\",\"log_level\":20,\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-11-14-54-38-973/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m train --epochs 50 --hidden_dim 10\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing device cuda.\u001b[0m\n",
      "\u001b[34mGet train data loader.\u001b[0m\n",
      "\u001b[34mModel loaded with embedding_dim 35, hidden_dim 10, vocab_size 5000.\u001b[0m\n",
      "\u001b[34mEpoch: 1, BCELoss: 0.6495233449068937\u001b[0m\n",
      "\u001b[34mEpoch: 2, BCELoss: 0.43837050145322626\u001b[0m\n",
      "\u001b[34mEpoch: 3, BCELoss: 0.25550691377032886\u001b[0m\n",
      "\u001b[34mEpoch: 4, BCELoss: 0.16303673996166748\u001b[0m\n",
      "\u001b[34mEpoch: 5, BCELoss: 0.11842383173379031\u001b[0m\n",
      "\u001b[34mEpoch: 6, BCELoss: 0.09110851314934817\u001b[0m\n",
      "\u001b[34mEpoch: 7, BCELoss: 0.07273957607421008\u001b[0m\n",
      "\u001b[34mEpoch: 8, BCELoss: 0.06245845691724257\u001b[0m\n",
      "\u001b[34mEpoch: 9, BCELoss: 0.0542400638488206\u001b[0m\n",
      "\u001b[34mEpoch: 10, BCELoss: 0.050560817969116295\u001b[0m\n",
      "\u001b[34mEpoch: 11, BCELoss: 0.04798758825795217\u001b[0m\n",
      "\u001b[34mEpoch: 12, BCELoss: 0.04747859727252613\u001b[0m\n",
      "\u001b[34mEpoch: 13, BCELoss: 0.04593367993154309\u001b[0m\n",
      "\u001b[34mEpoch: 14, BCELoss: 0.04505312781442295\u001b[0m\n",
      "\u001b[34mEpoch: 15, BCELoss: 0.043990154157985344\u001b[0m\n",
      "\u001b[34mEpoch: 16, BCELoss: 0.0433864871209318\u001b[0m\n",
      "\u001b[34mEpoch: 17, BCELoss: 0.04212340255352584\u001b[0m\n",
      "\u001b[34mEpoch: 18, BCELoss: 0.04202817075631835\u001b[0m\n",
      "\u001b[34mEpoch: 19, BCELoss: 0.041226361793550576\u001b[0m\n",
      "\u001b[34mEpoch: 20, BCELoss: 0.04108494215390899\u001b[0m\n",
      "\u001b[34mEpoch: 21, BCELoss: 0.04057493551888249\u001b[0m\n",
      "\u001b[34mEpoch: 22, BCELoss: 0.04028048213909973\u001b[0m\n",
      "\u001b[34mEpoch: 23, BCELoss: 0.04009426842358979\u001b[0m\n",
      "\u001b[34mEpoch: 24, BCELoss: 0.03993692367591641\u001b[0m\n",
      "\u001b[34mEpoch: 25, BCELoss: 0.03978480178524147\u001b[0m\n",
      "\u001b[34mEpoch: 26, BCELoss: 0.0396968928927725\u001b[0m\n",
      "\u001b[34mEpoch: 27, BCELoss: 0.03953561593185772\u001b[0m\n",
      "\u001b[34mEpoch: 28, BCELoss: 0.03946873308582739\u001b[0m\n",
      "\u001b[34mEpoch: 29, BCELoss: 0.039396374401721085\u001b[0m\n",
      "\u001b[34mEpoch: 30, BCELoss: 0.039296715266325256\u001b[0m\n",
      "\u001b[34mEpoch: 31, BCELoss: 0.03938224606893279\u001b[0m\n",
      "\u001b[34mEpoch: 32, BCELoss: 0.03917126340622252\u001b[0m\n",
      "\u001b[34mEpoch: 33, BCELoss: 0.03914402916350148\u001b[0m\n",
      "\u001b[34mEpoch: 34, BCELoss: 0.03905232098292221\u001b[0m\n",
      "\u001b[34mEpoch: 35, BCELoss: 0.03900772062214938\u001b[0m\n",
      "\u001b[34mEpoch: 36, BCELoss: 0.03908230940049345\u001b[0m\n",
      "\u001b[34mEpoch: 37, BCELoss: 0.03953480703586882\u001b[0m\n",
      "\u001b[34mEpoch: 38, BCELoss: 0.04057952101257714\u001b[0m\n",
      "\u001b[34mEpoch: 39, BCELoss: 0.056052333251996475\u001b[0m\n",
      "\u001b[34mEpoch: 40, BCELoss: 0.11128637939691544\u001b[0m\n",
      "\u001b[34mEpoch: 41, BCELoss: 0.151249884204431\u001b[0m\n",
      "\u001b[34mEpoch: 42, BCELoss: 0.14839452572844244\u001b[0m\n",
      "\u001b[34mEpoch: 43, BCELoss: 0.12053286216475746\u001b[0m\n",
      "\u001b[34mEpoch: 44, BCELoss: 0.09837587888945233\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mEpoch: 45, BCELoss: 0.08182852816852657\u001b[0m\n",
      "\u001b[34mEpoch: 46, BCELoss: 0.07192735848101703\u001b[0m\n",
      "\u001b[34mEpoch: 47, BCELoss: 0.06134305250915614\u001b[0m\n",
      "\u001b[34mEpoch: 48, BCELoss: 0.05794009244577451\u001b[0m\n",
      "\u001b[34mEpoch: 49, BCELoss: 0.055261330171064896\u001b[0m\n",
      "\u001b[34mEpoch: 50, BCELoss: 0.051739649339155716\u001b[0m\n",
      "\u001b[34m2020-11-11 14:58:47,637 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-11-11 14:58:58 Uploading - Uploading generated training model\n",
      "2020-11-11 14:58:58 Completed - Training job completed\n",
      "Training seconds: 94\n",
      "Billable seconds: 94\n",
      "---"
     ]
    }
   ],
   "source": [
    "data_dir_cv='Data/CVTrain/'\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'sagemaker/twitter_train_cv'\n",
    "role = sagemaker.get_execution_role()\n",
    "pos_epochs=[15,50]\n",
    "pos_hidden_dim=[10,100,200]\n",
    "finalroc=[]\n",
    "\n",
    "# This method make a Cross Validation in Sagemaker, creating, deploying and evaluating Pytorch models\n",
    "with different values of epochs and hidden dimention\n",
    "for i in range(1,6):\n",
    "    X_train, X_test, y_test= calcularvalores(i,info_modelo)\n",
    "    X_train.to_csv(data_dir_cv+'train.csv', header=False, index=False)\n",
    "    input_data = sagemaker_session.upload_data(path=data_dir, bucket=bucket, key_prefix=prefix)\n",
    "    for ep in pos_epochs:\n",
    "        for hd in pos_hidden_dim:\n",
    "            estimator = PyTorch(entry_point=\"train.py\",\n",
    "                            source_dir=\"train\",\n",
    "                            role=role,\n",
    "                            framework_version='0.4.0',\n",
    "                            py_version='py3',\n",
    "                            train_instance_count=1,\n",
    "                            train_instance_type='ml.p2.xlarge',\n",
    "                            hyperparameters={\n",
    "                                'epochs': ep,\n",
    "                                'hidden_dim': hd,\n",
    "                            })\n",
    "            estimator.fit({'training': input_data})\n",
    "    \n",
    "            model = PyTorchModel(model_data=estimator.model_data,\n",
    "                             role = role,\n",
    "                             framework_version='1.0',\n",
    "                             entry_point='predict.py',\n",
    "                             source_dir='serve',\n",
    "                             py_version='py3')\n",
    "\n",
    "            predictor=model.deploy(initial_instance_count = 1, instance_type = 'ml.m4.xlarge')\n",
    "            predictions=predict(X_test, rows=512)\n",
    "            roc=roc_auc_score(y_test.to_numpy(), predictions)\n",
    "            rf=[i,ep,hd,roc]\n",
    "            finalroc=finalroc+[rf]\n",
    "            roc_df=pd.DataFrame(finalroc)\n",
    "            roc_df.to_csv('Data/roc_df_pytorch.csv')\n",
    "            delete_endpoint(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted sagemaker-pytorch-2020-11-11-01-08-44-046\n"
     ]
    }
   ],
   "source": [
    "delete_endpoint(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_df=pd.read_csv('Data/roc_df_pytorch.csv').drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the combination of hyperparameters that optimize the AUC, it was selected the best epochs parameter and the best hidden dimension parameter:\n",
    "\n",
    "epochs=50\n",
    "\n",
    "hidden dimension=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_tot_=pd.DataFrame(roc_df.groupby(['1','2']).mean()['3']).reset_index()\n",
    "best_all=roc_tot_[roc_tot_['3']==max(roc_df.groupby(['1','2']).mean()['3'])]\n",
    "best_epochs=int(best_all['1'])\n",
    "best_hl=int(best_all['2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>0.998711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>0.998805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>200</td>\n",
       "      <td>0.998543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.998332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>0.998808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>200</td>\n",
       "      <td>0.998788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    1    2         3\n",
       "0  15   10  0.998711\n",
       "1  15  100  0.998805\n",
       "2  15  200  0.998543\n",
       "3  50   10  0.998332\n",
       "4  50  100  0.998808\n",
       "5  50  200  0.998788"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_tot_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I recreated the model with the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = sagemaker_session.upload_data(path=data_dir, bucket=bucket, key_prefix=prefix)\n",
    "estimator = PyTorch(entry_point=\"train.py\",\n",
    "                source_dir=\"train\",\n",
    "                role=role,\n",
    "                framework_version='0.4.0',\n",
    "                py_version='py3',\n",
    "                train_instance_count=1,\n",
    "                train_instance_type='ml.p2.xlarge',\n",
    "                hyperparameters={\n",
    "                    'epochs': best_epochs,\n",
    "                    'hidden_dim': best_hl,\n",
    "                })\n",
    "estimator.fit({'training': input_data})\n",
    "\n",
    "model = PyTorchModel(model_data=estimator.model_data,\n",
    "                 role = role,\n",
    "                 framework_version='1.0',\n",
    "                 entry_point='predict.py',\n",
    "                 source_dir='serve',\n",
    "                 py_version='py3')\n",
    "\n",
    "predictor=model.deploy(initial_instance_count = 1, instance_type = 'ml.m4.xlarge')\n",
    "predictions=predict(test_data, rows=512)\n",
    "roc=roc_auc_score(y_test.to_numpy(), predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we get an AUC of 0.78 and a ROC curve very similar that the one obtained with the suggested parameters of the literature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deZxN9f/A8dcbkSSFNiRKZQvVpH0RSqUoZUlKJV+V9v3b79v2rW/Lt/2bklRKRSvRpsUWJZFClmxhkCSEjJh5//54nzHXmOXOmHvPXd7Px+M+5p5zz73nPWfu3Pc9n8/5vD+iqjjnnHOFKRd2AM455xKbJwrnnHNF8kThnHOuSJ4onHPOFckThXPOuSJ5onDOOVckTxQuaiLSXUQ+CzuORCIiG0TkoBD2W09EVEQqxHvfsSAiP4nIqaV4nr8n48ATRZISkV9EZFPwQfWriAwSkd1juU9VfUNVT4/lPiKJyPEiMlpE1ovIOhEZKSKN47X/AuIZKyK9Itep6u6qujBG+ztURN4Rkd+D33+6iNwkIuVjsb/SChJWg515DVVtoqpji9nPDskx3u/JdOWJIrmdo6q7Ay2AI4A7Q46nVAr6ViwixwGfAR8AtYD6wI/AxFh8g0+0b+YicjDwLbAUOFxVqwEXAhlA1TLeV2i/e6Idd1cIVfVbEt6AX4A2EcuPAh9FLFcCHgOWACuB/kDliMc7AD8AfwILgHbB+mrAS8AKYBnwAFA+eKwnMCG43x94LF9MHwA3BfdrAe8Bq4BFwHUR290LvAu8Huy/VwG/31fAcwWs/wR4Lbh/KpAJ/BP4PTgm3aM5BhHPvR34FRgM7AV8GMS8JrhfJ9j+QSAbyAI2AM8G6xVoENwfBPQDPgLWYx/0B0fEczowF1gHPAeMK+h3D7Z9PfLvWcDj9YJ9Xxr8fr8Dd0U83hL4Blgb/C2fBSpGPK7ANcA8YFGw7mksMf0JTAVOiti+fHCcFwS/21TgAGB88Fobg+PSJdi+Pfb+Wgt8DTTL9969HZgObAYqEPF+DmKfEsSxEngiWL8k2NeG4HYcEe/JYJsmwOfAH8Fz/xn2/2oq3EIPwG+l/MNt/49VB5gBPB3x+FPACKA69g10JPBQ8FjL4MOqLXZWWRtoGDw2HHgBqALsA0wG/hE8tu2fEjg5+FCRYHkvYBOWIMoFHyR3AxWBg4CFwBnBtvcCW4COwbaV8/1uu2Efyq0K+L0vA1YE908FtgJPYEnhlOAD67AojkHucx8JnlsZqAF0CvZfFXgHGB6x77Hk+2Bnx0TxR3B8KwBvAEODx2oGH3znB49dHxyDwhLFr8BlRfz96wX7fjGIvTn2odsoePwo4NhgX/WA2cAN+eL+PDg2ucnz4uAYVABuDmLYNXjsVuw9dhggwf5q5D8GwfKRwG/AMViCuRR7v1aKeO/+gCWayhHrct/P3wA9gvu7A8fm+50rROyrJ3nvyapYUrwZ2DVYPibs/9VUuIUegN9K+Yezf6wN2Lc7Bb4E9gweE+wDM/Lb7HHkfXN8AXiygNfcN/iwiTzz6AaMCe5H/lMK9g3v5GD5SmB0cP8YYEm+174TeCW4fy8wvojfrU7wOzUs4LF2wJbg/qnYh32ViMffBv4VxTE4Ffg794OwkDhaAGsilsdSfKIYGPHYWcCc4P4lwDcRjwmWaAtLFFsIzvIKeTz3Q7NOxLrJQNdCtr8BGJYv7tOKeY+tAZoH9+cCHQrZLn+ieB74d75t5gKnRLx3Ly/g/ZybKMYD9wE1C/mdC0sU3YBpsfy/S9ebtw8mt46q+oWInAK8iX1rXQvsjX0rnioiudsK9u0O7JvcxwW83oHALsCKiOeVwz7QtqOqKiJDsX/O8cBFWHNJ7uvUEpG1EU8pjzUn5drhNSOsAXKA/YE5+R7bH2tm2batqm6MWF6MndUUdwwAVqlq1rYHRXYDnsSS0V7B6qoiUl5Vs4uIN9KvEff/wr4RE8S07XcOjl9mEa+zGvtdS7U/ETkUO9PKwI5DBewsL9J2fwMRuRnoFcSqwB7YewrsPbMginjA/v6Xisi1EesqBq9b4L7zuQK4H5gjIouA+1T1wyj2W5IYXQl4Z3YKUNVx2LfZx4JVv2PNQE1Udc/gVk2t4xvsn/TgAl5qKXZGUTPieXuoapNCdj0EuEBEDsTOIt6LeJ1FEa+xp6pWVdWzIsMu4vfZiDU/XFjAw52xs6dce4lIlYjlusDyKI5BQTHcjDWtHKOqe2DNa2AJpsiYo7ACO1OyF7TsVafwzfkCawYrreexJHtI8Lv8k7zfI9e230dETsL6DToDe6nqnljzZO5zCnvPFGQp8GC+v/9uqjqkoH3np6rzVLUb1vT5CPBu8Dcu7viXJEZXAp4oUsdTQFsRaaGqOVjb9ZMisg+AiNQWkTOCbV8CLhOR1iJSLnisoaquwK40elxE9ggeOzg4Y9mBqk7DOn4HAqNUNfcMYjLwp4jcLiKVRaS8iDQVkaNL8PvcgX0rvU5EqorIXiLyANZ8dF++be8TkYrBh1174J0ojkFBqmLJZa2IVAfuyff4Sqy/pTQ+Ag4XkY7BlT7XAPsVsf09wPEi8l8R2S+Iv4GIvC4ie0axv6pYn8gGEWkIXBXF9luxv2cFEbkbO6PINRD4t4gcIqaZiNQIHst/XF4E+ojIMcG2VUTkbBGJ6motEblYRPYO/oa576nsILYcCv8bfAjsJyI3iEil4H1zTDT7dEXzRJEiVHUV8BrWPg/27XA+MElE/sS+oR4WbDsZ6xR+EvvWOA5rLgBrS68IzMKagN6l6CaQIUAbrOkrN5Zs4BysjX8R9u1+IHZFVbS/zwTgDKzzdwXWpHQEcKKqzovY9NcgzuVY53EfVc1trir0GBTiKaxj+HdgEvBpvsefxs6g1ojIM9H+LsHv8zt2hvQo1qzUGLuyZ3Mh2y/AkmI94CcRWYedsU3B+qWKcwvWHLge++B+q5jtR2FXlP2MHesstm8eegLr//kMS0AvYccKrM/pVRFZKyKdVXUK1mf1LPa3mY/1JUSrHfY7b8COeVdVzVLVv7CrzyYG+zo28kmquh67QOMc7H0xD2hVgv26QuReseJc0glG8r6uqkU14SQkESmHXZ7bXVXHhB2Pc0XxMwrn4kREzhCRPUWkEnl9BpNCDsu5YsUsUYjIyyLym4jMLORxEZFnRGR+UJrgyFjF4lyCOA67Kud3rHmko6puCjck54oXs6YnETkZu87/NVVtWsDjZwHXYteaH4MNFvOOJ+ecSzAxO6NQ1fHYKNXCdMCSiKrqJGBPEYnmunHnnHNxFOaAu9psf1VFZrBuRf4NRaQ30BugSpUqRzVs2DAuATrnXDyp2g0gJwfWrYONGyErC7ZuhU2laKisy2L2ZC3T2fq7qu5dmrjCTBT5B/9AIQNqVHUAMAAgIyNDp0yZEsu4nHOuxP7+G+bOhR9/zFuXlQUvvww1ahT+vFybN8Pnnxf++NFHW+K46SY4++xiXiw324hQ5bXnKbf6N/Z84t7FxUdRsDATRSY25D5XHexaeOecC13kt/v8fv4Zpk2z+5MmwTPFjKrZZRc4/PDi99e4MTRrBkccYesqVIDzzoOaNaFqtMXlly2Dq6+CLl2ge3f4ZzDW8ol7o3yBHYWZKEYAfYN6QccA64KRwc45FxcffgiDBhX82HvvFby+MIceCpdcAg0bQvPmeesrV4batUsdYvRUYeBAuOUW2LIlitOO6MUsUYjIEKxCZ82g+Nk9WME5VLU/VpTuLGzU5l/YSGHnnCsTf/0FX35pbfu5liyBL76wBBGpSQHVzBoHcyl26bLjY6qWEFq0sOX99oNqUdcdiIEFC+DKK2HMGGjVCl58EQ4uu7JXMUsUQVGvoh5XrN6Nc86Vyvz5MGsWDB4MlSpt/9gbbxT+vJo1LTmcfLLd2rSJbZwxN2MGTJ0KAwZAr14gBXUBl56XGXfOJaycHJgwATZsgLfftnW//w4ffQTlytnjkSK/RB94IOy/P/Tvv/02NWpAnaQr+lKAmTPh+++tvatjR1i4MLpe81LwROGcSwjZ2XDbbbB2rTUbDR1a8HYHHAB77WVnAoceak1ARx0FTZtC+fIFPyel/P03/Oc/dtt3X+jcGXbdNWZJAjxROOcSxEcfwRNP2P3994fq1a1TuFEj6yfYbTdb3mWXcOMM1bffwhVXwE8/wcUXw5NPWpKIMU8Uzrm427rV+hW++Sbvg/+55+znDz9sf9WQCyxbBiedZGcRH35Yplc1FccThXMuJn77DeYFM4cMGWJ9CgCvvGJ9DrlqBpOt7rmnnUkUN94g7fz8s7Wx1a4Nb70FrVvDHnsU/7wy5InCOVcq8+bBHxHV3ObOhSlTbJDYG29Yoshvr2Am8urVoUMH+Oc/oUGD+MSbdNautU6bgQNh7FjrlDnvvFBC8UThnCuWql2G+u67Vnto0CBYtargbatWtfFelSrBHXfACSdY89Lxx0PFinENO3mNGAFXXQW//gq33mr1O0LkicI5t42qnRlkZdnyunXQowcsXbr9drlXFw0aBPvsk7e+fn27CsnthF694KWXrA3ugw8gIyPsiDxROOdMVhY8/7wVnctvv/3sS+3ll8Npp8W9iTz1RRTxIyPDBoHcfnvCnIJ5onAuja1da1cbDRqU1/EM8PjjcNBBdr9yZes/reCfFrGxdCn06QNdu9rpW58+YUe0A//TO5eGli+HBx/MuyQV4MILoUoV+6w67bTwYksbOTnwwgt25pCdHVpHdTQ8UTiXZr7/3kYy57r6amsWzy1t7eJg3jw76OPHW6GpAQOsgydBeaJwLo3k5MBrr9n9u++Gf/wDatUKN6a0NGsWTJ9usxr17FnmRfzKmicK55JEbg2kgnz3HSxatOP6IUPsMyj3c2jSpLzHLr3Uk0Rc/fijDTu/9FIbRLJwYd7AkgTnicK5BLJhQ14yWL3apsb88kubTS3/Jaolcfrp2/989NG8zmoXY5s3wwMPwMMP29DzLl2sPlOSJAnwROFcQlixwuaaueeewrc54gjo1An23nvHx1ShZcuCm7mrVUv4lo3U9c03VsRv9mwrB/7EE3Ep4lfWPFE4F2M5OXam8McfdoYQKbcG0pdf5q3r2tVqv4GVumjTxj7s07pqajJatgxOOcUGoXz8MZx5ZtgRlZonCudiRNUmzbn66uK3Pf54m3TnmWesOJ5LYrNnW2302rVttqXWra2uSRLzROFcDIwbZ/2V69bZcr16cO211iyd20+Qq1YtbxpKCWvWwM03W3nc8ePttLBjx7CjKhOeKJwrY5s325fI7GxbXrLEZmVzKWzYMDt1XLUK7rwz9CJ+Za1c2AE4lyoyM6F7d5uZMndaz7/+8iSR8i6/HM4/3/oiJk+2KUqTsMO6KH5G4VwZePdduOgiK69dpQq0aAHnnGN1klwKiizid+yxcMghcMstKXvFgScK56KkCnfdBYsX561bvx5GjsxbPvFE+PRTSxYuRS1ebEPaL7rILnnt3TvsiGLOE4VzUXrmGXjoIbufOytbTo6NoTr6aOvHPPnk8OJzMZaTY3XY77jDvjVceGHYEcWNJwrnojR2rP2cPt3ndU47c+daEb8JE+yytRdesEvZ0oQnCueKMXy4zQE9fLjN3uZJIg3NnQs//WQTd1xySdpdz+yJwrlCZGdbiZ5777XlqlXtqiaXJqZNsyJ+l10G555rRfzSdDSkJwrnIowdC61aWemMP/7IWz9yJLRvH1pYLp6ysuD++61yYu3a0K2bXe6apkkCPFG4NLdmDcyZAx9+aGMennrK1jdqZE1MmzZZ32XDhuHG6eJk4kQr4jd3rp1JPP54yo2JKA1PFC4t/fvfcN99eaOnc1WubLXb3nsvnLhciJYts9PJ2rVh1Kgda62kMU8ULi2o2pfETZtg4MC8uaIzMmx+6Nat4bjjkr52myuNWbOgcWNLEO+9Z8li993DjiqheKJwKS8ryyYVe/vt7dd/8YUlCJem/vgDbroJXn3VqjiefLINp3c78EThUtqWLVbEc8oUW37xRSvJ06qVj55Oa++9B9dcY9MI3nWXzfrkCuWJwqWk4cPh+++tLyJXZqa1Lrg017OnnUUceaTVW2nRIuyIEp4nCpdybr0VHnssb7luXRg92pNEWoss4nf88XZZ2803QwX/CIxGTMuMi0g7EZkrIvNF5I4CHq8rImNEZJqITBeRs2IZj0t9CxbkJYnx4+2qpsWLbfY4l6YWLbIrmF57zZZ794bbb/ckUQIxSxQiUh7oB5wJNAa6iUjjfJv9H/C2qh4BdAWei1U8LvUNGJBXrO/xx61vopzPuJK+srOtkmPTpjBpUt5ZhSuxWKbUlsB8VV0IICJDgQ7ArIhtFNgjuF8NWB7DeFwKU7XKz3vsAWefHd081S6FzZ5tA+e++cYGxvTvb22QrlRimShqA0sjljOBY/Jtcy/wmYhcC1QB2hT0QiLSG+gNUNf/2C6frVvhmOCddcAB8Oab4cbjEsD8+TZwZvBgK9CVZkX8ylosT8wL+svkP/frBgxS1TrAWcBgEdkhJlUdoKoZqpqx9957xyBUl8z697crnAA++ijcWFyIpk6Fl1+2++ecY30TF1/sSaIMxDJRZAKRswXXYcempSuAtwFU9RtgV6BmDGNyKWTmTJt58tprbXnWLDjwwHBjciHILch1zDF2PXRWlq3fY4+in+eiFstE8R1wiIjUF5GKWGf1iHzbLAFaA4hIIyxRrIphTC7JjRhhfRBnn21F+7ZuhX32gc8/tyseXZoZPx6aN4dHHrHxEdOmeRG/GIhZH4WqbhWRvsAooDzwsqr+JCL3A1NUdQRwM/CiiNyINUv1VPVLE1zBli+HDh3sfkaGjZdq1gxeeSXcuFxIli2zGiwHHOD1WGJMku1zOSMjQ6fk1mNwaWHjRuja1UqBg10SP2pUuDG5EM2YkTfN4Icfej2WKInIVFXNKM1z/Spzl9C+/toKeeYmiauu8iSRtn7/HXr0sNPI8eNtXfv2niTiwIcmuoS2aJH9vOIKG1DnA+jSkCq88w707WszTd1zT9710C4uPFG4pHD77Z4k0tall9p4iIwM+PLLvGYnFzeeKFzC+fNPqwJ9+eV56zxJpJnIIn6nnGLNTTfc4PWZQuJH3SWErVutP2LjRjgrojTkccdBx45w0EHhxebibOFCuPJKGyx32WXW7uhC5YnChe7pp+3LYqSDDoIPPoAmTXxgbdrIzob//c8mEipfHi65JOyIXMAThQvFokU2eG7uXHj+eVvXsaNNEVCxoo2R8FaGNDJrlrU1fvutjabs3x/q1Ak7Khfwf0UXV3//bYNnjz02b121albt9T//CS8uF7JFi2wykTfftEEzfhqZUDxRuLiYN8/mqx40CFYFRVpOP90uefX6TGnqu+/ghx+sP+Lss61vomrVsKNyBfBE4WJm82YYNsySwZgx1uzcoQN06wZ77WUzUlauHHaULu7++gvuvhuefNK+JfToYfWZPEkkLE8Ursz9/LMlh0GDYPVqqF/fmpV69oT99w87OheqsWOhVy9rZvrHP6yYnxfxS3ieKFyZWLXKKri++KJ9FlSoYJ3TvXtbrTYfB+HIzIS2be0sYvRoq9HkkoInCrdTBg+2UdMrVtjyQQfBQw/Z2cN++4UamksUP/5opcDr1LFrnk89FXbbLeyoXAl4onBRU7WzhQkTrL/hrrvyHitf3uax79PHzx5cYNUquP56GDLE3jinnLL9aEqXNDxRuAKpwpIl1iH9/vvw2ms2X31BFi2CevXiGp5LZKowdChcdx2sWwf33WdD7F3SiipRBDPU1VXV+TGOxyUA1cLPCk491TqmjzrKlnfZxS95d/n06AFvvGEVXl96yYbXu6RWbCOBiJwNzAA+D5ZbiMiwWAfm4u+vv+xLYGSSeOUV+3K4fr0lkDFj7MthxYp28yThAMjJySvk16oVPPEETJzoSSJFRHNGcT9wDDAGQFV/EJEGMY3KheL662HgQLufkWFXMe25Z7gxuSQwf74NmuvRw8pweBG/lBNNt+MWVV2bb11yzZ/qijV+vCWJm26CrCwbNOtJwhVp61Z47DGbH2LaNDvFdCkpmjOK2SLSGSgnIvWB64FJsQ3LxdPmzTbeoX59uP9+qFQp7Ihcwps500qAT5liw+2few5q1Qo7Khcj0ZxR9AWOAnKA94EsLFm4FPHQQ3lVXH36YReVJUtg8WLrwBo2zJNEihPVoluRROR8VX2/uHXxkpGRoVOmTAlj1ylp9mxo0QIuuMAuVHGuUN9+a4Pneve25Q0bYPfdw43JRU1EpqpqRmmeG80Zxf8VsO6uAta5JJOTY+V2qlSx+mzOFWjjRuu8Ou44ePRRa6sETxJppNA+ChE5A2gH1BaRJyIe2gNrhnJJ7qWX4Kuv7Oc++4QdjUtIo0fbFU0LF8JVV8HDD3snVhoqqjP7N2Am1ifxU8T69cAdsQzKxd6vv8Ktt9oAussuCzsal5AyM+GMM+wqh3Hj4OSTw47IhaTQRKGq04BpIvKGqmbFMSYXB7fcAps22YyTPmjObWfaNDjiCCviN3Kk1WjyiUPSWjR9FLVFZKiITBeRn3NvMY/MxdTo0dC5Mxx2WNiRuISxciV06WITlo8bZ+vatfMk4aIaRzEIeAB4DDgTuAzvo0g62dlW7XXVKpt9csUKHx/lAqp2ydv119uVTA88YNMPOheIJlHspqqjROQxVV0A/J+IfBXrwFzZ2bIFatfOm6t6//2tLHivXuHG5RLERRfZeIjjjrMrGxo1Cjsil2CiSRSbRUSABSLSB1gG+DUySWLzZjj0UEsSe+4J8+ZBzZphR+VCl5NjnVMicPrpliSuuca+QTiXTzR9FDcCuwPXAScAVwKXxzIot3MmTLArGo8+2uarX7LErmj88UdPEg6b1LxVK3j5ZVu+7DIrG+xJwhWi2DMKVf02uLse6AEgInViGZQrnffegxtvhKVLbblVK1tu2RLOPtvnsE97W7da+e977rE3g3dSuygVmShE5GigNjBBVX8XkSbA7cBpgCeLBDN5MixbZlWeTz/drmpyDoDp060E+NSpcN550K+fdVY5F4WiRmY/BHQCfsQ6sIdhxQAfAfrEJzwXrUsugREj7Eqm3DklnNsmM9NONd95Bzp18sEzrkSKOqPoADRX1U0iUh1YHizPjfbFRaQd8DRQHhioqg8XsE1n4F5sjosfVfWiEsTvgF9+gcGDrdP6yivDjsYljK+/tjOJPn3grLOsDIeXB3alUFRndpaqbgJQ1T+AOSVMEuWBftjYi8ZANxFpnG+bQ4A7gRNUtQlwQwnjT2srVsDdd1uFBbAmp1tuCTcmlwA2bLAxESeeCI8/nlfEz5OEK6WizigOEpHcUuIC1ItYRlXPL+a1WwLzVXUhgIgMxc5SZkVscyXQT1XXBK/5WwnjT1vvvWelwXNdey3cdlt48bgE8dlnVgZ8yRK73PU///Eifm6nFZUoOuVbfraEr10bWBqxnInNvR3pUAARmYg1T92rqp/mfyER6Q30Bqhbt24Jw0gty5bBmjV5SeL66+3KpgMPDDculwCWLrXL2w4+2Oa2PfHEsCNyKaKoooBf7uRrF9Rbln+WpArAIcCp2FVUX4lI0/xzdKvqAGAA2MRFOxlX0mrbFr74Im+5b1946qnw4nEJYupUOOooOOAA+PhjOOkkvxbalaloBtyVViZwQMRyHaxDPP82H6jqFlVdBMzFEocrwIIF9vOll+DNN21qAJfGfv0VLrwQMjLyivi1betJwpW5aEp4lNZ3wCEiUh8r+9EVyH9F03CgGzBIRGpiTVELYxhTUtqwAVavhkWLoHt3uxzepTFVeO01a3P86y/rh/Aifi6Goj6jEJES9Yip6lagLzAKmA28rao/icj9InJusNkoYLWIzALGALeq6uqS7CeVZWdbK0LVqlCvnq3zL4uOrl2hZ09o3NhKAd95J+yyS9hRuRQmqkU3+YtIS+AloJqq1hWR5kAvVb02HgHml5GRoVOmTAlj13F3yy12dSPYFU2HHmpnEz5WKg1FFvF79VVYvx6uvhrKxbL12KUSEZmqqhmleW40TU/PAO2xZiJU9UcRaVWanbno9e1rVRYA1q2DPfYINx4XojlzrCZ8z57289JLw47IpZlovo6UU9XF+dZlxyIYZzZuzEsSn3ziSSJtbdli/Q/Nm8OsWbD77mFH5NJUNGcUS4PmJw1GW18L+FSoZUwVbrjBynGMGGHrrr3WZqJ0aeiHH6z89w8/2KCZ//0P9tsv7KhcmoomUVyFNT/VBVYCXwTrXBmZMMEG0U6fbsvNmsFuu+X1T7g09OuvdnvvPTi/uCIIzsVWNIliq6p2jXkkaeztt2HGDGjYEN59F5o0CTsiF4oJE+zbwtVX26nkggX2jcG5kEXTR/GdiHwsIpeKSNWYR5Rmjj3WWhWqV4fZsz1JpKX16+3qhZNOsqH2uUX8PEm4BFFsolDVg4EHgKOAGSIyXET8DKMMDBgA334LxxwD/fuHHY0LxahR0LQpPPecFe76/nsv4ucSTlQXYavq16p6HXAk8CfwRkyjSgNTp8I//mH3b799+0qwLk0sXQrt29uZw4QJdjbhVza5BFRsohCR3UWku4iMBCYDqwCvF7ATVG2iIYChQ21mSpcmVG3OWrAifp98AtOmeQkOl9CiOaOYCRwLPKqqDVT1ZlX9NsZxpay//4Y2beDpp23ZK0GnkRUrbBrSY47JK+LXpo3XZXEJL5qrng5S1ZyYR5IGVKFmTeu7BPj8c6hdO9yYXByowqBBcNNNkJUFjzwCJ5wQdlTORa3QRCEij6vqzcB7IrJDQagoZrhz+Vx7bV6SWLMG9twz3HhcnHTubNc9n3QSDBxoRbucSyJFnVG8Ffws6cx2rgDDhuWV5Vi+3JNEysvOtgJ+5crBOefAaafZ1QtexM8loULftaoa9LjRSFW/jLwBjeITXmpYsQK6dLH7n34K++8fbjwuxmbPtrOHl16y5Usugauu8iThklY079yCpsm5oqwDSVWqNsh2yxZrcTjjjLAjcjGzZQs88AC0aAFz50K1amFH5FyZKKqPogs2K119EXk/4qGqwNqCn+XyO+usvBpOM8wBaaMAAB3USURBVGaEG4uLoWnTrAz49Ol2+vjMM7DPPmFH5VyZKKqPYjKwGpvrul/E+vXAtFgGlUoyM+3nypVQsWK4sbgYWrkSfv8dhg+HDh3Cjsa5MlVoolDVRcAirFqsK4XMTJg5Ezp29C+XKWn8eDtNvOYaa1+cPx8qVw47KufKXKF9FCIyLvi5RkT+iLitEZE/4hdi8po50342bRpuHK6M/fmnVXg95RRrYsot4udJwqWoojqzc6c7rQnsHXHLXXZROvvssCNwZebjj63E7wsv2AA6L+Ln0kBRl8fmjsY+ACivqtnAccA/gCpxiC3p/fln2BG4MrV0qfU/VKsGX39tM0tV8X8Fl/qiuTx2ODYN6sHAa9gYijdjGlUSy8qycj6HHJI3dsI7sZOYKkyaZPcPOAA++8zOIo45Jty4nIujaBJFjqpuAc4HnlLVawGvUJRPdrbVeatcGd5/3/o1W7SAxx6zny4JLV9uVyIcd1xeEb9WrTzzu7QT1VSoInIh0APoGKzbJXYhJadzzrGK0WBnFC++CHvtFW5MrpRUbVT1LbdYR/Vjj3kRP5fWoh2Z3QorM75QROoDQ2IbVnJZudKSRLNm8N57Vv/Nk0QSu+ACuPJKOxWcMQNuvhkqRPOdyrnUVOy7X1Vnish1QAMRaQjMV9UHYx9a8ngrKJ94+ulwvtfUTU6RRfw6drQ/5pVXen0m54huhruTgPnAS8DLwM8i4ufhwOjRlhiuv96W+/QJNx5XSjNnWtNSbhG/Hj280qtzEaI5n34SOEtVZwGISCNgMJARy8AS3TffQOvWdr9pU5v6+OCDw43JldDff8NDD8GDD9olr95e6FyBokkUFXOTBICqzhaRtL/sY/hw+3nvvXDPPaGG4kpj6lQr4jdzJlx0ETz1FOzt40idK0g0ieJ7EXkBO4sA6I4XBUTEBuR6kkhSq1fD2rUwcqSdDjrnChVNougDXAfcBggwHvhfLINKdPPmwYIFYUfhSmzMGLuK6brrrLN63jzYddewo3Iu4RWZKETkcOBgYJiqPhqfkBJf27aweLFXhE0a69bBbbfBgAHQsKF1VFeq5EnCuSgVVT32n1j5ju7A5yJS0Ex3aWXNGhuYu3gxnHeeVXJwCW7kSGjcGAYOtAF0U6d6ET/nSqioM4ruQDNV3SgiewMfY5fHpq0JE2DsWLt/++1Q2wuZJLalS22YfMOGdvXB0UeHHZFzSamoC8U3q+pGAFVdVcy2aeGzz+zn1KleEy5hqVplV8gr4jdliicJ53ZCUR/+B4nI+8FtGHBwxPL7RTxvGxFpJyJzRWS+iNxRxHYXiIiKSEKOzcjJscvtn33WluvUCTceV4jMTDj3XBs8l1vE79RTvYifczupqKanTvmWny3JC4tIeWyu7bZAJvCdiIyIHJMRbFcVu6rq25K8frxcdBEMiahsddtt3omdcHJyrArjrbfC1q3wxBNw4olhR+Vcyihqzuwvd/K1W2J1oRYCiMhQoAMwK992/wYeBW7Zyf2VGVW7QGbx4rwk0bs33H8/7LtvuLG5AnTqZH0Qp51mCeOgg8KOyLmUEsuSmLWBpRHLmcB2LfsicgRwgKp+KCKFJgoR6Q30Bqhbt24MQt3euHHb12166y3o3Dnmu3UlsXWr1WIqV84SxdlnwxVX2EhI51yZimUHdUH/sbrtQZFyWB2pm4t7IVUdoKoZqpqxdxzKLOTWhvv8czu78CSRYKZPt8mEXnzRli++GHr18iThXIxEnShEpKQXn2di823nqgMsj1iuCjQFxorIL8CxwIiwO7Rff91uAIcfHmYkbgebN1vNlKOOsnZBr83kXFxEU2a8pYjMAOYFy81FJJoSHt8Bh4hI/aCIYFdgRO6DqrpOVWuqaj1VrQdMAs5V1Sml+UXKwsaNVmEaYNQo749IKN99B0ceaR1F3brB7Nk++YdzcRLNGcUzQHtgNYCq/ojNeFckVd0K9AVGAbOBt1X1JxG5X0TOLX3IZa9vXxsXkXvZa/v2VgrIJZA1a2DDBvj4Y3jtNahRI+yInEsb0XRml1PVxbJ9+292NC+uqh9jI7oj191dyLanRvOasTB4sE1FcOyxULkyPPNMWJG47YwebUX8rr/eMvfPP3v5DedCEM0ZxVIRaQmoiJQXkRuAn2McV9x88w38+afNfvnJJ/D++z6gLnRr19o0pK1bwwsvWN8EeJJwLiTRJIqrgJuAusBKrNP5qlgGFS8TJ8Lxx9v9E3xy18TwwQdWxO/ll210oxfxcy50xTY9qepvWEd0ylm0yH7edx9ceGG4sThgyRL7QzRqBCNGQEZCVnRxLu0UmyhE5EUixj/kUtXeMYkoTu67z6YxBR8nESpVK8t70klQty588YV1Fnl9JucSRjRNT18AXwa3icA+wOZYBhVrK1fmJYlHHoHDDgs1nPS1ZImNqD755Lwifief7EnCuQQTTdPTW5HLIjIY+DxmEcXB4GD271tvtWZwF2c5OdC/v03qoWqXmXkRP+cSVmlqPdUHDizrQOIlJ8cSBNiMmC4E559vndZt21r1xXr1wo7IOVeEaPoo1pDXR1EO+AModG6JRPfBB/azUSM4+OBwY0krkUX8unSBDh2gZ0+vz+RcEigyUYiNsmsOLAtW5ajqDh3byWDePKv68Oijtpzb/OTi4Mcf4fLLbWxEnz5WgsM5lzSKTBSqqiIyTFWPildAsTB16vZXWrZvb3XlXIxlZcEDD9gVA9Wrw377hR2Rc64UornqabKIHBnzSGLkzjvzkkS3bvDDDzBsWLgxpYXJk+GII+DBB6F7dzud69gx7Kicc6VQ6BmFiFQICvudCFwpIguAjdg8E6qqCZ88fv8dHn7Y7r/+un1euTj580/YtAk+/RTOOCPsaJxzO6GopqfJwJFA0n4NzMy0n1dd5UkiLj77DH76CW68Edq0gblzvfyGcymgqEQhAKq6IE6xlLkZM+ynf6GNsTVr4KabYNAgaNIErr7aEoQnCedSQlGJYm8RuamwB1X1iRjEU2ZU4b//hQoVoFWxs2e4Unv/fbjmGli1yjqE7r7bE4RzKaaoRFEe2J2C575OeMuX2xnF1VfDHnuEHU2KWrIEunaFpk1tQqEjjgg7IudcDBSVKFao6v1xi6SM5eTYzyMTvss9yajC+PFwyilWxG/0aJsecJddwo7MORcjRV0em5RnEi6GFi+GM8+EU0/NK+J34omeJJxLcUUlitZxi8IltpwcePZZ66ieMAH+9z8rC+6cSwuFNj2p6h/xDMQlsI4dYeRIu3zshRfgwKStCemcK4XSVI916WDLFihf3or4desGF1wAPXp4ET/n0lA0JTySzsaNdtWTK6Xvv4eWLW3OCLBEccklniScS1MplyjWroX997fZNMEv6S+RTZtsLETLlvDrr3DAAWFH5JxLACnX9PTWW7B+vU150L69zZHjojBpElx6Kfz8s5UEf+wx2GuvsKNyziWAlEkUW7bA0KE23QFAv35Qo0a4MSWVjRvtIH7+udVpcs65QMokir59bVZNgCpV/MtwVD791Ir43XwztG4Nc+ZAxYphR+WcSzAp00cxa5b9nDPHmp7KpcxvFgOrV1sz05lnwquvwt9/23pPEs65AqTEx2lmpo0DO/poOOwwvzinUKrw7rvQuDG8+Sb83//Bd995gnDOFSklmp5WrrSfZ54ZbhwJb8kSuOgiaNbM5o5o3jzsiJxzSSAlzihyRc6L7QKqVrgPbET12LF2hZMnCedclFIiUbz2WtgRJKhFi+D0062jOreI3/HH2yQdzjkXpaRPFCtXwjPPQLVqNi2CA7Kz4emn7YB8+y08/7wX8XPOlVrSf7XctMl+Pvkk1K8fbiwJo0MH+OgjOOssK8PhI6ydczsh6RNFrrS/0imyiF+PHlaf6aKL/MA453ZaTJueRKSdiMwVkfkickcBj98kIrNEZLqIfCkiXr+6NKZMsZ7855+35S5doHt3TxLOuTIRs0QhIuWBfsCZQGOgm4g0zrfZNCBDVZsB7wKPlnQ/a9fubKRJbNMmuP12m4p01SqfJ8I5FxOxPKNoCcxX1YWq+jcwFOgQuYGqjlHVv4LFSUCdkuzg77/h+uvt/uGH73S8yeWbb+wS10cftSJ+s2ZZFUTnnCtjseyjqA0sjVjOBI4pYvsrgE8KekBEegO9AerWrbtt/VNPwfjx1ol91FE7HW9y2bTJpij94gu7/NU552IklomioAZyLXBDkYuBDOCUgh5X1QHAAICMjIxtr/Hnn/bzyy93LtCk8fHHVsTv1lvhtNNg9mzYZZewo3LOpbhYNj1lApHXZdYBdph3TkTaAHcB56rq5pLsYORIOOigNLgs9vff4eKL4eyz4Y038or4eZJwzsVBLBPFd8AhIlJfRCoCXYERkRuIyBHAC1iS+K2kO5g9Gy68sExiTUyqNslGo0bw9ttwzz0webIX8XPOxVXMmp5UdauI9AVGAeWBl1X1JxG5H5iiqiOA/wK7A++IXcq5RFXPLcl+Urqc+JIlVg68eXN46aU07LF3ziWCmA64U9WPgY/zrbs74r5PpZafqnW6tGljl7uOG2f108uXDzsy51yaSuXv48lnwQK7gqlt27wifsce60nCORcqTxSJIDsbnnjCmpamToUXXvAifs65hJEytZ6S2jnnwCef2IC555+HOiUad+icczGV1IlCCxyVkST+/tvmhShXDnr2tEJ+Xbt6fSbnXMJJ2qanpUth61bYf/+wIymFyZNtKPlzz9ly585W7dWThHMuASVtohg71n6ecEKoYZTMX3/BzTfDccfBmjVw8MFhR+Scc8VKyqYnVbj/fjj0UGjWLOxoojRhgo2JWLgQ/vEPeOQRm5bPOecSXFImikmTYP58ePXVJJr+OXdioTFj4NRTw47GOeeiliwfs9sZOhQqVYKOHcOOpBgjR1qdkdtug1atrBR40mQ255wzSdlHMW4cnHIK7LFH2JEUYtUqm4b03HNhyJC8In6eJJxzSSgpE0V2Nuy+e9hRFEAV3nzTivi9+651pHz7rRfxc84ltaT8ipvb3J9wliyByy6DI46wIn5NmoQdkXPO7bSkPKP47TfYZ5+wowjk5MCoUXb/wAPhq69g4kRPEs65lJF0iULVhiDsu2/YkQDz5tlMc+3a2ZysAC1bJujpjnPOlU7SJYotW+xnqIli61b4739tEMcPP1gzkxfxc86lqKTro9i61X7ut1+IQbRvb81NHTpYGY5atUIMxrnEtWXLFjIzM8nKygo7lLSx6667UqdOHXYpw6mSky5R5J5RxL2PYvNmm6O6XDno1Qsuv9zmYfX6TM4VKjMzk6pVq1KvXj3E/1diTlVZvXo1mZmZ1K9fv8xeN+manrKz7Wf16nHc6aRJcOSR0K+fLV9wgRXy8ze+c0XKysqiRo0aniTiRESoUaNGmZ/BJV2iyG162muvOOxs40a48UY4/nhYvx4OOSQOO3UutXiSiK9YHO+ka3rKPaPYc88Y7+irr6yI36JFcPXV8NBDCTwU3DnnYicpzyiqVLHugpjvaJddrF5Iv36eJJxLYsOGDUNEmDNnzrZ1Y8eOpX379ttt17NnT959913AOuLvuOMODjnkEJo2bUrLli355JNPdjqWhx56iAYNGnDYYYcxKncMVj4nnXQSLVq0oEWLFtSqVYuOQWG7devWcc4559C8eXOaNGnCK6+8stPxRCMpzyhi1uw0fLgV8bvzTivi99NPXp/JuRQwZMgQTjzxRIYOHcq9994b1XP+9a9/sWLFCmbOnEmlSpVYuXIl48aN26k4Zs2axdChQ/npp59Yvnw5bdq04eeff6Z8vrFXX3311bb7nTp1okOHDgD069ePxo0bM3LkSFatWsVhhx1G9+7dqRjjMkFJ9ymYnR2DZqeVK+Haa+Gdd6zT+uabrT6TJwnnyswNN9iwo7LUogU89VTR22zYsIGJEycyZswYzj333KgSxV9//cWLL77IokWLqFSpEgD77rsvnTt33ql4P/jgA7p27UqlSpWoX78+DRo0YPLkyRx33HEFbr9+/XpGjx697cxBRFi/fj2qyoYNG6hevToV4vA5lZRNT2V2RqEKgwdD48bwwQfw4IN2hZMX8XMuZQwfPpx27dpx6KGHUr16db7//vtinzN//nzq1q3LHlE0Od94443bmokibw8//PAO2y5btowDDjhg23KdOnVYtmxZoa89bNgwWrduvS2Ovn37Mnv2bGrVqsXhhx/O008/Tblysf8YT7qvzGXa9LRkiY2JyMiw0dUNG5bRCzvn8ivum3+sDBkyhBtuuAGArl27MmTIEI488shCrw4q6VVDTz75ZNTbqmqJ9jdkyBB69eq1bXnUqFG0aNGC0aNHs2DBAtq2bctJJ50UVULbGUmZKHaq6Sm3iN+ZZ1oRv4kTrdqr12dyLuWsXr2a0aNHM3PmTESE7OxsRIRHH32UGjVqsGbNmu22/+OPP6hZsyYNGjRgyZIlrF+/nqpVqxa5jxtvvJExY8bssL5r167ccccd262rU6cOS5cu3bacmZlJrUIqO6xevZrJkyczbNiwbeteeeUV7rjjDkSEBg0aUL9+febMmUPLli2LPRY7RVWT6lau3FF6/fVaOnPnqp50kiqojh1byhdxzkVr1qxZoe6/f//+2rt37+3WnXzyyTp+/HjNysrSevXqbYvxl19+0bp16+ratWtVVfXWW2/Vnj176ubNm1VVdfny5Tp48OCdimfmzJnarFkzzcrK0oULF2r9+vV169atBW77/PPP6yWXXLLduj59+ug999yjqqq//vqr1qpVS1etWrXDcws67sAULe3nbmzTUNnLySlF09PWrfDII1bEb8YMeOUVOPnkmMTnnEscQ4YM4bzzzttuXadOnXjzzTepVKkSr7/+OpdddhktWrTgggsuYODAgVSrVg2ABx54gL333pvGjRvTtGlTOnbsyN57771T8TRp0oTOnTvTuHFj2rVrR79+/bZd8XTWWWexfPnybdsOHTqUbt26bff8f/3rX3z99dccfvjhtG7dmkceeYSaNWvuVEzREC2gzSyRiWTo009P4brrSvCkM86Azz6D88+3MRGhVhR0Ln3Mnj2bRo0ahR1G2inouIvIVFXNKM3rJV0fBUTZR5GVZQPmypeH3r3t1qlTzGNzzrlUk3RNTxBF09PEiXaBdW4Rv06dPEk451wppVai2LABrrvOJhHKygI/5XUudMnWvJ3sYnG8kzJRFNj0NG4cNG0Kzz4LffvCzJnQtm3cY3PO5dl1111ZvXq1J4s40WA+il133bVMXzcp+ygKPaPYbTer+nrCCXGNxzlXsDp16pCZmcmqVavCDiVt5M5wV5aS8qqnjRunsNtuwPvvw5w58M9/2oPZ2T5wzjnnCrAzVz3FtOlJRNqJyFwRmS8idxTweCUReSt4/FsRqVf8a0Lldb/aLHOdOsGwYfD33/agJwnnnCtzMUsUIlIe6AecCTQGuolI43ybXQGsUdUGwJPAI8W97t6yGmncCD780CYT+vprL+LnnHMxFMszipbAfFVdqKp/A0OBDvm26QC8Gtx/F2gtxVTkqpOz2Dqtf/wR7rgjDjMYOedceotlZ3ZtYGnEciZwTGHbqOpWEVkH1AB+j9xIRHoDvYPFzTJhwkyv9ApATfIdqzTmxyKPH4s8fizyHFbaJ8YyURR0ZpC/5zyabVDVAcAAABGZUtoOmVTjxyKPH4s8fizy+LHIIyJTSvvcWDY9ZQIHRCzXAZYXto2IVACqAX/EMCbnnHMlFMtE8R1wiIjUF5GKQFdgRL5tRgCXBvcvAEZrsl2v65xzKS5mTU9Bn0NfYBRQHnhZVX8SkfuxuugjgJeAwSIyHzuT6BrFSw+IVcxJyI9FHj8WefxY5PFjkafUxyLpBtw555yLr6Ss9eSccy5+PFE455wrUsImiliU/0hWURyLm0RklohMF5EvReTAMOKMh+KORcR2F4iIikjKXhoZzbEQkc7Be+MnEXkz3jHGSxT/I3VFZIyITAv+T84KI85YE5GXReQ3EZlZyOMiIs8Ex2m6iBwZ1QuXdrLtWN6wzu8FwEFAReBHoHG+ba4G+gf3uwJvhR13iMeiFbBbcP+qdD4WwXZVgfHAJCAj7LhDfF8cAkwD9gqW9wk77hCPxQDgquB+Y+CXsOOO0bE4GTgSmFnI42cBn2Bj2I4Fvo3mdRP1jCIm5T+SVLHHQlXHqOpfweIkbMxKKormfQHwb+BRICuewcVZNMfiSqCfqq4BUNXf4hxjvERzLBTYI7hfjR3HdKUEVR1P0WPROgCvqZkE7Cki+xf3uomaKAoq/1G7sG1UdSuQW/4j1URzLCJdgX1jSEXFHgsROQI4QFU/jGdgIYjmfXEocKiITBSRSSLSLm7RxVc0x+Je4GIRyQQ+Bq6NT2gJp6SfJ0DiTlxUZuU/UkDUv6eIXAxkAKfENKLwFHksRKQcVoW4Z7wCClE074sKWPPTqdhZ5lci0lRV18Y4tniL5lh0Awap6uMichw2fqupqubEPryEUqrPzUQ9o/DyH3miORaISBvgLuBcVd0cp9jirbhjURVoCowVkV+wNtgRKdqhHe3/yAequkVVFwFzscSRaqI5FlcAbwOo6jfArljBwHQT1edJfomaKLz8R55ij0XQ3PICliRStR0aijkWqrpOVWuqaj1VrYf115yrqqUuhpbAovkfGY5d6ICI1MSaohbGNcr4iOZYLAFaA4hIIyxRpOP8rCOAS4Krn44F1qnqiuKelJBNTxq78h9JJ8pj8V9gd+CdoD9/iaqeG1rQMRLlsUgLUR6LUcDpIjILyAZuVdXV4UUdG1Eei5uBF0XkRqyppWcqfrEUkSFYU2PNoD/mHmAXAFXtj/XPnAXMB/4CLovqdVPwWDnnnCtDidr05JxzLkF4onDOOVckTxTOOeeK5InCOedckTxROOecK5InCpdwRCRbRH6IuNUrYtt6hVXKLOE+xwbVR38MSl4cVorX6CMilwT3e4pIrYjHBopI4zKO8zsRaRHFc24Qkd12dt8ufXmicIlok6q2iLj9Eqf9dlfV5lixyf+W9Mmq2l9VXwsWewK1Ih7rpaqzyiTKvDifI7o4bwA8UbhS80ThkkJw5vCViHwf3I4vYJsmIjI5OAuZLiKHBOsvjlj/goiUL2Z344EGwXNbB3MYzAhq/VcK1j8seXOAPBasu1dEbhGRC7CaW28E+6wcnAlkiMhVIvJoRMw9ReR/pYzzGyIKuonI8yIyRWzuifuCdddhCWuMiIwJ1p0uIt8Ex/EdEdm9mP24NOeJwiWiyhHNTsOCdb8BbVX1SKAL8EwBz+sDPK2qLbAP6sygXEMX4IRgfTbQvZj9nwPMEJFdgUFAF1U9HKtkcJWIVAfOA5qoajPggcgnq+q7wBTsm38LVd0U8fC7wPkRy12At0oZZzusTEeuu1Q1A2gGnCIizVT1GayWTytVbRWU8vg/oE1wLKcANxWzH5fmErKEh0t7m4IPy0i7AM8GbfLZWN2i/L4B7hKROsD7qjpPRFoDRwHfBeVNKmNJpyBviMgm4BesDPVhwCJV/Tl4/FXgGuBZbK6LgSLyERB1SXNVXSUiC4M6O/OCfUwMXrckcVbBylVEzlDWWUR6Y//X+2MT9EzP99xjg/UTg/1UxI6bc4XyROGSxY3ASqA5dia8w6REqvqmiHwLnA2MEpFeWFnlV1X1zij20T2ygKCIFDi/SVBbqCVWZK4r0Bc4rQS/y1tAZ2AOMExVVexTO+o4sVncHgb6AeeLSH3gFuBoVV0jIoOwwnf5CfC5qnYrQbwuzXnTk0sW1YAVwfwBPbBv09sRkYOAhUFzywisCeZL4AIR2SfYprpEP6f4HKCeiDQIlnsA44I2/Wqq+jHWUVzQlUfrsbLnBXkf6IjNkfBWsK5EcarqFqwJ6dig2WoPYCOwTkT2Bc4sJJZJwAm5v5OI7CYiBZ2dObeNJwqXLJ4DLhWRSViz08YCtukCzBSRH4CG2JSPs7AP1M9EZDrwOdYsUyxVzcKqa74jIjOAHKA/9qH7YfB647CznfwGAf1zO7Pzve4aYBZwoKpODtaVOM6g7+Nx4BZV/RGbH/sn4GWsOSvXAOATERmjqquwK7KGBPuZhB0r5wrl1WOdc84Vyc8onHPOFckThXPOuSJ5onDOOVckTxTOOeeK5InCOedckTxROOecK5InCuecc0X6fxjy2bzQa9suAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.78\n"
     ]
    }
   ],
   "source": [
    "graph_roc(y_test.to_numpy(), predictions)\n",
    "print('AUC: '+str(round(roc,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second model to be proven was the XGBoost, here we created a model based on the Bag of Words method, so the first thing here was transform the data to a dummy matrix based on the presence or absence of a word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('Data/Train.csv')\n",
    "new_data=pd.DataFrame()\n",
    "cont=0\n",
    "for lista in data['BOW']:\n",
    "    res = lista.strip('][').replace(\"'\",\"\").split(', ')\n",
    "    cont+=1\n",
    "    a1=pd.DataFrame([res])\n",
    "    new_data=pd.concat([new_data,a1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unir_filas(row):\n",
    "    row=[str(i) for i in row if str(i)!='nan']\n",
    "    return ' '.join(row)\n",
    "train_palabras=new_data.apply(unir_filas, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=3000)\n",
    "features_train = vectorizer.fit_transform(train_palabras).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ortog']=data['Ortografia'].apply(lambda x: 0 if not x else 1)\n",
    "data['emoji_sent_transf']=data.emoji_sentiment.fillna(0.5)\n",
    "data['have_emojis']=data['emoji_sentiment'].apply(lambda x: 0 if str(x)=='nan' else 1)\n",
    "other_x_data=data[['spanish_sentiment', 'emoji_sent_transf','have_emojis','ortog']]\n",
    "other_x_data=other_x_data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain=np.concatenate((other_x_data,features_train),axis=1)\n",
    "y_train=data['ingresos'].apply(lambda x: 0 if x=='Bajos' else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the xgboost package to make the cross validation and selection of hyperparameters, because the Sagemaker process of downloading data an creating the image URI last too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (1.2.1)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from xgboost) (1.18.1)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from xgboost) (1.4.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "profundidades=[5,10,20]\n",
    "muestras=[0.5,0.8,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " I decided to prove the results of AUC with the next hyperparameters\n",
    " \n",
    " max depth:5,10,20\n",
    " subsample= 0.5, 0.8, 1\n",
    " \n",
    " I used a 3CV method to get the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 5\n",
      "0.8 5\n",
      "1 5\n",
      "0.5 10\n",
      "0.8 10\n",
      "1 10\n",
      "0.5 20\n",
      "0.8 20\n",
      "1 20\n"
     ]
    }
   ],
   "source": [
    "listaxg={}\n",
    "output = pd.DataFrame()\n",
    "for p in profundidades:\n",
    "    for m in muestras:\n",
    "        model = XGBClassifier(verbosity=0,max_depth=p ,subsample=m )\n",
    "        model.fit(Xtrain, y_train)\n",
    "        scores = cross_val_score(model, Xtrain, y_train.to_numpy(), cv=3,scoring='roc_auc')\n",
    "        print(m,p)\n",
    "        listaxg.update({'AUC Promedio':np.mean(scores), 'AUC SDV':np.std(scores),'Profundidad':p,'Muestra':m})\n",
    "        output=output.append(listaxg, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best hyperparameter found were when subsample was 1 and the depth was 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC Promedio</th>\n",
       "      <th>AUC SDV</th>\n",
       "      <th>Muestra</th>\n",
       "      <th>Profundidad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.729740</td>\n",
       "      <td>0.013292</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.750947</td>\n",
       "      <td>0.015911</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.753794</td>\n",
       "      <td>0.009652</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.720388</td>\n",
       "      <td>0.013075</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.748588</td>\n",
       "      <td>0.010848</td>\n",
       "      <td>0.8</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.760006</td>\n",
       "      <td>0.006049</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.699496</td>\n",
       "      <td>0.010693</td>\n",
       "      <td>0.5</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.725729</td>\n",
       "      <td>0.010601</td>\n",
       "      <td>0.8</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.748330</td>\n",
       "      <td>0.005043</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AUC Promedio   AUC SDV  Muestra  Profundidad\n",
       "0      0.729740  0.013292      0.5          5.0\n",
       "1      0.750947  0.015911      0.8          5.0\n",
       "2      0.753794  0.009652      1.0          5.0\n",
       "3      0.720388  0.013075      0.5         10.0\n",
       "4      0.748588  0.010848      0.8         10.0\n",
       "5      0.760006  0.006049      1.0         10.0\n",
       "6      0.699496  0.010693      0.5         20.0\n",
       "7      0.725729  0.010601      0.8         20.0\n",
       "8      0.748330  0.005043      1.0         20.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I transformed the test data based on the vocabulary of train data and using the bag of words method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2=pd.read_csv('Data/Test.csv')\n",
    "new_data2=pd.DataFrame()\n",
    "cont=0\n",
    "for lista in data2['BOW']:\n",
    "    res = lista.strip('][').replace(\"'\",\"\").split(', ')\n",
    "    cont+=1\n",
    "    a1=pd.DataFrame([res])\n",
    "    new_data2=pd.concat([new_data2,a1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_palabras=new_data2.apply(unir_filas, 1)\n",
    "data2['ortog']=data2['Ortografia'].apply(lambda x: 0 if not x else 1)\n",
    "data2['emoji_sent_transf']=data2.emoji_sentiment.fillna(0.5)\n",
    "data2['have_emojis']=data2['emoji_sentiment'].apply(lambda x: 0 if str(x)=='nan' else 1)\n",
    "other_x_data2=data2[['spanish_sentiment', 'emoji_sent_transf','have_emojis','ortog']]\n",
    "other_x_data2=other_x_data2.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the same vectorizer to transform the test documents (ignore unknown words)\n",
    "features_test = vectorizer.transform(test_palabras).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest=np.concatenate((other_x_data2,features_test),axis=1)\n",
    "y_test=data2['ingresos'].apply(lambda x: 0 if x=='Bajos' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X = pd.DataFrame(Xtrain[:500])\n",
    "train_X = pd.DataFrame(Xtrain[500:])\n",
    "\n",
    "val_y = pd.DataFrame(y_train[:500])\n",
    "train_y = pd.DataFrame(y_train[500:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "dataxg='Data//XGboost'\n",
    "pd.concat([train_y, train_X], axis=1).to_csv(os.path.join(dataxg, 'train.csv'), header=False, index=False)\n",
    "pd.concat([val_y, val_X], axis=1).to_csv(os.path.join(dataxg, 'validation.csv'), header=False, index=False)\n",
    "pd.DataFrame(Xtest).to_csv(os.path.join(dataxg, 'test.csv'), header=False, index=False)\n",
    "pd.DataFrame(y_test).to_csv(os.path.join(dataxg, 'ytest.csv'), header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally in order of proving the model chosen with the test data I upload the test and train information to S3, to subsequently create a Sagemaker model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "session = sagemaker.Session() # Store the current SageMaker session\n",
    "\n",
    "# S3 prefix (which folder will we use)\n",
    "prefix = 'twitter_xgboost'\n",
    "\n",
    "test_location = session.upload_data(os.path.join(dataxg, 'test.csv'), key_prefix=prefix)\n",
    "train_location = session.upload_data(os.path.join(dataxg, 'train.csv'), key_prefix=prefix)\n",
    "validation_location = session.upload_data(os.path.join(dataxg, 'validation.csv'), key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I created the XGboost estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import get_execution_role\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "role = get_execution_role()\n",
    "container = sagemaker.image_uris.retrieve('xgboost', session.boto_region_name, 'latest', 'py3')\n",
    "xgb = sagemaker.estimator.Estimator(container, # The location of the container we wish to use\n",
    "                                    role,                                    # What is our current IAM Role\n",
    "                                    train_instance_count=1,                  # How many compute instances\n",
    "                                    train_instance_type='ml.m4.xlarge',      # What kind of compute instances\n",
    "                                    output_path='s3://{}/{}/output'.format(session.default_bucket(), prefix),\n",
    "                                    sagemaker_session=session)\n",
    "\n",
    "# And then set the algorithm specific parameters.\n",
    "xgb.set_hyperparameters(max_depth=10,\n",
    "                        subsample=1,\n",
    "                        objective='binary:logistic',\n",
    "                         num_round=500,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        silent=0,\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_train = sagemaker.TrainingInput(s3_data=train_location, content_type='csv')\n",
    "s3_input_validation = sagemaker.TrainingInput(s3_data=validation_location, content_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The I trained the XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-12 20:45:03 Starting - Starting the training job...\n",
      "2020-11-12 20:45:05 Starting - Launching requested ML instances......\n",
      "2020-11-12 20:46:12 Starting - Preparing the instances for training......\n",
      "2020-11-12 20:47:20 Downloading - Downloading input data...\n",
      "2020-11-12 20:47:53 Training - Downloading the training image..\n",
      "2020-11-12 20:48:14 Training - Training image download completed. Training in progress.\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2020-11-12:20:48:15:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2020-11-12:20:48:15:INFO] File size need to be processed in the node: 64.2mb. Available memory size in the node: 8478.34mb\u001b[0m\n",
      "\u001b[34m[2020-11-12:20:48:15:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[20:48:15] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[20:48:15] 5468x3004 matrix with 16425372 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2020-11-12:20:48:15:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[20:48:15] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[20:48:15] 500x3004 matrix with 1502000 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[20:48:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 26 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.411485#011validation-error:0.48\u001b[0m\n",
      "\u001b[34m[20:48:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 30 pruned nodes, max_depth=9\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.408193#011validation-error:0.446\u001b[0m\n",
      "\u001b[34m[20:48:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 24 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.407096#011validation-error:0.458\u001b[0m\n",
      "\u001b[34m[20:48:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 10 pruned nodes, max_depth=10\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.406913#011validation-error:0.454\u001b[0m\n",
      "\u001b[34m[20:48:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.410205#011validation-error:0.446\u001b[0m\n",
      "\u001b[34m[20:48:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 24 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.410936#011validation-error:0.452\u001b[0m\n",
      "\u001b[34m[20:48:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.411302#011validation-error:0.46\u001b[0m\n",
      "\u001b[34m[20:48:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.411119#011validation-error:0.46\u001b[0m\n",
      "\u001b[34m[20:48:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.413131#011validation-error:0.464\u001b[0m\n",
      "\u001b[34m[20:48:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 30 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.415143#011validation-error:0.468\u001b[0m\n",
      "\u001b[34m[20:48:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 30 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.416057#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 30 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.41624#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 30 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.41624#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.41624#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.41624#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.41624#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[16]#011train-error:0.41624#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[18]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[19]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[20]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[21]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[22]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[23]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[24]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[25]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[26]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[27]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[28]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[29]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[30]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[31]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[32]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[33]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[34]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[35]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[36]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[37]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[38]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[39]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[40]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[41]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[42]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[43]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[44]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[45]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[46]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[47]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[48]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[49]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[50]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[51]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[52]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[53]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[54]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[55]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[20:48:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[56]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[57]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[58]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[59]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[60]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[61]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[62]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[63]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[64]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[65]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[66]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[67]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[68]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[69]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[70]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[71]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[72]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[73]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[74]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[75]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[76]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[77]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[78]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[79]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[80]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[81]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[82]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:55] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[83]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:55] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[84]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[85]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[86]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[87]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[88]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[89]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[90]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[91]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:59] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[92]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:48:59] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[93]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[94]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[95]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[96]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[97]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[98]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[99]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[100]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[101]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[102]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[103]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[104]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[105]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[106]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[107]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[108]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[109]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[110]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[111]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[112]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[113]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[114]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[115]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[116]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[117]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[118]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[119]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[120]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[20:49:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[121]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[122]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[123]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[124]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[125]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[126]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[127]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[128]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[129]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[130]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[131]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[132]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[133]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[134]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[135]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[136]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[137]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[138]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[139]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[140]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[141]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[142]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[143]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[144]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[145]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[146]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[147]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[148]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[149]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[150]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[151]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[152]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[153]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[154]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[155]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[156]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[157]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[158]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[159]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[160]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[161]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[162]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[163]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[164]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[165]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[166]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[167]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[168]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[169]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[170]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[171]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[172]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[173]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[174]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[175]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[176]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[177]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[178]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[179]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[180]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[181]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[182]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[183]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[184]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[185]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[186]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[20:49:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[187]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[188]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[189]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[190]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[191]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[192]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[193]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[194]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[195]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[196]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[197]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[198]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[199]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[200]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[201]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[202]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[203]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[204]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[205]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[206]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[207]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[208]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[209]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[210]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[211]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[212]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[213]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:55] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[214]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:55] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[215]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[216]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[217]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[218]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[219]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[220]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[221]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:59] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[222]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:49:59] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[223]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[224]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[225]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[226]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[227]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[228]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[229]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[230]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[231]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[232]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[233]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[234]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[235]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[236]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[237]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[238]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[239]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[240]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[241]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[242]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[243]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[244]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[245]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[246]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[247]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[248]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[249]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[250]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[251]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[20:50:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[252]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[253]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[254]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[255]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[256]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[257]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[258]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[259]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[260]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[261]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[262]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[263]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[264]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[265]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[266]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[267]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[268]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[269]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[270]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[271]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[272]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[273]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[274]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[275]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[276]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[277]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[278]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[279]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[280]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[281]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[282]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[283]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[284]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[285]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[286]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[287]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[288]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[289]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[290]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[291]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[292]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[293]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[294]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[295]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[296]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[297]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[298]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[299]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[300]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[301]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[302]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[303]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[304]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[305]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[306]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[307]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[308]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[309]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[310]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[311]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[312]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[313]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[314]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[315]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[316]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[20:50:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[317]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[318]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[319]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[320]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[321]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[322]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[323]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[324]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[325]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[326]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[327]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[328]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[329]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[330]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[331]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[332]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[333]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[334]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[335]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[336]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[337]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[338]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[339]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[340]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[341]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[342]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[343]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:55] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[344]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:55] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[345]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[346]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[347]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[348]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[349]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[350]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[351]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[352]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:59] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[353]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:50:59] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[354]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[355]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[356]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[357]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[358]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[359]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[360]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[361]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[362]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[363]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[364]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[365]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[366]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[367]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[368]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[369]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[370]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[371]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[372]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[373]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:08] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[374]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[375]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[376]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[377]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:10] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[378]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[379]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[380]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[381]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:12] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[382]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[20:51:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[383]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[384]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[385]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[386]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[387]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[388]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:15] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[389]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[390]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[391]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[392]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:17] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[393]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[394]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:18] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[395]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[396]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[397]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:19] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[398]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[399]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:20] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[400]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[401]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[402]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[403]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[404]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[405]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:23] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[406]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[407]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:24] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[408]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[409]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[410]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:25] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[411]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[412]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:26] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[413]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[414]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:27] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[415]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[416]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:28] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[417]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[418]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[419]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[420]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[421]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[422]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[423]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[424]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[425]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:32] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[426]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[427]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:33] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[428]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[429]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:34] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[430]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[431]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:35] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[432]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[433]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:36] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[434]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[435]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[436]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:37] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[437]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[438]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:38] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[439]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[440]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:39] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[441]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[442]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:40] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[443]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[444]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[445]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[446]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:42] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[447]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[20:51:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[448]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[449]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:43] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[450]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[451]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[452]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[453]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:45] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[454]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[455]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:46] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[456]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[457]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:47] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[458]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[459]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:48] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[460]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[461]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[462]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:49] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[463]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[464]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:50] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[465]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[466]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[467]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[468]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:52] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[469]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[470]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:53] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[471]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[472]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:54] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[473]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:55] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[474]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:55] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[475]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:55] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[476]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[477]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:56] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[478]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[479]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:57] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[480]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[481]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[482]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:59] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[483]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:51:59] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[484]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:52:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[485]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:52:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[486]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:52:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[487]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:52:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[488]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:52:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[489]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:52:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[490]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:52:02] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[491]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:52:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[492]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:52:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[493]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:52:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[494]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:52:04] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[495]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:52:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[496]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:52:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[497]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:52:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[498]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n",
      "\u001b[34m[20:52:06] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 26 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[499]#011train-error:0.416789#011validation-error:0.47\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-11-12 20:52:14 Uploading - Uploading generated training model\n",
      "2020-11-12 20:52:14 Completed - Training job completed\n",
      "Training seconds: 294\n",
      "Billable seconds: 294\n"
     ]
    }
   ],
   "source": [
    "xgb.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The I depoyed the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "xgb_predictor = xgb.deploy(initial_instance_count = 1, instance_type = 'ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import csv_serializer\n",
    "\n",
    "# We need to tell the endpoint what format the data we are sending is in so that SageMaker can perform the serialization.\n",
    "\n",
    "xgb_predictor.serializer = csv_serializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally I proved the results in the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictxgb(data, rows=512):\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = ''\n",
    "    for array in split_array:\n",
    "        predictions = ','.join([predictions, xgb_predictor.predict(array).decode('utf-8')])\n",
    "    \n",
    "    return np.fromstring(predictions[1:], sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The csv_serializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The csv_serializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The csv_serializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "test_X = pd.read_csv(os.path.join(dataxg, 'test.csv'), header=None).values\n",
    "\n",
    "predictions = predictxgb(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5156143938547726"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import sklearn.metrics as metrics\n",
    "roc_auc_score(y_test.to_numpy(), predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph_roc(y_test.to_numpy(), predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I obtained a vey poor prediction with this model, getting a AUC of 0.52 and a very bad ROC curve. This model predicts so bad in the test data, possibly for the large number of variables, that can be a problem for XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted xgboost-2020-11-12-21-03-56-990\n"
     ]
    }
   ],
   "source": [
    "delete_endpoint(xgb_predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark:  Linear Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we create a model with a linear learner that will helped me to test my model and decide if the metrics that I was obtaining in the other model are good or not.\n",
    "\n",
    "For this model I created a Sagemaker model, using the bag of words method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "# import LinearLearner\n",
    "from sagemaker import LinearLearner\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "# specify an output path\n",
    "prefix = 'LinearLearner'\n",
    "output_path = 's3://{}/{}'.format(bucket, prefix)\n",
    "\n",
    "# instantiate LinearLearner\n",
    "linear = LinearLearner(role=role,\n",
    "                       train_instance_count=1, \n",
    "                       train_instance_type='ml.c4.xlarge',\n",
    "                       predictor_type='binary_classifier',\n",
    "                       output_path=output_path,\n",
    "                       sagemaker_session=sagemaker_session,\n",
    "                       epochs=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       0\n",
       "2       0\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "5463    0\n",
       "5464    0\n",
       "5465    1\n",
       "5466    0\n",
       "5467    1\n",
       "Name: ingresos, Length: 5468, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert features/labels to numpy\n",
    "train_x_np = Xtrain.astype('float32')\n",
    "train_y_np = y_train.astype('float32')\n",
    "\n",
    "# create RecordSet\n",
    "formatted_train_data = linear.record_set(train_x_np, labels=train_y_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating a model, I trained and deployed the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: 1.\n",
      "Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-12 19:34:02 Starting - Starting the training job...\n",
      "2020-11-12 19:34:04 Starting - Launching requested ML instances......\n",
      "2020-11-12 19:35:07 Starting - Preparing the instances for training......\n",
      "2020-11-12 19:36:13 Downloading - Downloading input data...\n",
      "2020-11-12 19:37:01 Training - Training image download completed. Training in progress..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:07 INFO 139838722238272] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'loss_insensitivity': u'0.01', u'epochs': u'15', u'feature_dim': u'auto', u'init_bias': u'0.0', u'lr_scheduler_factor': u'auto', u'num_calibration_samples': u'10000000', u'accuracy_top_k': u'3', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'num_point_for_scaler': u'10000', u'_log_level': u'info', u'quantile': u'0.5', u'bias_lr_mult': u'auto', u'lr_scheduler_step': u'auto', u'init_method': u'uniform', u'init_sigma': u'0.01', u'lr_scheduler_minimum_lr': u'auto', u'target_recall': u'0.8', u'num_models': u'auto', u'early_stopping_patience': u'3', u'momentum': u'auto', u'unbias_label': u'auto', u'wd': u'auto', u'optimizer': u'auto', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.001', u'learning_rate': u'auto', u'_kvstore': u'auto', u'normalize_data': u'true', u'binary_classifier_model_selection_criteria': u'accuracy', u'use_lr_scheduler': u'true', u'target_precision': u'0.8', u'unbias_data': u'auto', u'init_scale': u'0.07', u'bias_wd_mult': u'auto', u'f_beta': u'1.0', u'mini_batch_size': u'1000', u'huber_delta': u'1.0', u'num_classes': u'1', u'beta_1': u'auto', u'loss': u'auto', u'beta_2': u'auto', u'_enable_profiler': u'false', u'normalize_label': u'auto', u'_num_gpus': u'auto', u'balance_multiclass_weights': u'false', u'positive_example_weight_mult': u'1.0', u'l1': u'auto', u'margin': u'1.0'}\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:07 INFO 139838722238272] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {u'epochs': u'15', u'feature_dim': u'3004', u'mini_batch_size': u'1000', u'predictor_type': u'binary_classifier'}\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:07 INFO 139838722238272] Final configuration: {u'loss_insensitivity': u'0.01', u'epochs': u'15', u'feature_dim': u'3004', u'init_bias': u'0.0', u'lr_scheduler_factor': u'auto', u'num_calibration_samples': u'10000000', u'accuracy_top_k': u'3', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'num_point_for_scaler': u'10000', u'_log_level': u'info', u'quantile': u'0.5', u'bias_lr_mult': u'auto', u'lr_scheduler_step': u'auto', u'init_method': u'uniform', u'init_sigma': u'0.01', u'lr_scheduler_minimum_lr': u'auto', u'target_recall': u'0.8', u'num_models': u'auto', u'early_stopping_patience': u'3', u'momentum': u'auto', u'unbias_label': u'auto', u'wd': u'auto', u'optimizer': u'auto', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.001', u'learning_rate': u'auto', u'_kvstore': u'auto', u'normalize_data': u'true', u'binary_classifier_model_selection_criteria': u'accuracy', u'use_lr_scheduler': u'true', u'target_precision': u'0.8', u'unbias_data': u'auto', u'init_scale': u'0.07', u'bias_wd_mult': u'auto', u'f_beta': u'1.0', u'mini_batch_size': u'1000', u'huber_delta': u'1.0', u'num_classes': u'1', u'predictor_type': u'binary_classifier', u'beta_1': u'auto', u'loss': u'auto', u'beta_2': u'auto', u'_enable_profiler': u'false', u'normalize_label': u'auto', u'_num_gpus': u'auto', u'balance_multiclass_weights': u'false', u'positive_example_weight_mult': u'1.0', u'l1': u'auto', u'margin': u'1.0'}\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:07 WARNING 139838722238272] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:07 INFO 139838722238272] Using default worker.\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:08 INFO 139838722238272] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[2020-11-12 19:37:08.078] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 44, \"num_examples\": 1, \"num_bytes\": 12064000}\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:08 INFO 139838722238272] Create Store: local\u001b[0m\n",
      "\u001b[34m[2020-11-12 19:37:08.727] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 647, \"num_examples\": 6, \"num_bytes\": 65965952}\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:08 INFO 139838722238272] Scaler algorithm parameters\n",
      " <algorithm.scaler.ScalerAlgorithmStable object at 0x7f2e5ddfbcd0>\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:08 INFO 139838722238272] Scaling model computed with parameters:\n",
      " {'stdev_weight': \u001b[0m\n",
      "\u001b[34m[0.27514964 0.09042307 0.4658556  ... 0.02827296 0.019996   0.019996  ]\u001b[0m\n",
      "\u001b[34m<NDArray 3004 @cpu(0)>, 'stdev_label': None, 'mean_label': None, 'mean_weight': \u001b[0m\n",
      "\u001b[34m[3.6890590e-01 5.1160669e-01 3.1840003e-01 ... 8.0000004e-04 4.0000002e-04\n",
      " 4.0000002e-04]\u001b[0m\n",
      "\u001b[34m<NDArray 3004 @cpu(0)>}\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:08 INFO 139838722238272] nvidia-smi took: 0.0252659320831 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:08 INFO 139838722238272] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 7, \"sum\": 7.0, \"min\": 7}, \"Total Records Seen\": {\"count\": 1, \"max\": 6468, \"sum\": 6468.0, \"min\": 6468}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 5468, \"sum\": 5468.0, \"min\": 5468}, \"Reset Count\": {\"count\": 1, \"max\": 2, \"sum\": 2.0, \"min\": 2}}, \"EndTime\": 1605209828.835484, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\"}, \"StartTime\": 1605209828.835445}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-11-12 19:37:09.172] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 4, \"duration\": 336, \"num_examples\": 6, \"num_bytes\": 65965952}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 1.0122971069335938, \"sum\": 1.0122971069335938, \"min\": 1.0122971069335938}}, \"EndTime\": 1605209829.173266, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1605209829.172978}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 1.015811474609375, \"sum\": 1.015811474609375, \"min\": 1.015811474609375}}, \"EndTime\": 1605209829.173371, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1605209829.173354}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 1.0479595703125, \"sum\": 1.0479595703125, \"min\": 1.0479595703125}}, \"EndTime\": 1605209829.173421, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1605209829.173409}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 1.0084465576171875, \"sum\": 1.0084465576171875, \"min\": 1.0084465576171875}}, \"EndTime\": 1605209829.173467, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1605209829.173455}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 1.6550962890625, \"sum\": 1.6550962890625, \"min\": 1.6550962890625}}, \"EndTime\": 1605209829.173508, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1605209829.173498}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 1.7095728271484374, \"sum\": 1.7095728271484374, \"min\": 1.7095728271484374}}, \"EndTime\": 1605209829.173557, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1605209829.173537}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 1.7088623046875, \"sum\": 1.7088623046875, \"min\": 1.7088623046875}}, \"EndTime\": 1605209829.173595, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1605209829.173585}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 1.6958173583984375, \"sum\": 1.6958173583984375, \"min\": 1.6958173583984375}}, \"EndTime\": 1605209829.173633, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1605209829.173623}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.9832389038085938, \"sum\": 0.9832389038085938, \"min\": 0.9832389038085938}}, \"EndTime\": 1605209829.173671, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1605209829.173661}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.9886088256835938, \"sum\": 0.9886088256835938, \"min\": 0.9886088256835938}}, \"EndTime\": 1605209829.173712, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1605209829.173701}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.9847881713867187, \"sum\": 0.9847881713867187, \"min\": 0.9847881713867187}}, \"EndTime\": 1605209829.173751, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1605209829.173741}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 1.0093486572265624, \"sum\": 1.0093486572265624, \"min\": 1.0093486572265624}}, \"EndTime\": 1605209829.173789, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1605209829.173779}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 1.5700634521484376, \"sum\": 1.5700634521484376, \"min\": 1.5700634521484376}}, \"EndTime\": 1605209829.173827, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1605209829.173817}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 1.59520380859375, \"sum\": 1.59520380859375, \"min\": 1.59520380859375}}, \"EndTime\": 1605209829.173865, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1605209829.173855}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 1.5512724365234376, \"sum\": 1.5512724365234376, \"min\": 1.5512724365234376}}, \"EndTime\": 1605209829.173902, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1605209829.173892}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 1.57548115234375, \"sum\": 1.57548115234375, \"min\": 1.57548115234375}}, \"EndTime\": 1605209829.17394, \"Dimensions\": {\"model\": 15, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1605209829.17393}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.96710771484375, \"sum\": 0.96710771484375, \"min\": 0.96710771484375}}, \"EndTime\": 1605209829.173977, \"Dimensions\": {\"model\": 16, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1605209829.173967}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.9269659545898438, \"sum\": 0.9269659545898438, \"min\": 0.9269659545898438}}, \"EndTime\": 1605209829.174015, \"Dimensions\": {\"model\": 17, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1605209829.174004}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.9514951538085937, \"sum\": 0.9514951538085937, \"min\": 0.9514951538085937}}, \"EndTime\": 1605209829.174052, \"Dimensions\": {\"model\": 18, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1605209829.174042}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.9407386474609375, \"sum\": 0.9407386474609375, \"min\": 0.9407386474609375}}, \"EndTime\": 1605209829.17409, \"Dimensions\": {\"model\": 19, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1605209829.17408}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 1.073125048828125, \"sum\": 1.073125048828125, \"min\": 1.073125048828125}}, \"EndTime\": 1605209829.174134, \"Dimensions\": {\"model\": 20, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1605209829.17412}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 1.0269488891601561, \"sum\": 1.0269488891601561, \"min\": 1.0269488891601561}}, \"EndTime\": 1605209829.174183, \"Dimensions\": {\"model\": 21, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1605209829.174173}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 1.0731598388671875, \"sum\": 1.0731598388671875, \"min\": 1.0731598388671875}}, \"EndTime\": 1605209829.174235, \"Dimensions\": {\"model\": 22, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1605209829.174219}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 1.0536020141601563, \"sum\": 1.0536020141601563, \"min\": 1.0536020141601563}}, \"EndTime\": 1605209829.174288, \"Dimensions\": {\"model\": 23, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1605209829.174273}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.9476389038085937, \"sum\": 0.9476389038085937, \"min\": 0.9476389038085937}}, \"EndTime\": 1605209829.174345, \"Dimensions\": {\"model\": 24, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1605209829.174329}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.9561268676757813, \"sum\": 0.9561268676757813, \"min\": 0.9561268676757813}}, \"EndTime\": 1605209829.174403, \"Dimensions\": {\"model\": 25, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1605209829.174387}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.96792783203125, \"sum\": 0.96792783203125, \"min\": 0.96792783203125}}, \"EndTime\": 1605209829.17446, \"Dimensions\": {\"model\": 26, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1605209829.174444}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.9528700561523438, \"sum\": 0.9528700561523438, \"min\": 0.9528700561523438}}, \"EndTime\": 1605209829.174528, \"Dimensions\": {\"model\": 27, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1605209829.174509}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 1.1432607421875, \"sum\": 1.1432607421875, \"min\": 1.1432607421875}}, \"EndTime\": 1605209829.174594, \"Dimensions\": {\"model\": 28, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1605209829.174576}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 1.1401135864257812, \"sum\": 1.1401135864257812, \"min\": 1.1401135864257812}}, \"EndTime\": 1605209829.174656, \"Dimensions\": {\"model\": 29, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1605209829.174639}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 1.1764129028320311, \"sum\": 1.1764129028320311, \"min\": 1.1764129028320311}}, \"EndTime\": 1605209829.174719, \"Dimensions\": {\"model\": 30, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1605209829.174701}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 1.1679194091796874, \"sum\": 1.1679194091796874, \"min\": 1.1679194091796874}}, \"EndTime\": 1605209829.174783, \"Dimensions\": {\"model\": 31, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1605209829.174765}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:09 INFO 139838722238272] #quality_metric: host=algo-1, epoch=0, train binary_classification_cross_entropy_objective <loss>=1.01229710693\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:09 INFO 139838722238272] #early_stopping_criteria_metric: host=algo-1, epoch=0, criteria=binary_classification_cross_entropy_objective, value=0.92696595459\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:09 INFO 139838722238272] Epoch 0: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:09 INFO 139838722238272] Saving model for epoch: 0\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:09 INFO 139838722238272] Saved checkpoint to \"/tmp/tmpqHwumV/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:09 INFO 139838722238272] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 5468, \"sum\": 5468.0, \"min\": 5468}, \"Total Batches Seen\": {\"count\": 1, \"max\": 13, \"sum\": 13.0, \"min\": 13}, \"Total Records Seen\": {\"count\": 1, \"max\": 11936, \"sum\": 11936.0, \"min\": 11936}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 5468, \"sum\": 5468.0, \"min\": 5468}, \"Reset Count\": {\"count\": 1, \"max\": 3, \"sum\": 3.0, \"min\": 3}}, \"EndTime\": 1605209829.19386, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 0}, \"StartTime\": 1605209828.835751}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:09 INFO 139838722238272] #throughput_metric: host=algo-1, train throughput=15263.3831623 records/second\u001b[0m\n",
      "\u001b[34m[2020-11-12 19:37:09.485] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 6, \"duration\": 291, \"num_examples\": 6, \"num_bytes\": 65965952}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6624428588867187, \"sum\": 0.6624428588867187, \"min\": 0.6624428588867187}}, \"EndTime\": 1605209829.485642, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1605209829.485533}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.664313232421875, \"sum\": 0.664313232421875, \"min\": 0.664313232421875}}, \"EndTime\": 1605209829.485916, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1605209829.485893}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6829524536132813, \"sum\": 0.6829524536132813, \"min\": 0.6829524536132813}}, \"EndTime\": 1605209829.486064, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1605209829.485961}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6535181274414062, \"sum\": 0.6535181274414062, \"min\": 0.6535181274414062}}, \"EndTime\": 1605209829.48624, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1605209829.48622}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.74297568359375, \"sum\": 0.74297568359375, \"min\": 0.74297568359375}}, \"EndTime\": 1605209829.486348, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1605209829.486284}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7803333618164062, \"sum\": 0.7803333618164062, \"min\": 0.7803333618164062}}, \"EndTime\": 1605209829.486412, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1605209829.486397}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7616343994140625, \"sum\": 0.7616343994140625, \"min\": 0.7616343994140625}}, \"EndTime\": 1605209829.486508, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1605209829.486491}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.774372021484375, \"sum\": 0.774372021484375, \"min\": 0.774372021484375}}, \"EndTime\": 1605209829.486561, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1605209829.486547}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6446406372070312, \"sum\": 0.6446406372070312, \"min\": 0.6446406372070312}}, \"EndTime\": 1605209829.486688, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1605209829.48667}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6440438232421875, \"sum\": 0.6440438232421875, \"min\": 0.6440438232421875}}, \"EndTime\": 1605209829.486751, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1605209829.486734}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6381623168945313, \"sum\": 0.6381623168945313, \"min\": 0.6381623168945313}}, \"EndTime\": 1605209829.486804, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1605209829.48679}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6488980590820312, \"sum\": 0.6488980590820312, \"min\": 0.6488980590820312}}, \"EndTime\": 1605209829.486981, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1605209829.486886}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7189585693359375, \"sum\": 0.7189585693359375, \"min\": 0.7189585693359375}}, \"EndTime\": 1605209829.487058, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1605209829.487039}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7164740234375, \"sum\": 0.7164740234375, \"min\": 0.7164740234375}}, \"EndTime\": 1605209829.487114, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1605209829.487099}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6908780883789063, \"sum\": 0.6908780883789063, \"min\": 0.6908780883789063}}, \"EndTime\": 1605209829.487298, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1605209829.487277}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7545357421875, \"sum\": 0.7545357421875, \"min\": 0.7545357421875}}, \"EndTime\": 1605209829.487363, \"Dimensions\": {\"model\": 15, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1605209829.487346}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6673639770507812, \"sum\": 0.6673639770507812, \"min\": 0.6673639770507812}}, \"EndTime\": 1605209829.487419, \"Dimensions\": {\"model\": 16, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1605209829.487404}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6543246948242187, \"sum\": 0.6543246948242187, \"min\": 0.6543246948242187}}, \"EndTime\": 1605209829.487605, \"Dimensions\": {\"model\": 17, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1605209829.487586}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.661388525390625, \"sum\": 0.661388525390625, \"min\": 0.661388525390625}}, \"EndTime\": 1605209829.487668, \"Dimensions\": {\"model\": 18, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1605209829.487652}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6602156127929687, \"sum\": 0.6602156127929687, \"min\": 0.6602156127929687}}, \"EndTime\": 1605209829.487721, \"Dimensions\": {\"model\": 19, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1605209829.487707}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 1.0354355712890626, \"sum\": 1.0354355712890626, \"min\": 1.0354355712890626}}, \"EndTime\": 1605209829.487911, \"Dimensions\": {\"model\": 20, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1605209829.487892}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 1.087914892578125, \"sum\": 1.087914892578125, \"min\": 1.087914892578125}}, \"EndTime\": 1605209829.487969, \"Dimensions\": {\"model\": 21, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1605209829.487954}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 1.0250520629882813, \"sum\": 1.0250520629882813, \"min\": 1.0250520629882813}}, \"EndTime\": 1605209829.488027, \"Dimensions\": {\"model\": 22, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1605209829.48801}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 1.0645661376953126, \"sum\": 1.0645661376953126, \"min\": 1.0645661376953126}}, \"EndTime\": 1605209829.488212, \"Dimensions\": {\"model\": 23, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1605209829.488189}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7622268432617187, \"sum\": 0.7622268432617187, \"min\": 0.7622268432617187}}, \"EndTime\": 1605209829.488277, \"Dimensions\": {\"model\": 24, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1605209829.488259}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.763690380859375, \"sum\": 0.763690380859375, \"min\": 0.763690380859375}}, \"EndTime\": 1605209829.488451, \"Dimensions\": {\"model\": 25, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1605209829.48832}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7674181396484375, \"sum\": 0.7674181396484375, \"min\": 0.7674181396484375}}, \"EndTime\": 1605209829.488528, \"Dimensions\": {\"model\": 26, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1605209829.488507}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7689826293945312, \"sum\": 0.7689826293945312, \"min\": 0.7689826293945312}}, \"EndTime\": 1605209829.488593, \"Dimensions\": {\"model\": 27, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1605209829.488575}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.9603771118164063, \"sum\": 0.9603771118164063, \"min\": 0.9603771118164063}}, \"EndTime\": 1605209829.488785, \"Dimensions\": {\"model\": 28, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1605209829.488636}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.9750402465820313, \"sum\": 0.9750402465820313, \"min\": 0.9750402465820313}}, \"EndTime\": 1605209829.488859, \"Dimensions\": {\"model\": 29, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1605209829.48884}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.9590239624023438, \"sum\": 0.9590239624023438, \"min\": 0.9590239624023438}}, \"EndTime\": 1605209829.489009, \"Dimensions\": {\"model\": 30, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1605209829.488904}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.9614324340820313, \"sum\": 0.9614324340820313, \"min\": 0.9614324340820313}}, \"EndTime\": 1605209829.48909, \"Dimensions\": {\"model\": 31, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1605209829.48907}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:09 INFO 139838722238272] #quality_metric: host=algo-1, epoch=1, train binary_classification_cross_entropy_objective <loss>=0.662442858887\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:09 INFO 139838722238272] #early_stopping_criteria_metric: host=algo-1, epoch=1, criteria=binary_classification_cross_entropy_objective, value=0.638162316895\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:09 INFO 139838722238272] Epoch 1: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:09 INFO 139838722238272] Saving model for epoch: 1\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:09 INFO 139838722238272] Saved checkpoint to \"/tmp/tmpfdG_ll/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:09 INFO 139838722238272] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 5468, \"sum\": 5468.0, \"min\": 5468}, \"Total Batches Seen\": {\"count\": 1, \"max\": 19, \"sum\": 19.0, \"min\": 19}, \"Total Records Seen\": {\"count\": 1, \"max\": 17404, \"sum\": 17404.0, \"min\": 17404}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 5468, \"sum\": 5468.0, \"min\": 5468}, \"Reset Count\": {\"count\": 1, \"max\": 4, \"sum\": 4.0, \"min\": 4}}, \"EndTime\": 1605209829.505638, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 1}, \"StartTime\": 1605209829.194142}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:09 INFO 139838722238272] #throughput_metric: host=algo-1, train throughput=17546.2742043 records/second\u001b[0m\n",
      "\u001b[34m[2020-11-12 19:37:09.870] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 8, \"duration\": 364, \"num_examples\": 6, \"num_bytes\": 65965952}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.49456951904296875, \"sum\": 0.49456951904296875, \"min\": 0.49456951904296875}}, \"EndTime\": 1605209829.87092, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1605209829.870599}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.48933599853515625, \"sum\": 0.48933599853515625, \"min\": 0.48933599853515625}}, \"EndTime\": 1605209829.871047, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1605209829.870999}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.4992087524414062, \"sum\": 0.4992087524414062, \"min\": 0.4992087524414062}}, \"EndTime\": 1605209829.871124, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1605209829.871103}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.480887548828125, \"sum\": 0.480887548828125, \"min\": 0.480887548828125}}, \"EndTime\": 1605209829.871221, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1605209829.871171}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.49259794921875, \"sum\": 0.49259794921875, \"min\": 0.49259794921875}}, \"EndTime\": 1605209829.871328, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1605209829.871307}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.49555753173828127, \"sum\": 0.49555753173828127, \"min\": 0.49555753173828127}}, \"EndTime\": 1605209829.871394, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1605209829.871376}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.4996763427734375, \"sum\": 0.4996763427734375, \"min\": 0.4996763427734375}}, \"EndTime\": 1605209829.871542, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1605209829.871496}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5033104553222656, \"sum\": 0.5033104553222656, \"min\": 0.5033104553222656}}, \"EndTime\": 1605209829.871614, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1605209829.871594}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.47687359619140623, \"sum\": 0.47687359619140623, \"min\": 0.47687359619140623}}, \"EndTime\": 1605209829.871706, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1605209829.871659}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.48011480712890625, \"sum\": 0.48011480712890625, \"min\": 0.48011480712890625}}, \"EndTime\": 1605209829.871775, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1605209829.871756}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.47204896240234373, \"sum\": 0.47204896240234373, \"min\": 0.47204896240234373}}, \"EndTime\": 1605209829.871863, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1605209829.871816}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.47596693725585937, \"sum\": 0.47596693725585937, \"min\": 0.47596693725585937}}, \"EndTime\": 1605209829.871932, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1605209829.871914}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.4733357360839844, \"sum\": 0.4733357360839844, \"min\": 0.4733357360839844}}, \"EndTime\": 1605209829.872017, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1605209829.871977}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.50397607421875, \"sum\": 0.50397607421875, \"min\": 0.50397607421875}}, \"EndTime\": 1605209829.87208, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1605209829.872062}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.4605353271484375, \"sum\": 0.4605353271484375, \"min\": 0.4605353271484375}}, \"EndTime\": 1605209829.872142, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1605209829.872124}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.4883364013671875, \"sum\": 0.4883364013671875, \"min\": 0.4883364013671875}}, \"EndTime\": 1605209829.872198, \"Dimensions\": {\"model\": 15, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1605209829.872181}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5601791748046875, \"sum\": 0.5601791748046875, \"min\": 0.5601791748046875}}, \"EndTime\": 1605209829.872259, \"Dimensions\": {\"model\": 16, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1605209829.872241}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5644171630859375, \"sum\": 0.5644171630859375, \"min\": 0.5644171630859375}}, \"EndTime\": 1605209829.872322, \"Dimensions\": {\"model\": 17, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1605209829.872305}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5668092041015625, \"sum\": 0.5668092041015625, \"min\": 0.5668092041015625}}, \"EndTime\": 1605209829.872381, \"Dimensions\": {\"model\": 18, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1605209829.872364}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.567837744140625, \"sum\": 0.567837744140625, \"min\": 0.567837744140625}}, \"EndTime\": 1605209829.872441, \"Dimensions\": {\"model\": 19, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1605209829.872424}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7990738891601562, \"sum\": 0.7990738891601562, \"min\": 0.7990738891601562}}, \"EndTime\": 1605209829.872499, \"Dimensions\": {\"model\": 20, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1605209829.872482}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7859812255859375, \"sum\": 0.7859812255859375, \"min\": 0.7859812255859375}}, \"EndTime\": 1605209829.872557, \"Dimensions\": {\"model\": 21, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1605209829.872541}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.8274547607421875, \"sum\": 0.8274547607421875, \"min\": 0.8274547607421875}}, \"EndTime\": 1605209829.872611, \"Dimensions\": {\"model\": 22, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1605209829.872595}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7926824951171875, \"sum\": 0.7926824951171875, \"min\": 0.7926824951171875}}, \"EndTime\": 1605209829.872671, \"Dimensions\": {\"model\": 23, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1605209829.872653}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7095367309570313, \"sum\": 0.7095367309570313, \"min\": 0.7095367309570313}}, \"EndTime\": 1605209829.872732, \"Dimensions\": {\"model\": 24, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1605209829.872715}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7084788330078124, \"sum\": 0.7084788330078124, \"min\": 0.7084788330078124}}, \"EndTime\": 1605209829.872793, \"Dimensions\": {\"model\": 25, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1605209829.872775}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.70829765625, \"sum\": 0.70829765625, \"min\": 0.70829765625}}, \"EndTime\": 1605209829.872853, \"Dimensions\": {\"model\": 26, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1605209829.872836}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.710320947265625, \"sum\": 0.710320947265625, \"min\": 0.710320947265625}}, \"EndTime\": 1605209829.872947, \"Dimensions\": {\"model\": 27, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1605209829.872895}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.8433781860351562, \"sum\": 0.8433781860351562, \"min\": 0.8433781860351562}}, \"EndTime\": 1605209829.873011, \"Dimensions\": {\"model\": 28, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1605209829.872993}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.8329876708984375, \"sum\": 0.8329876708984375, \"min\": 0.8329876708984375}}, \"EndTime\": 1605209829.873072, \"Dimensions\": {\"model\": 29, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1605209829.873054}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.847967041015625, \"sum\": 0.847967041015625, \"min\": 0.847967041015625}}, \"EndTime\": 1605209829.873127, \"Dimensions\": {\"model\": 30, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1605209829.873112}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.844387109375, \"sum\": 0.844387109375, \"min\": 0.844387109375}}, \"EndTime\": 1605209829.87318, \"Dimensions\": {\"model\": 31, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1605209829.873164}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:09 INFO 139838722238272] #quality_metric: host=algo-1, epoch=2, train binary_classification_cross_entropy_objective <loss>=0.494569519043\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:09 INFO 139838722238272] #early_stopping_criteria_metric: host=algo-1, epoch=2, criteria=binary_classification_cross_entropy_objective, value=0.460535327148\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:09 INFO 139838722238272] Epoch 2: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:09 INFO 139838722238272] Saving model for epoch: 2\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:09 INFO 139838722238272] Saved checkpoint to \"/tmp/tmpRM148c/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:09 INFO 139838722238272] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 5468, \"sum\": 5468.0, \"min\": 5468}, \"Total Batches Seen\": {\"count\": 1, \"max\": 25, \"sum\": 25.0, \"min\": 25}, \"Total Records Seen\": {\"count\": 1, \"max\": 22872, \"sum\": 22872.0, \"min\": 22872}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 5468, \"sum\": 5468.0, \"min\": 5468}, \"Reset Count\": {\"count\": 1, \"max\": 5, \"sum\": 5.0, \"min\": 5}}, \"EndTime\": 1605209829.887802, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 2}, \"StartTime\": 1605209829.505923}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:09 INFO 139838722238272] #throughput_metric: host=algo-1, train throughput=14314.173005 records/second\u001b[0m\n",
      "\u001b[34m[2020-11-12 19:37:10.238] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 10, \"duration\": 349, \"num_examples\": 6, \"num_bytes\": 65965952}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.4042120849609375, \"sum\": 0.4042120849609375, \"min\": 0.4042120849609375}}, \"EndTime\": 1605209830.238348, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1605209830.238236}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.3962180114746094, \"sum\": 0.3962180114746094, \"min\": 0.3962180114746094}}, \"EndTime\": 1605209830.238457, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1605209830.238434}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.402228369140625, \"sum\": 0.402228369140625, \"min\": 0.402228369140625}}, \"EndTime\": 1605209830.238526, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1605209830.238507}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.39222986450195313, \"sum\": 0.39222986450195313, \"min\": 0.39222986450195313}}, \"EndTime\": 1605209830.238588, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1605209830.238571}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.37510648193359375, \"sum\": 0.37510648193359375, \"min\": 0.37510648193359375}}, \"EndTime\": 1605209830.238649, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1605209830.238633}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.36217289428710936, \"sum\": 0.36217289428710936, \"min\": 0.36217289428710936}}, \"EndTime\": 1605209830.238707, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1605209830.238691}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.35869930419921875, \"sum\": 0.35869930419921875, \"min\": 0.35869930419921875}}, \"EndTime\": 1605209830.238775, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1605209830.238759}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.38019781494140625, \"sum\": 0.38019781494140625, \"min\": 0.38019781494140625}}, \"EndTime\": 1605209830.238834, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1605209830.238818}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.3899168273925781, \"sum\": 0.3899168273925781, \"min\": 0.3899168273925781}}, \"EndTime\": 1605209830.238888, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1605209830.238873}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.393738330078125, \"sum\": 0.393738330078125, \"min\": 0.393738330078125}}, \"EndTime\": 1605209830.238943, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1605209830.238927}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.3867560302734375, \"sum\": 0.3867560302734375, \"min\": 0.3867560302734375}}, \"EndTime\": 1605209830.239001, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1605209830.238985}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.38703768310546877, \"sum\": 0.38703768310546877, \"min\": 0.38703768310546877}}, \"EndTime\": 1605209830.239057, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1605209830.239041}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.37326619873046873, \"sum\": 0.37326619873046873, \"min\": 0.37326619873046873}}, \"EndTime\": 1605209830.239113, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1605209830.239096}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.36568547973632815, \"sum\": 0.36568547973632815, \"min\": 0.36568547973632815}}, \"EndTime\": 1605209830.239172, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1605209830.239155}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.37020848999023437, \"sum\": 0.37020848999023437, \"min\": 0.37020848999023437}}, \"EndTime\": 1605209830.23923, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1605209830.239213}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.37286064453125, \"sum\": 0.37286064453125, \"min\": 0.37286064453125}}, \"EndTime\": 1605209830.239287, \"Dimensions\": {\"model\": 15, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1605209830.239271}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.537071142578125, \"sum\": 0.537071142578125, \"min\": 0.537071142578125}}, \"EndTime\": 1605209830.239343, \"Dimensions\": {\"model\": 16, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1605209830.239327}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5439113403320313, \"sum\": 0.5439113403320313, \"min\": 0.5439113403320313}}, \"EndTime\": 1605209830.239395, \"Dimensions\": {\"model\": 17, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1605209830.239382}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5443159545898437, \"sum\": 0.5443159545898437, \"min\": 0.5443159545898437}}, \"EndTime\": 1605209830.239447, \"Dimensions\": {\"model\": 18, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1605209830.239433}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5479869873046875, \"sum\": 0.5479869873046875, \"min\": 0.5479869873046875}}, \"EndTime\": 1605209830.2395, \"Dimensions\": {\"model\": 19, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1605209830.239485}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7610763916015625, \"sum\": 0.7610763916015625, \"min\": 0.7610763916015625}}, \"EndTime\": 1605209830.239556, \"Dimensions\": {\"model\": 20, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1605209830.23954}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7871767944335938, \"sum\": 0.7871767944335938, \"min\": 0.7871767944335938}}, \"EndTime\": 1605209830.239609, \"Dimensions\": {\"model\": 21, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1605209830.239594}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7656880981445312, \"sum\": 0.7656880981445312, \"min\": 0.7656880981445312}}, \"EndTime\": 1605209830.239659, \"Dimensions\": {\"model\": 22, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1605209830.239645}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7798243286132812, \"sum\": 0.7798243286132812, \"min\": 0.7798243286132812}}, \"EndTime\": 1605209830.239712, \"Dimensions\": {\"model\": 23, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1605209830.239697}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7158761840820312, \"sum\": 0.7158761840820312, \"min\": 0.7158761840820312}}, \"EndTime\": 1605209830.239764, \"Dimensions\": {\"model\": 24, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1605209830.23975}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7120138427734375, \"sum\": 0.7120138427734375, \"min\": 0.7120138427734375}}, \"EndTime\": 1605209830.239814, \"Dimensions\": {\"model\": 25, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1605209830.2398}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7090928100585937, \"sum\": 0.7090928100585937, \"min\": 0.7090928100585937}}, \"EndTime\": 1605209830.239862, \"Dimensions\": {\"model\": 26, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1605209830.239849}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7121598999023437, \"sum\": 0.7121598999023437, \"min\": 0.7121598999023437}}, \"EndTime\": 1605209830.23991, \"Dimensions\": {\"model\": 27, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1605209830.239897}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.791481298828125, \"sum\": 0.791481298828125, \"min\": 0.791481298828125}}, \"EndTime\": 1605209830.239986, \"Dimensions\": {\"model\": 28, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1605209830.239968}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7996080932617188, \"sum\": 0.7996080932617188, \"min\": 0.7996080932617188}}, \"EndTime\": 1605209830.240046, \"Dimensions\": {\"model\": 29, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1605209830.24003}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.78550400390625, \"sum\": 0.78550400390625, \"min\": 0.78550400390625}}, \"EndTime\": 1605209830.240101, \"Dimensions\": {\"model\": 30, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1605209830.240087}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7969048583984375, \"sum\": 0.7969048583984375, \"min\": 0.7969048583984375}}, \"EndTime\": 1605209830.240151, \"Dimensions\": {\"model\": 31, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1605209830.240138}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:10 INFO 139838722238272] #quality_metric: host=algo-1, epoch=3, train binary_classification_cross_entropy_objective <loss>=0.404212084961\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:10 INFO 139838722238272] #early_stopping_criteria_metric: host=algo-1, epoch=3, criteria=binary_classification_cross_entropy_objective, value=0.358699304199\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:10 INFO 139838722238272] Epoch 3: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:10 INFO 139838722238272] Saving model for epoch: 3\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:10 INFO 139838722238272] Saved checkpoint to \"/tmp/tmpCguj85/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:10 INFO 139838722238272] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 5468, \"sum\": 5468.0, \"min\": 5468}, \"Total Batches Seen\": {\"count\": 1, \"max\": 31, \"sum\": 31.0, \"min\": 31}, \"Total Records Seen\": {\"count\": 1, \"max\": 28340, \"sum\": 28340.0, \"min\": 28340}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 5468, \"sum\": 5468.0, \"min\": 5468}, \"Reset Count\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}}, \"EndTime\": 1605209830.251012, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 3}, \"StartTime\": 1605209829.888065}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:10 INFO 139838722238272] #throughput_metric: host=algo-1, train throughput=15060.3770812 records/second\u001b[0m\n",
      "\u001b[34m[2020-11-12 19:37:10.611] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 12, \"duration\": 359, \"num_examples\": 6, \"num_bytes\": 65965952}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.35042301025390626, \"sum\": 0.35042301025390626, \"min\": 0.35042301025390626}}, \"EndTime\": 1605209830.611197, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1605209830.611091}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.34291854248046877, \"sum\": 0.34291854248046877, \"min\": 0.34291854248046877}}, \"EndTime\": 1605209830.611297, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1605209830.611277}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.3474133605957031, \"sum\": 0.3474133605957031, \"min\": 0.3474133605957031}}, \"EndTime\": 1605209830.611361, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1605209830.611344}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.3416178649902344, \"sum\": 0.3416178649902344, \"min\": 0.3416178649902344}}, \"EndTime\": 1605209830.611416, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1605209830.611401}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.28320545654296875, \"sum\": 0.28320545654296875, \"min\": 0.28320545654296875}}, \"EndTime\": 1605209830.611469, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1605209830.611454}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.29139884643554687, \"sum\": 0.29139884643554687, \"min\": 0.29139884643554687}}, \"EndTime\": 1605209830.611531, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1605209830.611514}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.28538096313476563, \"sum\": 0.28538096313476563, \"min\": 0.28538096313476563}}, \"EndTime\": 1605209830.611593, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1605209830.611574}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.2870380126953125, \"sum\": 0.2870380126953125, \"min\": 0.2870380126953125}}, \"EndTime\": 1605209830.611723, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1605209830.611703}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.3411721984863281, \"sum\": 0.3411721984863281, \"min\": 0.3411721984863281}}, \"EndTime\": 1605209830.611786, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1605209830.611767}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.3437339904785156, \"sum\": 0.3437339904785156, \"min\": 0.3437339904785156}}, \"EndTime\": 1605209830.611847, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1605209830.611829}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.33828406372070313, \"sum\": 0.33828406372070313, \"min\": 0.33828406372070313}}, \"EndTime\": 1605209830.611907, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1605209830.61189}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.33696841430664065, \"sum\": 0.33696841430664065, \"min\": 0.33696841430664065}}, \"EndTime\": 1605209830.611965, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1605209830.61195}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.30019044189453126, \"sum\": 0.30019044189453126, \"min\": 0.30019044189453126}}, \"EndTime\": 1605209830.612075, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1605209830.612053}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.32383953247070313, \"sum\": 0.32383953247070313, \"min\": 0.32383953247070313}}, \"EndTime\": 1605209830.612143, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1605209830.612125}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.32082005004882813, \"sum\": 0.32082005004882813, \"min\": 0.32082005004882813}}, \"EndTime\": 1605209830.612204, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1605209830.612186}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.31164105834960937, \"sum\": 0.31164105834960937, \"min\": 0.31164105834960937}}, \"EndTime\": 1605209830.612266, \"Dimensions\": {\"model\": 15, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1605209830.612249}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5276192749023437, \"sum\": 0.5276192749023437, \"min\": 0.5276192749023437}}, \"EndTime\": 1605209830.612322, \"Dimensions\": {\"model\": 16, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1605209830.612307}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5306105224609375, \"sum\": 0.5306105224609375, \"min\": 0.5306105224609375}}, \"EndTime\": 1605209830.612374, \"Dimensions\": {\"model\": 17, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1605209830.61236}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5303027099609375, \"sum\": 0.5303027099609375, \"min\": 0.5303027099609375}}, \"EndTime\": 1605209830.612422, \"Dimensions\": {\"model\": 18, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1605209830.612409}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5342553955078125, \"sum\": 0.5342553955078125, \"min\": 0.5342553955078125}}, \"EndTime\": 1605209830.612474, \"Dimensions\": {\"model\": 19, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1605209830.612459}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.79730439453125, \"sum\": 0.79730439453125, \"min\": 0.79730439453125}}, \"EndTime\": 1605209830.612533, \"Dimensions\": {\"model\": 20, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1605209830.612516}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.8039773071289062, \"sum\": 0.8039773071289062, \"min\": 0.8039773071289062}}, \"EndTime\": 1605209830.612596, \"Dimensions\": {\"model\": 21, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1605209830.61258}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.8196975341796875, \"sum\": 0.8196975341796875, \"min\": 0.8196975341796875}}, \"EndTime\": 1605209830.61266, \"Dimensions\": {\"model\": 22, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1605209830.612642}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.8003819091796875, \"sum\": 0.8003819091796875, \"min\": 0.8003819091796875}}, \"EndTime\": 1605209830.612729, \"Dimensions\": {\"model\": 23, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1605209830.612711}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7171794677734376, \"sum\": 0.7171794677734376, \"min\": 0.7171794677734376}}, \"EndTime\": 1605209830.612791, \"Dimensions\": {\"model\": 24, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1605209830.612773}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.71208369140625, \"sum\": 0.71208369140625, \"min\": 0.71208369140625}}, \"EndTime\": 1605209830.612855, \"Dimensions\": {\"model\": 25, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1605209830.612837}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7101562744140625, \"sum\": 0.7101562744140625, \"min\": 0.7101562744140625}}, \"EndTime\": 1605209830.612939, \"Dimensions\": {\"model\": 26, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1605209830.612899}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7113710083007813, \"sum\": 0.7113710083007813, \"min\": 0.7113710083007813}}, \"EndTime\": 1605209830.613008, \"Dimensions\": {\"model\": 27, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1605209830.61299}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7524357177734375, \"sum\": 0.7524357177734375, \"min\": 0.7524357177734375}}, \"EndTime\": 1605209830.613065, \"Dimensions\": {\"model\": 28, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1605209830.61305}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.747773486328125, \"sum\": 0.747773486328125, \"min\": 0.747773486328125}}, \"EndTime\": 1605209830.613118, \"Dimensions\": {\"model\": 29, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1605209830.613104}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.766224072265625, \"sum\": 0.766224072265625, \"min\": 0.766224072265625}}, \"EndTime\": 1605209830.613179, \"Dimensions\": {\"model\": 30, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1605209830.613161}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7543485717773437, \"sum\": 0.7543485717773437, \"min\": 0.7543485717773437}}, \"EndTime\": 1605209830.613238, \"Dimensions\": {\"model\": 31, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1605209830.613224}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:10 INFO 139838722238272] #quality_metric: host=algo-1, epoch=4, train binary_classification_cross_entropy_objective <loss>=0.350423010254\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:10 INFO 139838722238272] #early_stopping_criteria_metric: host=algo-1, epoch=4, criteria=binary_classification_cross_entropy_objective, value=0.283205456543\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:10 INFO 139838722238272] Epoch 4: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:10 INFO 139838722238272] Saving model for epoch: 4\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:10 INFO 139838722238272] Saved checkpoint to \"/tmp/tmp_IsKcy/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:10 INFO 139838722238272] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 5468, \"sum\": 5468.0, \"min\": 5468}, \"Total Batches Seen\": {\"count\": 1, \"max\": 37, \"sum\": 37.0, \"min\": 37}, \"Total Records Seen\": {\"count\": 1, \"max\": 33808, \"sum\": 33808.0, \"min\": 33808}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 5468, \"sum\": 5468.0, \"min\": 5468}, \"Reset Count\": {\"count\": 1, \"max\": 7, \"sum\": 7.0, \"min\": 7}}, \"EndTime\": 1605209830.664578, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 4}, \"StartTime\": 1605209830.251303}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:10 INFO 139838722238272] #throughput_metric: host=algo-1, train throughput=13226.3212489 records/second\u001b[0m\n",
      "\u001b[34m[2020-11-12 19:37:11.020] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 14, \"duration\": 355, \"num_examples\": 6, \"num_bytes\": 65965952}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.3156379211425781, \"sum\": 0.3156379211425781, \"min\": 0.3156379211425781}}, \"EndTime\": 1605209831.02126, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1605209831.021117}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.30879083862304685, \"sum\": 0.30879083862304685, \"min\": 0.30879083862304685}}, \"EndTime\": 1605209831.021604, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1605209831.021567}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.313141552734375, \"sum\": 0.313141552734375, \"min\": 0.313141552734375}}, \"EndTime\": 1605209831.021886, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1605209831.021862}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.30885939331054685, \"sum\": 0.30885939331054685, \"min\": 0.30885939331054685}}, \"EndTime\": 1605209831.022162, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1605209831.022138}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.22963155212402345, \"sum\": 0.22963155212402345, \"min\": 0.22963155212402345}}, \"EndTime\": 1605209831.022453, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1605209831.022426}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.23335248107910156, \"sum\": 0.23335248107910156, \"min\": 0.23335248107910156}}, \"EndTime\": 1605209831.022795, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1605209831.022768}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.2275195556640625, \"sum\": 0.2275195556640625, \"min\": 0.2275195556640625}}, \"EndTime\": 1605209831.023083, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1605209831.023058}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.23180913696289063, \"sum\": 0.23180913696289063, \"min\": 0.23180913696289063}}, \"EndTime\": 1605209831.023361, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1605209831.023337}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.31028033447265624, \"sum\": 0.31028033447265624, \"min\": 0.31028033447265624}}, \"EndTime\": 1605209831.023635, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1605209831.023611}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.31157632446289063, \"sum\": 0.31157632446289063, \"min\": 0.31157632446289063}}, \"EndTime\": 1605209831.023903, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1605209831.023865}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.3075802978515625, \"sum\": 0.3075802978515625, \"min\": 0.3075802978515625}}, \"EndTime\": 1605209831.024172, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1605209831.024134}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.30565475463867187, \"sum\": 0.30565475463867187, \"min\": 0.30565475463867187}}, \"EndTime\": 1605209831.024441, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1605209831.024403}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.3090323669433594, \"sum\": 0.3090323669433594, \"min\": 0.3090323669433594}}, \"EndTime\": 1605209831.024708, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1605209831.024658}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.31053663330078124, \"sum\": 0.31053663330078124, \"min\": 0.31053663330078124}}, \"EndTime\": 1605209831.024983, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1605209831.024925}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.30429755859375, \"sum\": 0.30429755859375, \"min\": 0.30429755859375}}, \"EndTime\": 1605209831.025257, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1605209831.025233}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.3019670654296875, \"sum\": 0.3019670654296875, \"min\": 0.3019670654296875}}, \"EndTime\": 1605209831.025529, \"Dimensions\": {\"model\": 15, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1605209831.025504}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.520921728515625, \"sum\": 0.520921728515625, \"min\": 0.520921728515625}}, \"EndTime\": 1605209831.025798, \"Dimensions\": {\"model\": 16, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1605209831.025774}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5211694702148437, \"sum\": 0.5211694702148437, \"min\": 0.5211694702148437}}, \"EndTime\": 1605209831.026067, \"Dimensions\": {\"model\": 17, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1605209831.026044}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.518980908203125, \"sum\": 0.518980908203125, \"min\": 0.518980908203125}}, \"EndTime\": 1605209831.026338, \"Dimensions\": {\"model\": 18, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1605209831.026314}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5221970092773438, \"sum\": 0.5221970092773438, \"min\": 0.5221970092773438}}, \"EndTime\": 1605209831.026602, \"Dimensions\": {\"model\": 19, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1605209831.026554}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.693189013671875, \"sum\": 0.693189013671875, \"min\": 0.693189013671875}}, \"EndTime\": 1605209831.026869, \"Dimensions\": {\"model\": 20, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1605209831.026845}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7047709228515625, \"sum\": 0.7047709228515625, \"min\": 0.7047709228515625}}, \"EndTime\": 1605209831.027137, \"Dimensions\": {\"model\": 21, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1605209831.027114}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7075817993164063, \"sum\": 0.7075817993164063, \"min\": 0.7075817993164063}}, \"EndTime\": 1605209831.027306, \"Dimensions\": {\"model\": 22, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1605209831.027281}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6979038208007813, \"sum\": 0.6979038208007813, \"min\": 0.6979038208007813}}, \"EndTime\": 1605209831.02741, \"Dimensions\": {\"model\": 23, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1605209831.027387}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7049037353515625, \"sum\": 0.7049037353515625, \"min\": 0.7049037353515625}}, \"EndTime\": 1605209831.027481, \"Dimensions\": {\"model\": 24, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1605209831.027463}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7017830932617187, \"sum\": 0.7017830932617187, \"min\": 0.7017830932617187}}, \"EndTime\": 1605209831.027587, \"Dimensions\": {\"model\": 25, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1605209831.027564}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7009375610351563, \"sum\": 0.7009375610351563, \"min\": 0.7009375610351563}}, \"EndTime\": 1605209831.027652, \"Dimensions\": {\"model\": 26, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1605209831.027638}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6996874267578125, \"sum\": 0.6996874267578125, \"min\": 0.6996874267578125}}, \"EndTime\": 1605209831.027739, \"Dimensions\": {\"model\": 27, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1605209831.027693}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7361997680664063, \"sum\": 0.7361997680664063, \"min\": 0.7361997680664063}}, \"EndTime\": 1605209831.027806, \"Dimensions\": {\"model\": 28, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1605209831.027788}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7348301025390624, \"sum\": 0.7348301025390624, \"min\": 0.7348301025390624}}, \"EndTime\": 1605209831.027869, \"Dimensions\": {\"model\": 29, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1605209831.027853}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.723747265625, \"sum\": 0.723747265625, \"min\": 0.723747265625}}, \"EndTime\": 1605209831.027928, \"Dimensions\": {\"model\": 30, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1605209831.027911}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7373166015625, \"sum\": 0.7373166015625, \"min\": 0.7373166015625}}, \"EndTime\": 1605209831.027989, \"Dimensions\": {\"model\": 31, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1605209831.027972}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:11 INFO 139838722238272] #quality_metric: host=algo-1, epoch=5, train binary_classification_cross_entropy_objective <loss>=0.315637921143\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:11 INFO 139838722238272] #early_stopping_criteria_metric: host=algo-1, epoch=5, criteria=binary_classification_cross_entropy_objective, value=0.227519555664\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:11 INFO 139838722238272] Epoch 5: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:11 INFO 139838722238272] Saving model for epoch: 5\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:11 INFO 139838722238272] Saved checkpoint to \"/tmp/tmpp24XYd/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:11 INFO 139838722238272] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 5468, \"sum\": 5468.0, \"min\": 5468}, \"Total Batches Seen\": {\"count\": 1, \"max\": 43, \"sum\": 43.0, \"min\": 43}, \"Total Records Seen\": {\"count\": 1, \"max\": 39276, \"sum\": 39276.0, \"min\": 39276}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 5468, \"sum\": 5468.0, \"min\": 5468}, \"Reset Count\": {\"count\": 1, \"max\": 8, \"sum\": 8.0, \"min\": 8}}, \"EndTime\": 1605209831.036948, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 5}, \"StartTime\": 1605209830.66487}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:11 INFO 139838722238272] #throughput_metric: host=algo-1, train throughput=14691.101133 records/second\u001b[0m\n",
      "\u001b[34m[2020-11-12 19:37:11.338] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 16, \"duration\": 300, \"num_examples\": 6, \"num_bytes\": 65965952}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.2908844299316406, \"sum\": 0.2908844299316406, \"min\": 0.2908844299316406}}, \"EndTime\": 1605209831.338273, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1605209831.338178}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.2849973571777344, \"sum\": 0.2849973571777344, \"min\": 0.2849973571777344}}, \"EndTime\": 1605209831.338364, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1605209831.338349}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.28930472412109376, \"sum\": 0.28930472412109376, \"min\": 0.28930472412109376}}, \"EndTime\": 1605209831.338414, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1605209831.338401}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.28557333374023436, \"sum\": 0.28557333374023436, \"min\": 0.28557333374023436}}, \"EndTime\": 1605209831.338458, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1605209831.338447}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.19023935546875, \"sum\": 0.19023935546875, \"min\": 0.19023935546875}}, \"EndTime\": 1605209831.338498, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1605209831.338488}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.1948936004638672, \"sum\": 0.1948936004638672, \"min\": 0.1948936004638672}}, \"EndTime\": 1605209831.338537, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1605209831.338527}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.19327149353027342, \"sum\": 0.19327149353027342, \"min\": 0.19327149353027342}}, \"EndTime\": 1605209831.338576, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1605209831.338566}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.19222026062011718, \"sum\": 0.19222026062011718, \"min\": 0.19222026062011718}}, \"EndTime\": 1605209831.338616, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1605209831.338606}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.2886296630859375, \"sum\": 0.2886296630859375, \"min\": 0.2886296630859375}}, \"EndTime\": 1605209831.338655, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1605209831.338645}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.2891609130859375, \"sum\": 0.2891609130859375, \"min\": 0.2891609130859375}}, \"EndTime\": 1605209831.338694, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1605209831.338684}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.2863726745605469, \"sum\": 0.2863726745605469, \"min\": 0.2863726745605469}}, \"EndTime\": 1605209831.338732, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1605209831.338722}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.28410743408203126, \"sum\": 0.28410743408203126, \"min\": 0.28410743408203126}}, \"EndTime\": 1605209831.338771, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1605209831.338761}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.3292408142089844, \"sum\": 0.3292408142089844, \"min\": 0.3292408142089844}}, \"EndTime\": 1605209831.33881, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1605209831.3388}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.31944539184570314, \"sum\": 0.31944539184570314, \"min\": 0.31944539184570314}}, \"EndTime\": 1605209831.338849, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1605209831.338839}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.3246658813476562, \"sum\": 0.3246658813476562, \"min\": 0.3246658813476562}}, \"EndTime\": 1605209831.338888, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1605209831.338878}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.3169751403808594, \"sum\": 0.3169751403808594, \"min\": 0.3169751403808594}}, \"EndTime\": 1605209831.338926, \"Dimensions\": {\"model\": 15, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1605209831.338916}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5208756103515625, \"sum\": 0.5208756103515625, \"min\": 0.5208756103515625}}, \"EndTime\": 1605209831.338975, \"Dimensions\": {\"model\": 16, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1605209831.338954}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5202361450195313, \"sum\": 0.5202361450195313, \"min\": 0.5202361450195313}}, \"EndTime\": 1605209831.339012, \"Dimensions\": {\"model\": 17, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1605209831.339002}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5174274841308594, \"sum\": 0.5174274841308594, \"min\": 0.5174274841308594}}, \"EndTime\": 1605209831.339049, \"Dimensions\": {\"model\": 18, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1605209831.339039}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5194260498046875, \"sum\": 0.5194260498046875, \"min\": 0.5194260498046875}}, \"EndTime\": 1605209831.339086, \"Dimensions\": {\"model\": 19, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1605209831.339077}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.752157666015625, \"sum\": 0.752157666015625, \"min\": 0.752157666015625}}, \"EndTime\": 1605209831.339124, \"Dimensions\": {\"model\": 20, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1605209831.339114}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.758159375, \"sum\": 0.758159375, \"min\": 0.758159375}}, \"EndTime\": 1605209831.339165, \"Dimensions\": {\"model\": 21, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1605209831.339155}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.751152001953125, \"sum\": 0.751152001953125, \"min\": 0.751152001953125}}, \"EndTime\": 1605209831.339204, \"Dimensions\": {\"model\": 22, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1605209831.339194}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7443169189453125, \"sum\": 0.7443169189453125, \"min\": 0.7443169189453125}}, \"EndTime\": 1605209831.339242, \"Dimensions\": {\"model\": 23, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1605209831.339232}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.693611279296875, \"sum\": 0.693611279296875, \"min\": 0.693611279296875}}, \"EndTime\": 1605209831.339279, \"Dimensions\": {\"model\": 24, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1605209831.339269}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6925887451171875, \"sum\": 0.6925887451171875, \"min\": 0.6925887451171875}}, \"EndTime\": 1605209831.339316, \"Dimensions\": {\"model\": 25, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1605209831.339306}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6941748046875, \"sum\": 0.6941748046875, \"min\": 0.6941748046875}}, \"EndTime\": 1605209831.339354, \"Dimensions\": {\"model\": 26, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1605209831.339344}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6912221435546875, \"sum\": 0.6912221435546875, \"min\": 0.6912221435546875}}, \"EndTime\": 1605209831.33939, \"Dimensions\": {\"model\": 27, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1605209831.339381}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7104639892578125, \"sum\": 0.7104639892578125, \"min\": 0.7104639892578125}}, \"EndTime\": 1605209831.339428, \"Dimensions\": {\"model\": 28, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1605209831.339418}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7132873779296875, \"sum\": 0.7132873779296875, \"min\": 0.7132873779296875}}, \"EndTime\": 1605209831.339465, \"Dimensions\": {\"model\": 29, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1605209831.339455}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7210151123046875, \"sum\": 0.7210151123046875, \"min\": 0.7210151123046875}}, \"EndTime\": 1605209831.339508, \"Dimensions\": {\"model\": 30, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1605209831.339495}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7135728637695312, \"sum\": 0.7135728637695312, \"min\": 0.7135728637695312}}, \"EndTime\": 1605209831.33954, \"Dimensions\": {\"model\": 31, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1605209831.339532}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:11 INFO 139838722238272] #quality_metric: host=algo-1, epoch=6, train binary_classification_cross_entropy_objective <loss>=0.290884429932\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:11 INFO 139838722238272] #early_stopping_criteria_metric: host=algo-1, epoch=6, criteria=binary_classification_cross_entropy_objective, value=0.190239355469\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:11 INFO 139838722238272] Epoch 6: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:11 INFO 139838722238272] Saving model for epoch: 6\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:11 INFO 139838722238272] Saved checkpoint to \"/tmp/tmpAHamXj/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:11 INFO 139838722238272] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 5468, \"sum\": 5468.0, \"min\": 5468}, \"Total Batches Seen\": {\"count\": 1, \"max\": 49, \"sum\": 49.0, \"min\": 49}, \"Total Records Seen\": {\"count\": 1, \"max\": 44744, \"sum\": 44744.0, \"min\": 44744}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 5468, \"sum\": 5468.0, \"min\": 5468}, \"Reset Count\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}}, \"EndTime\": 1605209831.348167, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 6}, \"StartTime\": 1605209831.037198}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:11 INFO 139838722238272] #throughput_metric: host=algo-1, train throughput=17578.2680928 records/second\u001b[0m\n",
      "\u001b[34m[2020-11-12 19:37:11.619] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 18, \"duration\": 270, \"num_examples\": 6, \"num_bytes\": 65965952}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.272154931640625, \"sum\": 0.272154931640625, \"min\": 0.272154931640625}}, \"EndTime\": 1605209831.619499, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1605209831.619396}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.26728271484375, \"sum\": 0.26728271484375, \"min\": 0.26728271484375}}, \"EndTime\": 1605209831.619589, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1605209831.619568}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.271541943359375, \"sum\": 0.271541943359375, \"min\": 0.271541943359375}}, \"EndTime\": 1605209831.61966, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1605209831.61964}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.26793087768554685, \"sum\": 0.26793087768554685, \"min\": 0.26793087768554685}}, \"EndTime\": 1605209831.619725, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1605209831.619706}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.1654258544921875, \"sum\": 0.1654258544921875, \"min\": 0.1654258544921875}}, \"EndTime\": 1605209831.619794, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1605209831.619774}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.1705066192626953, \"sum\": 0.1705066192626953, \"min\": 0.1705066192626953}}, \"EndTime\": 1605209831.619858, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1605209831.61984}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.16731026306152344, \"sum\": 0.16731026306152344, \"min\": 0.16731026306152344}}, \"EndTime\": 1605209831.619921, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1605209831.619904}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.1693408935546875, \"sum\": 0.1693408935546875, \"min\": 0.1693408935546875}}, \"EndTime\": 1605209831.619985, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1605209831.619968}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.272616357421875, \"sum\": 0.272616357421875, \"min\": 0.272616357421875}}, \"EndTime\": 1605209831.620046, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1605209831.620028}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.27252355346679685, \"sum\": 0.27252355346679685, \"min\": 0.27252355346679685}}, \"EndTime\": 1605209831.620119, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1605209831.620093}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.27088333129882813, \"sum\": 0.27088333129882813, \"min\": 0.27088333129882813}}, \"EndTime\": 1605209831.620188, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1605209831.62017}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.2684409118652344, \"sum\": 0.2684409118652344, \"min\": 0.2684409118652344}}, \"EndTime\": 1605209831.620242, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1605209831.620226}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.3463923095703125, \"sum\": 0.3463923095703125, \"min\": 0.3463923095703125}}, \"EndTime\": 1605209831.620292, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1605209831.620276}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.33798157958984376, \"sum\": 0.33798157958984376, \"min\": 0.33798157958984376}}, \"EndTime\": 1605209831.620356, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1605209831.620339}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.34514274291992186, \"sum\": 0.34514274291992186, \"min\": 0.34514274291992186}}, \"EndTime\": 1605209831.62041, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1605209831.620394}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.3546073486328125, \"sum\": 0.3546073486328125, \"min\": 0.3546073486328125}}, \"EndTime\": 1605209831.620464, \"Dimensions\": {\"model\": 15, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1605209831.620448}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5261611450195313, \"sum\": 0.5261611450195313, \"min\": 0.5261611450195313}}, \"EndTime\": 1605209831.620517, \"Dimensions\": {\"model\": 16, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1605209831.620502}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.52535810546875, \"sum\": 0.52535810546875, \"min\": 0.52535810546875}}, \"EndTime\": 1605209831.62058, \"Dimensions\": {\"model\": 17, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1605209831.620563}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5239645874023438, \"sum\": 0.5239645874023438, \"min\": 0.5239645874023438}}, \"EndTime\": 1605209831.62064, \"Dimensions\": {\"model\": 18, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1605209831.620623}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5243205932617188, \"sum\": 0.5243205932617188, \"min\": 0.5243205932617188}}, \"EndTime\": 1605209831.620693, \"Dimensions\": {\"model\": 19, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1605209831.620678}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.693506103515625, \"sum\": 0.693506103515625, \"min\": 0.693506103515625}}, \"EndTime\": 1605209831.620749, \"Dimensions\": {\"model\": 20, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1605209831.620733}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7017644165039062, \"sum\": 0.7017644165039062, \"min\": 0.7017644165039062}}, \"EndTime\": 1605209831.620807, \"Dimensions\": {\"model\": 21, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1605209831.620791}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7064219482421875, \"sum\": 0.7064219482421875, \"min\": 0.7064219482421875}}, \"EndTime\": 1605209831.620871, \"Dimensions\": {\"model\": 22, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1605209831.620853}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6934760009765625, \"sum\": 0.6934760009765625, \"min\": 0.6934760009765625}}, \"EndTime\": 1605209831.620958, \"Dimensions\": {\"model\": 23, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1605209831.620939}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.689533984375, \"sum\": 0.689533984375, \"min\": 0.689533984375}}, \"EndTime\": 1605209831.621024, \"Dimensions\": {\"model\": 24, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1605209831.621006}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6885580444335937, \"sum\": 0.6885580444335937, \"min\": 0.6885580444335937}}, \"EndTime\": 1605209831.621082, \"Dimensions\": {\"model\": 25, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1605209831.621066}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6919657470703126, \"sum\": 0.6919657470703126, \"min\": 0.6919657470703126}}, \"EndTime\": 1605209831.62114, \"Dimensions\": {\"model\": 26, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1605209831.621122}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6912312133789063, \"sum\": 0.6912312133789063, \"min\": 0.6912312133789063}}, \"EndTime\": 1605209831.621199, \"Dimensions\": {\"model\": 27, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1605209831.621182}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7098094604492188, \"sum\": 0.7098094604492188, \"min\": 0.7098094604492188}}, \"EndTime\": 1605209831.621252, \"Dimensions\": {\"model\": 28, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1605209831.621235}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.703865087890625, \"sum\": 0.703865087890625, \"min\": 0.703865087890625}}, \"EndTime\": 1605209831.621313, \"Dimensions\": {\"model\": 29, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1605209831.621296}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7015802001953125, \"sum\": 0.7015802001953125, \"min\": 0.7015802001953125}}, \"EndTime\": 1605209831.62137, \"Dimensions\": {\"model\": 30, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1605209831.621354}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7081724853515625, \"sum\": 0.7081724853515625, \"min\": 0.7081724853515625}}, \"EndTime\": 1605209831.621426, \"Dimensions\": {\"model\": 31, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1605209831.62141}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:11 INFO 139838722238272] #quality_metric: host=algo-1, epoch=7, train binary_classification_cross_entropy_objective <loss>=0.272154931641\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:11 INFO 139838722238272] #early_stopping_criteria_metric: host=algo-1, epoch=7, criteria=binary_classification_cross_entropy_objective, value=0.165425854492\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:11 INFO 139838722238272] Epoch 7: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:11 INFO 139838722238272] Saving model for epoch: 7\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:11 INFO 139838722238272] Saved checkpoint to \"/tmp/tmpeVbwjq/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:11 INFO 139838722238272] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 5468, \"sum\": 5468.0, \"min\": 5468}, \"Total Batches Seen\": {\"count\": 1, \"max\": 55, \"sum\": 55.0, \"min\": 55}, \"Total Records Seen\": {\"count\": 1, \"max\": 50212, \"sum\": 50212.0, \"min\": 50212}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 5468, \"sum\": 5468.0, \"min\": 5468}, \"Reset Count\": {\"count\": 1, \"max\": 10, \"sum\": 10.0, \"min\": 10}}, \"EndTime\": 1605209831.629609, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 7}, \"StartTime\": 1605209831.348407}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:11 INFO 139838722238272] #throughput_metric: host=algo-1, train throughput=19437.4112939 records/second\u001b[0m\n",
      "\u001b[34m[2020-11-12 19:37:11.903] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 20, \"duration\": 273, \"num_examples\": 6, \"num_bytes\": 65965952}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.25758287353515624, \"sum\": 0.25758287353515624, \"min\": 0.25758287353515624}}, \"EndTime\": 1605209831.90327, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1605209831.903178}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.25353407592773436, \"sum\": 0.25353407592773436, \"min\": 0.25353407592773436}}, \"EndTime\": 1605209831.903366, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1605209831.90335}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.25773749694824216, \"sum\": 0.25773749694824216, \"min\": 0.25773749694824216}}, \"EndTime\": 1605209831.903415, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1605209831.903403}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.25411585388183594, \"sum\": 0.25411585388183594, \"min\": 0.25411585388183594}}, \"EndTime\": 1605209831.903465, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1605209831.903453}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.14924676208496093, \"sum\": 0.14924676208496093, \"min\": 0.14924676208496093}}, \"EndTime\": 1605209831.903514, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1605209831.903502}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.1534688720703125, \"sum\": 0.1534688720703125, \"min\": 0.1534688720703125}}, \"EndTime\": 1605209831.903563, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1605209831.903552}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.1519412139892578, \"sum\": 0.1519412139892578, \"min\": 0.1519412139892578}}, \"EndTime\": 1605209831.903611, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1605209831.9036}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.1524387390136719, \"sum\": 0.1524387390136719, \"min\": 0.1524387390136719}}, \"EndTime\": 1605209831.90366, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1605209831.903648}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.26049759216308593, \"sum\": 0.26049759216308593, \"min\": 0.26049759216308593}}, \"EndTime\": 1605209831.903708, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1605209831.903697}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.2599352630615234, \"sum\": 0.2599352630615234, \"min\": 0.2599352630615234}}, \"EndTime\": 1605209831.903756, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1605209831.903745}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.2592048675537109, \"sum\": 0.2592048675537109, \"min\": 0.2592048675537109}}, \"EndTime\": 1605209831.903804, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1605209831.903792}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.2567378143310547, \"sum\": 0.2567378143310547, \"min\": 0.2567378143310547}}, \"EndTime\": 1605209831.903845, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1605209831.903835}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.33386566162109377, \"sum\": 0.33386566162109377, \"min\": 0.33386566162109377}}, \"EndTime\": 1605209831.903891, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1605209831.90388}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.34115713500976563, \"sum\": 0.34115713500976563, \"min\": 0.34115713500976563}}, \"EndTime\": 1605209831.903935, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1605209831.903924}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.3363068115234375, \"sum\": 0.3363068115234375, \"min\": 0.3363068115234375}}, \"EndTime\": 1605209831.903985, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1605209831.903975}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.33787054443359377, \"sum\": 0.33787054443359377, \"min\": 0.33787054443359377}}, \"EndTime\": 1605209831.904022, \"Dimensions\": {\"model\": 15, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1605209831.904013}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.532157568359375, \"sum\": 0.532157568359375, \"min\": 0.532157568359375}}, \"EndTime\": 1605209831.904061, \"Dimensions\": {\"model\": 16, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1605209831.904051}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5312154418945313, \"sum\": 0.5312154418945313, \"min\": 0.5312154418945313}}, \"EndTime\": 1605209831.904098, \"Dimensions\": {\"model\": 17, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1605209831.904088}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5320505859375, \"sum\": 0.5320505859375, \"min\": 0.5320505859375}}, \"EndTime\": 1605209831.904136, \"Dimensions\": {\"model\": 18, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1605209831.904126}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5312381591796875, \"sum\": 0.5312381591796875, \"min\": 0.5312381591796875}}, \"EndTime\": 1605209831.904174, \"Dimensions\": {\"model\": 19, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1605209831.904164}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.754603173828125, \"sum\": 0.754603173828125, \"min\": 0.754603173828125}}, \"EndTime\": 1605209831.904211, \"Dimensions\": {\"model\": 20, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1605209831.904202}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7367911254882813, \"sum\": 0.7367911254882813, \"min\": 0.7367911254882813}}, \"EndTime\": 1605209831.904249, \"Dimensions\": {\"model\": 21, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1605209831.904239}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.72645244140625, \"sum\": 0.72645244140625, \"min\": 0.72645244140625}}, \"EndTime\": 1605209831.904287, \"Dimensions\": {\"model\": 22, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1605209831.904277}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7229215087890625, \"sum\": 0.7229215087890625, \"min\": 0.7229215087890625}}, \"EndTime\": 1605209831.904326, \"Dimensions\": {\"model\": 23, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1605209831.904316}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6889826293945313, \"sum\": 0.6889826293945313, \"min\": 0.6889826293945313}}, \"EndTime\": 1605209831.904365, \"Dimensions\": {\"model\": 24, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1605209831.904355}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.688514208984375, \"sum\": 0.688514208984375, \"min\": 0.688514208984375}}, \"EndTime\": 1605209831.904402, \"Dimensions\": {\"model\": 25, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1605209831.904393}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.69051591796875, \"sum\": 0.69051591796875, \"min\": 0.69051591796875}}, \"EndTime\": 1605209831.90444, \"Dimensions\": {\"model\": 26, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1605209831.90443}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6915393188476563, \"sum\": 0.6915393188476563, \"min\": 0.6915393188476563}}, \"EndTime\": 1605209831.904477, \"Dimensions\": {\"model\": 27, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1605209831.904467}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6957358642578125, \"sum\": 0.6957358642578125, \"min\": 0.6957358642578125}}, \"EndTime\": 1605209831.904516, \"Dimensions\": {\"model\": 28, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1605209831.904508}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7018529418945313, \"sum\": 0.7018529418945313, \"min\": 0.7018529418945313}}, \"EndTime\": 1605209831.904543, \"Dimensions\": {\"model\": 29, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1605209831.904536}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6996929321289063, \"sum\": 0.6996929321289063, \"min\": 0.6996929321289063}}, \"EndTime\": 1605209831.904569, \"Dimensions\": {\"model\": 30, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1605209831.904562}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.69801708984375, \"sum\": 0.69801708984375, \"min\": 0.69801708984375}}, \"EndTime\": 1605209831.904595, \"Dimensions\": {\"model\": 31, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1605209831.904588}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:11 INFO 139838722238272] #quality_metric: host=algo-1, epoch=8, train binary_classification_cross_entropy_objective <loss>=0.257582873535\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:11 INFO 139838722238272] #early_stopping_criteria_metric: host=algo-1, epoch=8, criteria=binary_classification_cross_entropy_objective, value=0.149246762085\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:11 INFO 139838722238272] Epoch 8: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:11 INFO 139838722238272] Saving model for epoch: 8\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:11 INFO 139838722238272] Saved checkpoint to \"/tmp/tmpxcPjOM/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:11 INFO 139838722238272] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 5468, \"sum\": 5468.0, \"min\": 5468}, \"Total Batches Seen\": {\"count\": 1, \"max\": 61, \"sum\": 61.0, \"min\": 61}, \"Total Records Seen\": {\"count\": 1, \"max\": 55680, \"sum\": 55680.0, \"min\": 55680}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 5468, \"sum\": 5468.0, \"min\": 5468}, \"Reset Count\": {\"count\": 1, \"max\": 11, \"sum\": 11.0, \"min\": 11}}, \"EndTime\": 1605209831.912985, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 8}, \"StartTime\": 1605209831.629883}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:11 INFO 139838722238272] #throughput_metric: host=algo-1, train throughput=19304.2187241 records/second\u001b[0m\n",
      "\u001b[34m[2020-11-12 19:37:12.226] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 22, \"duration\": 311, \"num_examples\": 6, \"num_bytes\": 65965952}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.24608592529296874, \"sum\": 0.24608592529296874, \"min\": 0.24608592529296874}}, \"EndTime\": 1605209832.226914, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1605209832.226814}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.24259778442382812, \"sum\": 0.24259778442382812, \"min\": 0.24259778442382812}}, \"EndTime\": 1605209832.227027, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1605209832.227005}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.24672374267578126, \"sum\": 0.24672374267578126, \"min\": 0.24672374267578126}}, \"EndTime\": 1605209832.227086, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1605209832.227068}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.24301290588378907, \"sum\": 0.24301290588378907, \"min\": 0.24301290588378907}}, \"EndTime\": 1605209832.227154, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1605209832.227136}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.14048894653320312, \"sum\": 0.14048894653320312, \"min\": 0.14048894653320312}}, \"EndTime\": 1605209832.227216, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1605209832.227198}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.1411575469970703, \"sum\": 0.1411575469970703, \"min\": 0.1411575469970703}}, \"EndTime\": 1605209832.227282, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1605209832.227263}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.14008167114257813, \"sum\": 0.14008167114257813, \"min\": 0.14008167114257813}}, \"EndTime\": 1605209832.227343, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1605209832.227325}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.14295144653320313, \"sum\": 0.14295144653320313, \"min\": 0.14295144653320313}}, \"EndTime\": 1605209832.227407, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1605209832.227389}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.2511738494873047, \"sum\": 0.2511738494873047, \"min\": 0.2511738494873047}}, \"EndTime\": 1605209832.227481, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1605209832.227452}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.25043240051269533, \"sum\": 0.25043240051269533, \"min\": 0.25043240051269533}}, \"EndTime\": 1605209832.22754, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1605209832.227524}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.25026311645507815, \"sum\": 0.25026311645507815, \"min\": 0.25026311645507815}}, \"EndTime\": 1605209832.227601, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1605209832.227584}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.24774481201171875, \"sum\": 0.24774481201171875, \"min\": 0.24774481201171875}}, \"EndTime\": 1605209832.227661, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1605209832.227645}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.3070860107421875, \"sum\": 0.3070860107421875, \"min\": 0.3070860107421875}}, \"EndTime\": 1605209832.227721, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1605209832.227704}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.32721932373046875, \"sum\": 0.32721932373046875, \"min\": 0.32721932373046875}}, \"EndTime\": 1605209832.227785, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1605209832.227767}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.31566004638671874, \"sum\": 0.31566004638671874, \"min\": 0.31566004638671874}}, \"EndTime\": 1605209832.227848, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1605209832.227831}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.31284675903320314, \"sum\": 0.31284675903320314, \"min\": 0.31284675903320314}}, \"EndTime\": 1605209832.227909, \"Dimensions\": {\"model\": 15, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1605209832.227892}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5352675903320312, \"sum\": 0.5352675903320312, \"min\": 0.5352675903320312}}, \"EndTime\": 1605209832.227972, \"Dimensions\": {\"model\": 16, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1605209832.227954}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5345576416015625, \"sum\": 0.5345576416015625, \"min\": 0.5345576416015625}}, \"EndTime\": 1605209832.228034, \"Dimensions\": {\"model\": 17, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1605209832.228017}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5364333862304688, \"sum\": 0.5364333862304688, \"min\": 0.5364333862304688}}, \"EndTime\": 1605209832.228093, \"Dimensions\": {\"model\": 18, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1605209832.228077}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5354485717773437, \"sum\": 0.5354485717773437, \"min\": 0.5354485717773437}}, \"EndTime\": 1605209832.228151, \"Dimensions\": {\"model\": 19, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1605209832.228135}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.72392353515625, \"sum\": 0.72392353515625, \"min\": 0.72392353515625}}, \"EndTime\": 1605209832.228211, \"Dimensions\": {\"model\": 20, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1605209832.228194}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7222213256835938, \"sum\": 0.7222213256835938, \"min\": 0.7222213256835938}}, \"EndTime\": 1605209832.228271, \"Dimensions\": {\"model\": 21, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1605209832.228254}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7239964233398437, \"sum\": 0.7239964233398437, \"min\": 0.7239964233398437}}, \"EndTime\": 1605209832.228332, \"Dimensions\": {\"model\": 22, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1605209832.228316}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7151426635742187, \"sum\": 0.7151426635742187, \"min\": 0.7151426635742187}}, \"EndTime\": 1605209832.228399, \"Dimensions\": {\"model\": 23, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1605209832.228381}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6883945068359375, \"sum\": 0.6883945068359375, \"min\": 0.6883945068359375}}, \"EndTime\": 1605209832.228437, \"Dimensions\": {\"model\": 24, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1605209832.228428}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6896868041992188, \"sum\": 0.6896868041992188, \"min\": 0.6896868041992188}}, \"EndTime\": 1605209832.228486, \"Dimensions\": {\"model\": 25, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1605209832.22847}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6884719604492188, \"sum\": 0.6884719604492188, \"min\": 0.6884719604492188}}, \"EndTime\": 1605209832.228544, \"Dimensions\": {\"model\": 26, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1605209832.228528}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6902546630859375, \"sum\": 0.6902546630859375, \"min\": 0.6902546630859375}}, \"EndTime\": 1605209832.228603, \"Dimensions\": {\"model\": 27, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1605209832.228586}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6974447509765626, \"sum\": 0.6974447509765626, \"min\": 0.6974447509765626}}, \"EndTime\": 1605209832.228656, \"Dimensions\": {\"model\": 28, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1605209832.228645}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6929008178710937, \"sum\": 0.6929008178710937, \"min\": 0.6929008178710937}}, \"EndTime\": 1605209832.228689, \"Dimensions\": {\"model\": 29, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1605209832.228681}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6957814086914063, \"sum\": 0.6957814086914063, \"min\": 0.6957814086914063}}, \"EndTime\": 1605209832.228727, \"Dimensions\": {\"model\": 30, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1605209832.228713}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6977203979492187, \"sum\": 0.6977203979492187, \"min\": 0.6977203979492187}}, \"EndTime\": 1605209832.228783, \"Dimensions\": {\"model\": 31, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1605209832.228768}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:12 INFO 139838722238272] #quality_metric: host=algo-1, epoch=9, train binary_classification_cross_entropy_objective <loss>=0.246085925293\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:12 INFO 139838722238272] #early_stopping_criteria_metric: host=algo-1, epoch=9, criteria=binary_classification_cross_entropy_objective, value=0.140081671143\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:12 INFO 139838722238272] Epoch 9: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:12 INFO 139838722238272] Saving model for epoch: 9\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:12 INFO 139838722238272] Saved checkpoint to \"/tmp/tmpE_glyz/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:12 INFO 139838722238272] #progress_metric: host=algo-1, completed 66 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 5468, \"sum\": 5468.0, \"min\": 5468}, \"Total Batches Seen\": {\"count\": 1, \"max\": 67, \"sum\": 67.0, \"min\": 67}, \"Total Records Seen\": {\"count\": 1, \"max\": 61148, \"sum\": 61148.0, \"min\": 61148}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 5468, \"sum\": 5468.0, \"min\": 5468}, \"Reset Count\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}}, \"EndTime\": 1605209832.237046, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 9}, \"StartTime\": 1605209831.914785}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:12 INFO 139838722238272] #throughput_metric: host=algo-1, train throughput=16960.7694922 records/second\u001b[0m\n",
      "\u001b[34m[2020-11-12 19:37:12.519] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 24, \"duration\": 281, \"num_examples\": 6, \"num_bytes\": 65965952}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.23676519165039062, \"sum\": 0.23676519165039062, \"min\": 0.23676519165039062}}, \"EndTime\": 1605209832.51917, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1605209832.519076}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.23369409484863282, \"sum\": 0.23369409484863282, \"min\": 0.23369409484863282}}, \"EndTime\": 1605209832.519255, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1605209832.519241}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.23767786865234375, \"sum\": 0.23767786865234375, \"min\": 0.23767786865234375}}, \"EndTime\": 1605209832.519314, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1605209832.519299}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.2339439208984375, \"sum\": 0.2339439208984375, \"min\": 0.2339439208984375}}, \"EndTime\": 1605209832.519376, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1605209832.51936}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.13217837219238282, \"sum\": 0.13217837219238282, \"min\": 0.13217837219238282}}, \"EndTime\": 1605209832.519439, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1605209832.519422}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.1339054473876953, \"sum\": 0.1339054473876953, \"min\": 0.1339054473876953}}, \"EndTime\": 1605209832.519507, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1605209832.51949}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.13131502532958986, \"sum\": 0.13131502532958986, \"min\": 0.13131502532958986}}, \"EndTime\": 1605209832.51958, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1605209832.519561}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.13190514221191407, \"sum\": 0.13190514221191407, \"min\": 0.13190514221191407}}, \"EndTime\": 1605209832.519652, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1605209832.519634}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.24385369873046875, \"sum\": 0.24385369873046875, \"min\": 0.24385369873046875}}, \"EndTime\": 1605209832.519725, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1605209832.519707}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.24305267028808594, \"sum\": 0.24305267028808594, \"min\": 0.24305267028808594}}, \"EndTime\": 1605209832.519797, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1605209832.519779}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.24321495971679688, \"sum\": 0.24321495971679688, \"min\": 0.24321495971679688}}, \"EndTime\": 1605209832.519869, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1605209832.51985}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.24072083129882813, \"sum\": 0.24072083129882813, \"min\": 0.24072083129882813}}, \"EndTime\": 1605209832.51995, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1605209832.519932}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.2922652954101562, \"sum\": 0.2922652954101562, \"min\": 0.2922652954101562}}, \"EndTime\": 1605209832.520005, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1605209832.51999}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.3015821105957031, \"sum\": 0.3015821105957031, \"min\": 0.3015821105957031}}, \"EndTime\": 1605209832.520062, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1605209832.520047}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.29487741088867186, \"sum\": 0.29487741088867186, \"min\": 0.29487741088867186}}, \"EndTime\": 1605209832.520112, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1605209832.520097}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.30112628173828127, \"sum\": 0.30112628173828127, \"min\": 0.30112628173828127}}, \"EndTime\": 1605209832.520164, \"Dimensions\": {\"model\": 15, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1605209832.52015}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5351960571289063, \"sum\": 0.5351960571289063, \"min\": 0.5351960571289063}}, \"EndTime\": 1605209832.520216, \"Dimensions\": {\"model\": 16, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1605209832.520202}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5351970947265625, \"sum\": 0.5351970947265625, \"min\": 0.5351970947265625}}, \"EndTime\": 1605209832.520276, \"Dimensions\": {\"model\": 17, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1605209832.52026}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5362865478515625, \"sum\": 0.5362865478515625, \"min\": 0.5362865478515625}}, \"EndTime\": 1605209832.520338, \"Dimensions\": {\"model\": 18, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1605209832.52032}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.53592431640625, \"sum\": 0.53592431640625, \"min\": 0.53592431640625}}, \"EndTime\": 1605209832.520395, \"Dimensions\": {\"model\": 19, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1605209832.520379}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7803673461914062, \"sum\": 0.7803673461914062, \"min\": 0.7803673461914062}}, \"EndTime\": 1605209832.520454, \"Dimensions\": {\"model\": 20, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1605209832.520437}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7412257690429688, \"sum\": 0.7412257690429688, \"min\": 0.7412257690429688}}, \"EndTime\": 1605209832.520509, \"Dimensions\": {\"model\": 21, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1605209832.520495}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7356902954101563, \"sum\": 0.7356902954101563, \"min\": 0.7356902954101563}}, \"EndTime\": 1605209832.520563, \"Dimensions\": {\"model\": 22, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1605209832.520549}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7252780517578125, \"sum\": 0.7252780517578125, \"min\": 0.7252780517578125}}, \"EndTime\": 1605209832.520616, \"Dimensions\": {\"model\": 23, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1605209832.520604}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.687806982421875, \"sum\": 0.687806982421875, \"min\": 0.687806982421875}}, \"EndTime\": 1605209832.520672, \"Dimensions\": {\"model\": 24, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1605209832.520655}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6890232299804687, \"sum\": 0.6890232299804687, \"min\": 0.6890232299804687}}, \"EndTime\": 1605209832.520723, \"Dimensions\": {\"model\": 25, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1605209832.520708}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6870490234375, \"sum\": 0.6870490234375, \"min\": 0.6870490234375}}, \"EndTime\": 1605209832.520779, \"Dimensions\": {\"model\": 26, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1605209832.520764}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6879924438476562, \"sum\": 0.6879924438476562, \"min\": 0.6879924438476562}}, \"EndTime\": 1605209832.520826, \"Dimensions\": {\"model\": 27, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1605209832.520811}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6922824096679687, \"sum\": 0.6922824096679687, \"min\": 0.6922824096679687}}, \"EndTime\": 1605209832.520884, \"Dimensions\": {\"model\": 28, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1605209832.520867}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6947143310546875, \"sum\": 0.6947143310546875, \"min\": 0.6947143310546875}}, \"EndTime\": 1605209832.521013, \"Dimensions\": {\"model\": 29, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1605209832.520991}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6926062133789063, \"sum\": 0.6926062133789063, \"min\": 0.6926062133789063}}, \"EndTime\": 1605209832.521076, \"Dimensions\": {\"model\": 30, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1605209832.521059}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6912947631835937, \"sum\": 0.6912947631835937, \"min\": 0.6912947631835937}}, \"EndTime\": 1605209832.521128, \"Dimensions\": {\"model\": 31, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1605209832.521112}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:12 INFO 139838722238272] #quality_metric: host=algo-1, epoch=10, train binary_classification_cross_entropy_objective <loss>=0.23676519165\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:12 INFO 139838722238272] #early_stopping_criteria_metric: host=algo-1, epoch=10, criteria=binary_classification_cross_entropy_objective, value=0.13131502533\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:12 INFO 139838722238272] Epoch 10: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:12 INFO 139838722238272] Saving model for epoch: 10\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:12 INFO 139838722238272] Saved checkpoint to \"/tmp/tmpGJp20V/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:12 INFO 139838722238272] #progress_metric: host=algo-1, completed 73 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 5468, \"sum\": 5468.0, \"min\": 5468}, \"Total Batches Seen\": {\"count\": 1, \"max\": 73, \"sum\": 73.0, \"min\": 73}, \"Total Records Seen\": {\"count\": 1, \"max\": 66616, \"sum\": 66616.0, \"min\": 66616}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 5468, \"sum\": 5468.0, \"min\": 5468}, \"Reset Count\": {\"count\": 1, \"max\": 13, \"sum\": 13.0, \"min\": 13}}, \"EndTime\": 1605209832.529215, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 10}, \"StartTime\": 1605209832.237337}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:12 INFO 139838722238272] #throughput_metric: host=algo-1, train throughput=18725.8403738 records/second\u001b[0m\n",
      "\u001b[34m[2020-11-12 19:37:12.831] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 26, \"duration\": 302, \"num_examples\": 6, \"num_bytes\": 65965952}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.22908795166015625, \"sum\": 0.22908795166015625, \"min\": 0.22908795166015625}}, \"EndTime\": 1605209832.831924, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1605209832.83182}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.2263033905029297, \"sum\": 0.2263033905029297, \"min\": 0.2263033905029297}}, \"EndTime\": 1605209832.832022, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1605209832.832002}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.23016025695800782, \"sum\": 0.23016025695800782, \"min\": 0.23016025695800782}}, \"EndTime\": 1605209832.832082, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1605209832.832064}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.2264054412841797, \"sum\": 0.2264054412841797, \"min\": 0.2264054412841797}}, \"EndTime\": 1605209832.832156, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1605209832.832137}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.12796242218017578, \"sum\": 0.12796242218017578, \"min\": 0.12796242218017578}}, \"EndTime\": 1605209832.832213, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1605209832.832195}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.12701824798583985, \"sum\": 0.12701824798583985, \"min\": 0.12701824798583985}}, \"EndTime\": 1605209832.832269, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1605209832.832252}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.12683582305908203, \"sum\": 0.12683582305908203, \"min\": 0.12683582305908203}}, \"EndTime\": 1605209832.832333, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1605209832.832315}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.12804328155517578, \"sum\": 0.12804328155517578, \"min\": 0.12804328155517578}}, \"EndTime\": 1605209832.832392, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1605209832.832374}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.23803949584960937, \"sum\": 0.23803949584960937, \"min\": 0.23803949584960937}}, \"EndTime\": 1605209832.832446, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1605209832.832429}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.2371665069580078, \"sum\": 0.2371665069580078, \"min\": 0.2371665069580078}}, \"EndTime\": 1605209832.832499, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1605209832.832483}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.23757943725585937, \"sum\": 0.23757943725585937, \"min\": 0.23757943725585937}}, \"EndTime\": 1605209832.832574, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1605209832.832556}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.23512784423828126, \"sum\": 0.23512784423828126, \"min\": 0.23512784423828126}}, \"EndTime\": 1605209832.832636, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1605209832.832619}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.28567323608398437, \"sum\": 0.28567323608398437, \"min\": 0.28567323608398437}}, \"EndTime\": 1605209832.832741, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1605209832.832718}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.28992904052734375, \"sum\": 0.28992904052734375, \"min\": 0.28992904052734375}}, \"EndTime\": 1605209832.832817, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1605209832.832799}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.2893734252929687, \"sum\": 0.2893734252929687, \"min\": 0.2893734252929687}}, \"EndTime\": 1605209832.832877, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1605209832.832861}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.29197426147460936, \"sum\": 0.29197426147460936, \"min\": 0.29197426147460936}}, \"EndTime\": 1605209832.832967, \"Dimensions\": {\"model\": 15, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1605209832.832947}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5336039794921875, \"sum\": 0.5336039794921875, \"min\": 0.5336039794921875}}, \"EndTime\": 1605209832.83303, \"Dimensions\": {\"model\": 16, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1605209832.833013}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.53413115234375, \"sum\": 0.53413115234375, \"min\": 0.53413115234375}}, \"EndTime\": 1605209832.833092, \"Dimensions\": {\"model\": 17, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1605209832.833074}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5339859741210937, \"sum\": 0.5339859741210937, \"min\": 0.5339859741210937}}, \"EndTime\": 1605209832.83315, \"Dimensions\": {\"model\": 18, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1605209832.833133}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5340655151367187, \"sum\": 0.5340655151367187, \"min\": 0.5340655151367187}}, \"EndTime\": 1605209832.833212, \"Dimensions\": {\"model\": 19, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1605209832.833196}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7609555053710938, \"sum\": 0.7609555053710938, \"min\": 0.7609555053710938}}, \"EndTime\": 1605209832.83328, \"Dimensions\": {\"model\": 20, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1605209832.833263}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7461919067382813, \"sum\": 0.7461919067382813, \"min\": 0.7461919067382813}}, \"EndTime\": 1605209832.833347, \"Dimensions\": {\"model\": 21, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1605209832.83333}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7420164428710937, \"sum\": 0.7420164428710937, \"min\": 0.7420164428710937}}, \"EndTime\": 1605209832.833403, \"Dimensions\": {\"model\": 22, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1605209832.83339}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7365000732421875, \"sum\": 0.7365000732421875, \"min\": 0.7365000732421875}}, \"EndTime\": 1605209832.833435, \"Dimensions\": {\"model\": 23, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1605209832.833427}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6876938354492188, \"sum\": 0.6876938354492188, \"min\": 0.6876938354492188}}, \"EndTime\": 1605209832.83349, \"Dimensions\": {\"model\": 24, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1605209832.833473}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6878794311523437, \"sum\": 0.6878794311523437, \"min\": 0.6878794311523437}}, \"EndTime\": 1605209832.833561, \"Dimensions\": {\"model\": 25, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1605209832.833543}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6873802124023437, \"sum\": 0.6873802124023437, \"min\": 0.6873802124023437}}, \"EndTime\": 1605209832.833631, \"Dimensions\": {\"model\": 26, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1605209832.833613}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.68696513671875, \"sum\": 0.68696513671875, \"min\": 0.68696513671875}}, \"EndTime\": 1605209832.833694, \"Dimensions\": {\"model\": 27, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1605209832.833677}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6914216186523438, \"sum\": 0.6914216186523438, \"min\": 0.6914216186523438}}, \"EndTime\": 1605209832.83374, \"Dimensions\": {\"model\": 28, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1605209832.833725}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6918539306640625, \"sum\": 0.6918539306640625, \"min\": 0.6918539306640625}}, \"EndTime\": 1605209832.833788, \"Dimensions\": {\"model\": 29, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1605209832.833777}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6916122314453125, \"sum\": 0.6916122314453125, \"min\": 0.6916122314453125}}, \"EndTime\": 1605209832.833817, \"Dimensions\": {\"model\": 30, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1605209832.833809}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.693272216796875, \"sum\": 0.693272216796875, \"min\": 0.693272216796875}}, \"EndTime\": 1605209832.833844, \"Dimensions\": {\"model\": 31, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1605209832.833837}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:12 INFO 139838722238272] #quality_metric: host=algo-1, epoch=11, train binary_classification_cross_entropy_objective <loss>=0.22908795166\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:12 INFO 139838722238272] #early_stopping_criteria_metric: host=algo-1, epoch=11, criteria=binary_classification_cross_entropy_objective, value=0.126835823059\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:12 INFO 139838722238272] Epoch 11: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:12 INFO 139838722238272] Saving model for epoch: 11\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:12 INFO 139838722238272] Saved checkpoint to \"/tmp/tmp5nREYW/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:12 INFO 139838722238272] #progress_metric: host=algo-1, completed 80 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 5468, \"sum\": 5468.0, \"min\": 5468}, \"Total Batches Seen\": {\"count\": 1, \"max\": 79, \"sum\": 79.0, \"min\": 79}, \"Total Records Seen\": {\"count\": 1, \"max\": 72084, \"sum\": 72084.0, \"min\": 72084}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 5468, \"sum\": 5468.0, \"min\": 5468}, \"Reset Count\": {\"count\": 1, \"max\": 14, \"sum\": 14.0, \"min\": 14}}, \"EndTime\": 1605209832.840698, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 11}, \"StartTime\": 1605209832.529479}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:12 INFO 139838722238272] #throughput_metric: host=algo-1, train throughput=17562.6802138 records/second\u001b[0m\n",
      "\u001b[34m[2020-11-12 19:37:13.131] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 28, \"duration\": 290, \"num_examples\": 6, \"num_bytes\": 65965952}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.22258524475097657, \"sum\": 0.22258524475097657, \"min\": 0.22258524475097657}}, \"EndTime\": 1605209833.131888, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1605209833.131794}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.22003050842285157, \"sum\": 0.22003050842285157, \"min\": 0.22003050842285157}}, \"EndTime\": 1605209833.131987, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1605209833.13197}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.22376609497070313, \"sum\": 0.22376609497070313, \"min\": 0.22376609497070313}}, \"EndTime\": 1605209833.132044, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1605209833.132031}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.22000723876953124, \"sum\": 0.22000723876953124, \"min\": 0.22000723876953124}}, \"EndTime\": 1605209833.132096, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1605209833.132084}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.12378191680908203, \"sum\": 0.12378191680908203, \"min\": 0.12378191680908203}}, \"EndTime\": 1605209833.132146, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1605209833.132134}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.12404695739746094, \"sum\": 0.12404695739746094, \"min\": 0.12404695739746094}}, \"EndTime\": 1605209833.132191, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1605209833.13218}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.12323272094726563, \"sum\": 0.12323272094726563, \"min\": 0.12323272094726563}}, \"EndTime\": 1605209833.132232, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1605209833.132222}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.12353155517578125, \"sum\": 0.12353155517578125, \"min\": 0.12353155517578125}}, \"EndTime\": 1605209833.132272, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1605209833.132262}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.23328866577148438, \"sum\": 0.23328866577148438, \"min\": 0.23328866577148438}}, \"EndTime\": 1605209833.132319, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1605209833.132308}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.2323556121826172, \"sum\": 0.2323556121826172, \"min\": 0.2323556121826172}}, \"EndTime\": 1605209833.132368, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1605209833.132356}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.23293481140136718, \"sum\": 0.23293481140136718, \"min\": 0.23293481140136718}}, \"EndTime\": 1605209833.132481, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1605209833.132463}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.23057807922363283, \"sum\": 0.23057807922363283, \"min\": 0.23057807922363283}}, \"EndTime\": 1605209833.132546, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1605209833.132535}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.27024676513671875, \"sum\": 0.27024676513671875, \"min\": 0.27024676513671875}}, \"EndTime\": 1605209833.132588, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1605209833.132578}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.28447940673828126, \"sum\": 0.28447940673828126, \"min\": 0.28447940673828126}}, \"EndTime\": 1605209833.132633, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1605209833.13262}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.2933670654296875, \"sum\": 0.2933670654296875, \"min\": 0.2933670654296875}}, \"EndTime\": 1605209833.132696, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1605209833.132682}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.28256553344726565, \"sum\": 0.28256553344726565, \"min\": 0.28256553344726565}}, \"EndTime\": 1605209833.132745, \"Dimensions\": {\"model\": 15, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1605209833.132734}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.53179287109375, \"sum\": 0.53179287109375, \"min\": 0.53179287109375}}, \"EndTime\": 1605209833.132786, \"Dimensions\": {\"model\": 16, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1605209833.132776}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5324576904296875, \"sum\": 0.5324576904296875, \"min\": 0.5324576904296875}}, \"EndTime\": 1605209833.132825, \"Dimensions\": {\"model\": 17, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1605209833.132814}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5316330688476563, \"sum\": 0.5316330688476563, \"min\": 0.5316330688476563}}, \"EndTime\": 1605209833.132863, \"Dimensions\": {\"model\": 18, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1605209833.132853}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5316961303710938, \"sum\": 0.5316961303710938, \"min\": 0.5316961303710938}}, \"EndTime\": 1605209833.1329, \"Dimensions\": {\"model\": 19, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1605209833.13289}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.8131181518554688, \"sum\": 0.8131181518554688, \"min\": 0.8131181518554688}}, \"EndTime\": 1605209833.132967, \"Dimensions\": {\"model\": 20, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1605209833.132954}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7559945556640625, \"sum\": 0.7559945556640625, \"min\": 0.7559945556640625}}, \"EndTime\": 1605209833.133007, \"Dimensions\": {\"model\": 21, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1605209833.132997}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7528621704101562, \"sum\": 0.7528621704101562, \"min\": 0.7528621704101562}}, \"EndTime\": 1605209833.133046, \"Dimensions\": {\"model\": 22, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1605209833.133036}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.735983984375, \"sum\": 0.735983984375, \"min\": 0.735983984375}}, \"EndTime\": 1605209833.133087, \"Dimensions\": {\"model\": 23, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1605209833.133077}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6877936401367187, \"sum\": 0.6877936401367187, \"min\": 0.6877936401367187}}, \"EndTime\": 1605209833.133129, \"Dimensions\": {\"model\": 24, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1605209833.133116}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.68781826171875, \"sum\": 0.68781826171875, \"min\": 0.68781826171875}}, \"EndTime\": 1605209833.13317, \"Dimensions\": {\"model\": 25, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1605209833.133161}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6878686767578125, \"sum\": 0.6878686767578125, \"min\": 0.6878686767578125}}, \"EndTime\": 1605209833.133198, \"Dimensions\": {\"model\": 26, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1605209833.133191}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6869231689453125, \"sum\": 0.6869231689453125, \"min\": 0.6869231689453125}}, \"EndTime\": 1605209833.133224, \"Dimensions\": {\"model\": 27, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1605209833.133217}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6918026123046875, \"sum\": 0.6918026123046875, \"min\": 0.6918026123046875}}, \"EndTime\": 1605209833.133258, \"Dimensions\": {\"model\": 28, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1605209833.133246}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6904590454101562, \"sum\": 0.6904590454101562, \"min\": 0.6904590454101562}}, \"EndTime\": 1605209833.133307, \"Dimensions\": {\"model\": 29, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1605209833.133293}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6917791625976563, \"sum\": 0.6917791625976563, \"min\": 0.6917791625976563}}, \"EndTime\": 1605209833.133357, \"Dimensions\": {\"model\": 30, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1605209833.133342}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6912176391601562, \"sum\": 0.6912176391601562, \"min\": 0.6912176391601562}}, \"EndTime\": 1605209833.133414, \"Dimensions\": {\"model\": 31, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1605209833.133398}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:13 INFO 139838722238272] #quality_metric: host=algo-1, epoch=12, train binary_classification_cross_entropy_objective <loss>=0.222585244751\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:13 INFO 139838722238272] #early_stopping_criteria_metric: host=algo-1, epoch=12, criteria=binary_classification_cross_entropy_objective, value=0.123232720947\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:13 INFO 139838722238272] Epoch 12: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:13 INFO 139838722238272] Saving model for epoch: 12\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:13 INFO 139838722238272] Saved checkpoint to \"/tmp/tmpxGmzmZ/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:13 INFO 139838722238272] #progress_metric: host=algo-1, completed 86 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 5468, \"sum\": 5468.0, \"min\": 5468}, \"Total Batches Seen\": {\"count\": 1, \"max\": 85, \"sum\": 85.0, \"min\": 85}, \"Total Records Seen\": {\"count\": 1, \"max\": 77552, \"sum\": 77552.0, \"min\": 77552}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 5468, \"sum\": 5468.0, \"min\": 5468}, \"Reset Count\": {\"count\": 1, \"max\": 15, \"sum\": 15.0, \"min\": 15}}, \"EndTime\": 1605209833.141467, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 12}, \"StartTime\": 1605209832.841001}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:13 INFO 139838722238272] #throughput_metric: host=algo-1, train throughput=18190.5859372 records/second\u001b[0m\n",
      "\u001b[34m[2020-11-12 19:37:13.427] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 30, \"duration\": 284, \"num_examples\": 6, \"num_bytes\": 65965952}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.216999658203125, \"sum\": 0.216999658203125, \"min\": 0.216999658203125}}, \"EndTime\": 1605209833.428013, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1605209833.427912}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.21459612731933594, \"sum\": 0.21459612731933594, \"min\": 0.21459612731933594}}, \"EndTime\": 1605209833.428107, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1605209833.428088}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.21826279907226562, \"sum\": 0.21826279907226562, \"min\": 0.21826279907226562}}, \"EndTime\": 1605209833.42817, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1605209833.428152}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.21447829895019532, \"sum\": 0.21447829895019532, \"min\": 0.21447829895019532}}, \"EndTime\": 1605209833.428235, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1605209833.428217}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.11971710052490235, \"sum\": 0.11971710052490235, \"min\": 0.11971710052490235}}, \"EndTime\": 1605209833.428299, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1605209833.428281}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.12083374938964844, \"sum\": 0.12083374938964844, \"min\": 0.12083374938964844}}, \"EndTime\": 1605209833.42836, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1605209833.428344}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.11927397918701171, \"sum\": 0.11927397918701171, \"min\": 0.11927397918701171}}, \"EndTime\": 1605209833.428411, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1605209833.428397}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.12001723937988282, \"sum\": 0.12001723937988282, \"min\": 0.12001723937988282}}, \"EndTime\": 1605209833.428461, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1605209833.428449}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.229369482421875, \"sum\": 0.229369482421875, \"min\": 0.229369482421875}}, \"EndTime\": 1605209833.428516, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1605209833.428499}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.2283454071044922, \"sum\": 0.2283454071044922, \"min\": 0.2283454071044922}}, \"EndTime\": 1605209833.428588, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1605209833.428569}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.22906315612792968, \"sum\": 0.22906315612792968, \"min\": 0.22906315612792968}}, \"EndTime\": 1605209833.428664, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1605209833.428646}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.22680559997558594, \"sum\": 0.22680559997558594, \"min\": 0.22680559997558594}}, \"EndTime\": 1605209833.428727, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1605209833.42871}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.26229122314453124, \"sum\": 0.26229122314453124, \"min\": 0.26229122314453124}}, \"EndTime\": 1605209833.428795, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1605209833.428777}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.28943193359375, \"sum\": 0.28943193359375, \"min\": 0.28943193359375}}, \"EndTime\": 1605209833.428865, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1605209833.428847}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.2822344970703125, \"sum\": 0.2822344970703125, \"min\": 0.2822344970703125}}, \"EndTime\": 1605209833.428951, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1605209833.428932}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.2993118835449219, \"sum\": 0.2993118835449219, \"min\": 0.2993118835449219}}, \"EndTime\": 1605209833.429017, \"Dimensions\": {\"model\": 15, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1605209833.429}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5305587280273437, \"sum\": 0.5305587280273437, \"min\": 0.5305587280273437}}, \"EndTime\": 1605209833.429079, \"Dimensions\": {\"model\": 16, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1605209833.429063}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5309267333984375, \"sum\": 0.5309267333984375, \"min\": 0.5309267333984375}}, \"EndTime\": 1605209833.429151, \"Dimensions\": {\"model\": 17, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1605209833.429132}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5302707641601563, \"sum\": 0.5302707641601563, \"min\": 0.5302707641601563}}, \"EndTime\": 1605209833.429327, \"Dimensions\": {\"model\": 18, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1605209833.429228}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5301404174804687, \"sum\": 0.5301404174804687, \"min\": 0.5301404174804687}}, \"EndTime\": 1605209833.429381, \"Dimensions\": {\"model\": 19, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1605209833.429366}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7898839599609375, \"sum\": 0.7898839599609375, \"min\": 0.7898839599609375}}, \"EndTime\": 1605209833.42944, \"Dimensions\": {\"model\": 20, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1605209833.429422}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7656050048828125, \"sum\": 0.7656050048828125, \"min\": 0.7656050048828125}}, \"EndTime\": 1605209833.429511, \"Dimensions\": {\"model\": 21, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1605209833.429494}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7567282958984375, \"sum\": 0.7567282958984375, \"min\": 0.7567282958984375}}, \"EndTime\": 1605209833.429563, \"Dimensions\": {\"model\": 22, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1605209833.429547}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7552713500976562, \"sum\": 0.7552713500976562, \"min\": 0.7552713500976562}}, \"EndTime\": 1605209833.429622, \"Dimensions\": {\"model\": 23, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1605209833.429604}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.687879345703125, \"sum\": 0.687879345703125, \"min\": 0.687879345703125}}, \"EndTime\": 1605209833.429684, \"Dimensions\": {\"model\": 24, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1605209833.429666}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6877350830078125, \"sum\": 0.6877350830078125, \"min\": 0.6877350830078125}}, \"EndTime\": 1605209833.429753, \"Dimensions\": {\"model\": 25, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1605209833.429734}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6879973876953125, \"sum\": 0.6879973876953125, \"min\": 0.6879973876953125}}, \"EndTime\": 1605209833.429824, \"Dimensions\": {\"model\": 26, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1605209833.429806}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6873099853515625, \"sum\": 0.6873099853515625, \"min\": 0.6873099853515625}}, \"EndTime\": 1605209833.429892, \"Dimensions\": {\"model\": 27, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1605209833.429874}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6901471069335937, \"sum\": 0.6901471069335937, \"min\": 0.6901471069335937}}, \"EndTime\": 1605209833.429952, \"Dimensions\": {\"model\": 28, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1605209833.429935}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.691907958984375, \"sum\": 0.691907958984375, \"min\": 0.691907958984375}}, \"EndTime\": 1605209833.430014, \"Dimensions\": {\"model\": 29, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1605209833.429997}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6901183959960937, \"sum\": 0.6901183959960937, \"min\": 0.6901183959960937}}, \"EndTime\": 1605209833.430101, \"Dimensions\": {\"model\": 30, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1605209833.430085}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6907450073242187, \"sum\": 0.6907450073242187, \"min\": 0.6907450073242187}}, \"EndTime\": 1605209833.430163, \"Dimensions\": {\"model\": 31, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1605209833.430146}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:13 INFO 139838722238272] #quality_metric: host=algo-1, epoch=13, train binary_classification_cross_entropy_objective <loss>=0.216999658203\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:13 INFO 139838722238272] #early_stopping_criteria_metric: host=algo-1, epoch=13, criteria=binary_classification_cross_entropy_objective, value=0.119273979187\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:13 INFO 139838722238272] Epoch 13: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:13 INFO 139838722238272] Saving model for epoch: 13\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:13 INFO 139838722238272] Saved checkpoint to \"/tmp/tmpP5mgol/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:13 INFO 139838722238272] #progress_metric: host=algo-1, completed 93 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 5468, \"sum\": 5468.0, \"min\": 5468}, \"Total Batches Seen\": {\"count\": 1, \"max\": 91, \"sum\": 91.0, \"min\": 91}, \"Total Records Seen\": {\"count\": 1, \"max\": 83020, \"sum\": 83020.0, \"min\": 83020}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 5468, \"sum\": 5468.0, \"min\": 5468}, \"Reset Count\": {\"count\": 1, \"max\": 16, \"sum\": 16.0, \"min\": 16}}, \"EndTime\": 1605209833.43861, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 13}, \"StartTime\": 1605209833.143205}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:13 INFO 139838722238272] #throughput_metric: host=algo-1, train throughput=18502.9735934 records/second\u001b[0m\n",
      "\u001b[34m[2020-11-12 19:37:13.752] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 32, \"duration\": 312, \"num_examples\": 6, \"num_bytes\": 65965952}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.21210113525390625, \"sum\": 0.21210113525390625, \"min\": 0.21210113525390625}}, \"EndTime\": 1605209833.753131, \"Dimensions\": {\"model\": 0, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1605209833.753}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.20981378173828125, \"sum\": 0.20981378173828125, \"min\": 0.20981378173828125}}, \"EndTime\": 1605209833.753282, \"Dimensions\": {\"model\": 1, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1605209833.753255}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.21342594604492188, \"sum\": 0.21342594604492188, \"min\": 0.21342594604492188}}, \"EndTime\": 1605209833.753369, \"Dimensions\": {\"model\": 2, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1605209833.753347}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.20961478576660156, \"sum\": 0.20961478576660156, \"min\": 0.20961478576660156}}, \"EndTime\": 1605209833.753441, \"Dimensions\": {\"model\": 3, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1605209833.753421}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.11859465942382813, \"sum\": 0.11859465942382813, \"min\": 0.11859465942382813}}, \"EndTime\": 1605209833.753511, \"Dimensions\": {\"model\": 4, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1605209833.753492}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.1181291000366211, \"sum\": 0.1181291000366211, \"min\": 0.1181291000366211}}, \"EndTime\": 1605209833.753575, \"Dimensions\": {\"model\": 5, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1605209833.753557}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.11824990844726563, \"sum\": 0.11824990844726563, \"min\": 0.11824990844726563}}, \"EndTime\": 1605209833.753645, \"Dimensions\": {\"model\": 6, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1605209833.753625}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.118227001953125, \"sum\": 0.118227001953125, \"min\": 0.118227001953125}}, \"EndTime\": 1605209833.753705, \"Dimensions\": {\"model\": 7, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1605209833.753689}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.2260432098388672, \"sum\": 0.2260432098388672, \"min\": 0.2260432098388672}}, \"EndTime\": 1605209833.753964, \"Dimensions\": {\"model\": 8, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1605209833.753784}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.22495472106933595, \"sum\": 0.22495472106933595, \"min\": 0.22495472106933595}}, \"EndTime\": 1605209833.754053, \"Dimensions\": {\"model\": 9, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1605209833.754032}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.2257593078613281, \"sum\": 0.2257593078613281, \"min\": 0.2257593078613281}}, \"EndTime\": 1605209833.754133, \"Dimensions\": {\"model\": 10, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1605209833.754112}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.22361575622558594, \"sum\": 0.22361575622558594, \"min\": 0.22361575622558594}}, \"EndTime\": 1605209833.754204, \"Dimensions\": {\"model\": 11, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1605209833.754185}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.2728396423339844, \"sum\": 0.2728396423339844, \"min\": 0.2728396423339844}}, \"EndTime\": 1605209833.75427, \"Dimensions\": {\"model\": 12, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1605209833.754253}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.31259061279296874, \"sum\": 0.31259061279296874, \"min\": 0.31259061279296874}}, \"EndTime\": 1605209833.754329, \"Dimensions\": {\"model\": 13, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1605209833.754312}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.29603601684570313, \"sum\": 0.29603601684570313, \"min\": 0.29603601684570313}}, \"EndTime\": 1605209833.754392, \"Dimensions\": {\"model\": 14, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1605209833.754374}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.29560187377929686, \"sum\": 0.29560187377929686, \"min\": 0.29560187377929686}}, \"EndTime\": 1605209833.754463, \"Dimensions\": {\"model\": 15, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1605209833.754445}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5299775268554687, \"sum\": 0.5299775268554687, \"min\": 0.5299775268554687}}, \"EndTime\": 1605209833.754535, \"Dimensions\": {\"model\": 16, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1605209833.754516}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.530071337890625, \"sum\": 0.530071337890625, \"min\": 0.530071337890625}}, \"EndTime\": 1605209833.754593, \"Dimensions\": {\"model\": 17, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1605209833.754576}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5297714721679687, \"sum\": 0.5297714721679687, \"min\": 0.5297714721679687}}, \"EndTime\": 1605209833.754701, \"Dimensions\": {\"model\": 18, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1605209833.754637}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.5298636596679688, \"sum\": 0.5298636596679688, \"min\": 0.5298636596679688}}, \"EndTime\": 1605209833.754769, \"Dimensions\": {\"model\": 19, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1605209833.754751}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.8288796508789062, \"sum\": 0.8288796508789062, \"min\": 0.8288796508789062}}, \"EndTime\": 1605209833.75483, \"Dimensions\": {\"model\": 20, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1605209833.754812}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7716980102539063, \"sum\": 0.7716980102539063, \"min\": 0.7716980102539063}}, \"EndTime\": 1605209833.754894, \"Dimensions\": {\"model\": 21, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1605209833.754876}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7742952270507812, \"sum\": 0.7742952270507812, \"min\": 0.7742952270507812}}, \"EndTime\": 1605209833.754954, \"Dimensions\": {\"model\": 22, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1605209833.754939}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.7519755737304687, \"sum\": 0.7519755737304687, \"min\": 0.7519755737304687}}, \"EndTime\": 1605209833.755058, \"Dimensions\": {\"model\": 23, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1605209833.755037}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6877484741210937, \"sum\": 0.6877484741210937, \"min\": 0.6877484741210937}}, \"EndTime\": 1605209833.755151, \"Dimensions\": {\"model\": 24, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1605209833.755133}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6873029174804688, \"sum\": 0.6873029174804688, \"min\": 0.6873029174804688}}, \"EndTime\": 1605209833.755205, \"Dimensions\": {\"model\": 25, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1605209833.755191}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6876483642578125, \"sum\": 0.6876483642578125, \"min\": 0.6876483642578125}}, \"EndTime\": 1605209833.755262, \"Dimensions\": {\"model\": 26, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1605209833.755247}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6876373168945312, \"sum\": 0.6876373168945312, \"min\": 0.6876373168945312}}, \"EndTime\": 1605209833.755318, \"Dimensions\": {\"model\": 27, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1605209833.755303}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6904932739257813, \"sum\": 0.6904932739257813, \"min\": 0.6904932739257813}}, \"EndTime\": 1605209833.755374, \"Dimensions\": {\"model\": 28, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1605209833.755359}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6905006591796875, \"sum\": 0.6905006591796875, \"min\": 0.6905006591796875}}, \"EndTime\": 1605209833.755429, \"Dimensions\": {\"model\": 29, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1605209833.755414}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6909908813476563, \"sum\": 0.6909908813476563, \"min\": 0.6909908813476563}}, \"EndTime\": 1605209833.755479, \"Dimensions\": {\"model\": 30, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1605209833.755466}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"count\": 1, \"max\": 0.6914436767578125, \"sum\": 0.6914436767578125, \"min\": 0.6914436767578125}}, \"EndTime\": 1605209833.755533, \"Dimensions\": {\"model\": 31, \"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1605209833.755517}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:13 INFO 139838722238272] #quality_metric: host=algo-1, epoch=14, train binary_classification_cross_entropy_objective <loss>=0.212101135254\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:13 INFO 139838722238272] #early_stopping_criteria_metric: host=algo-1, epoch=14, criteria=binary_classification_cross_entropy_objective, value=0.118129100037\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:13 INFO 139838722238272] Epoch 14: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:13 INFO 139838722238272] Saving model for epoch: 14\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:13 INFO 139838722238272] Saved checkpoint to \"/tmp/tmpuSzmpJ/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:13 INFO 139838722238272] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 5468, \"sum\": 5468.0, \"min\": 5468}, \"Total Batches Seen\": {\"count\": 1, \"max\": 97, \"sum\": 97.0, \"min\": 97}, \"Total Records Seen\": {\"count\": 1, \"max\": 88488, \"sum\": 88488.0, \"min\": 88488}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 5468, \"sum\": 5468.0, \"min\": 5468}, \"Reset Count\": {\"count\": 1, \"max\": 17, \"sum\": 17.0, \"min\": 17}}, \"EndTime\": 1605209833.764147, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\", \"epoch\": 14}, \"StartTime\": 1605209833.440453}\n",
      "\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:13 INFO 139838722238272] #throughput_metric: host=algo-1, train throughput=16885.9804903 records/second\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:13 WARNING 139838722238272] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:13 WARNING 139838722238272] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[2020-11-12 19:37:13.785] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 34, \"duration\": 20, \"num_examples\": 1, \"num_bytes\": 12064000}\u001b[0m\n",
      "\u001b[34m[2020-11-12 19:37:13.948] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 37, \"duration\": 159, \"num_examples\": 6, \"num_bytes\": 65965952}\u001b[0m\n",
      "\u001b[34m[2020-11-12 19:37:14.033] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 39, \"duration\": 72, \"num_examples\": 6, \"num_bytes\": 65965952}\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:14 INFO 139838722238272] #train_score (algo-1) : ('binary_classification_cross_entropy_objective', 0.3612331733619896)\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:14 INFO 139838722238272] #train_score (algo-1) : ('binary_classification_accuracy', 0.9290416971470373)\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:14 INFO 139838722238272] #train_score (algo-1) : ('binary_f_1.000', 0.9218057234985892)\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:14 INFO 139838722238272] #train_score (algo-1) : ('precision', 0.9384489125974559)\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:14 INFO 139838722238272] #train_score (algo-1) : ('recall', 0.9057425742574258)\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:14 INFO 139838722238272] #train_score (algo-1) : ('roc_auc_score', 0.9699098717211171)\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:14 INFO 139838722238272] #quality_metric: host=algo-1, train binary_classification_cross_entropy_objective <loss>=0.361233173362\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:14 INFO 139838722238272] #quality_metric: host=algo-1, train binary_classification_accuracy <score>=0.929041697147\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:14 INFO 139838722238272] #quality_metric: host=algo-1, train binary_f_1.000 <score>=0.921805723499\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:14 INFO 139838722238272] #quality_metric: host=algo-1, train precision <score>=0.938448912597\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:14 INFO 139838722238272] #quality_metric: host=algo-1, train recall <score>=0.905742574257\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:14 INFO 139838722238272] #quality_metric: host=algo-1, train roc_auc_score <score>=0.969909871721\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:14 INFO 139838722238272] Best model found for hyperparameters: {\"lr_scheduler_step\": 100, \"wd\": 0.0001, \"optimizer\": \"adam\", \"lr_scheduler_factor\": 0.99, \"l1\": 0.0, \"learning_rate\": 0.1, \"lr_scheduler_minimum_lr\": 1e-05}\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:14 INFO 139838722238272] Saved checkpoint to \"/tmp/tmpNaSR7W/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[11/12/2020 19:37:14 INFO 139838722238272] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 6294.546127319336, \"sum\": 6294.546127319336, \"min\": 6294.546127319336}, \"finalize.time\": {\"count\": 1, \"max\": 278.03492546081543, \"sum\": 278.03492546081543, \"min\": 278.03492546081543}, \"initialize.time\": {\"count\": 1, \"max\": 786.0500812530518, \"sum\": 786.0500812530518, \"min\": 786.0500812530518}, \"check_early_stopping.time\": {\"count\": 15, \"max\": 1.2011528015136719, \"sum\": 14.362096786499023, \"min\": 0.823974609375}, \"setuptime\": {\"count\": 1, \"max\": 28.934955596923828, \"sum\": 28.934955596923828, \"min\": 28.934955596923828}, \"update.time\": {\"count\": 15, \"max\": 410.0828170776367, \"sum\": 4856.234788894653, \"min\": 278.60403060913086}, \"epochs\": {\"count\": 1, \"max\": 15, \"sum\": 15.0, \"min\": 15}}, \"EndTime\": 1605209834.048287, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"Linear Learner\"}, \"StartTime\": 1605209828.033209}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-11-12 19:37:24 Uploading - Uploading generated training model\n",
      "2020-11-12 19:37:24 Completed - Training job completed\n",
      "Training seconds: 71\n",
      "Billable seconds: 71\n",
      "CPU times: user 547 ms, sys: 64.6 ms, total: 611 ms\n",
      "Wall time: 3min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# train the estimator on formatted training data\n",
    "linear.fit(formatted_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------!CPU times: user 346 ms, sys: 15.8 ms, total: 362 ms\n",
      "Wall time: 9min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# deploy and create a predictor\n",
    "linear_predictor = linear.deploy(initial_instance_count=1, instance_type='ml.t2.medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[label {\n",
      "  key: \"predicted_label\"\n",
      "  value {\n",
      "    float32_tensor {\n",
      "      values: 0.0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "label {\n",
      "  key: \"score\"\n",
      "  value {\n",
      "    float32_tensor {\n",
      "      values: 0.006237988825887442\n",
      "    }\n",
      "  }\n",
      "}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# test one prediction\n",
    "test_x_np = test_X.astype('float32')\n",
    "result = linear_predictor.predict(test_x_np[0])\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_batches = [linear_predictor.predict(batch) for batch in np.array_split(test_x_np, 100)]\n",
    "\n",
    "# LinearLearner produces a `predicted_label` for each data point in a batch\n",
    "# get the 'predicted_label' for every point in a batch\n",
    "test_preds = np.concatenate([np.array([x.label['score'].float32_tensor.values[0] for x in batch]) \n",
    "                             for batch in prediction_batches])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7383477397901755"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test.to_numpy(), test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3debzM9ffA8dehEEmFFmRJVFKJG9oXKZXim5IWoeTbnlLf6tv3296v5Vtp0Ur7QitRSgslspbKEmUJl+yUnXud3x/nc91x3WXuMvOZ5Twfj/u4M/P5zMyZz507Zz7v5bxFVXHOOecKUi7sAJxzziU2TxTOOecK5YnCOedcoTxROOecK5QnCuecc4XyROGcc65Qnihc1ETkEhH5Iuw4EomIrBORA0N43voioiKyS7yfOxZEZLqInFyC+/l7Mg48USQpEflDRDYGH1RLROQ1Edk9ls+pqm+r6umxfI5IInKsiIwUkbUi8peIDBORJvF6/nzi+UZEekbepqq7q+rcGD1fYxF5X0RWBK//FxG5WUTKx+L5SipIWAeV5jFU9TBV/aaI59kpOcb7PZmuPFEkt3NUdXegGXAUcEfI8ZRIft+KReQY4AvgY6AW0AD4GRgbi2/wifbNXEQaAhOAhcDhqloNuADIAKqW8XOF9toT7bi7Aqiq/yThD/AHcFrE9UeBTyOuVwQeAxYAS4EXgN0itncAfgL+BuYA7YLbqwEvA38Ci4AHgPLBtu7AmODyC8BjeWL6GLg5uFwL+BBYDswDbojY7x7gA+Ct4Pl75vP6vgOey+f2z4A3gssnA5nAv4EVwTG5JJpjEHHf24AlwJvAXsAnQcyrg8t1gv0fBLKBTcA6oF9wuwIHBZdfA54FPgXWYh/0DSPiOR2YBfwFPAd8m99rD/Z9K/Lvmc/2+sFzdwte3wrgzojtLYFxwJrgb9kPqBCxXYFrgd+BecFtT2GJ6W/gB+CEiP3LB8d5TvDafgAOAEYHj7U+OC4XBvu3x95fa4DvgSPyvHdvA34BNgO7EPF+DmKfHMSxFHgiuH1B8Fzrgp9jiHhPBvscBnwJrAru+++w/1dT4Sf0APynhH+4Hf+x6gBTgacitj8JDAX2xr6BDgMeCra1DD6s2mJnlbWBQ4JtQ4AXgSrAPsBE4J/Btu3/lMCJwYeKBNf3AjZiCaJc8EFyF1ABOBCYC5wR7HsPsBXoGOy7W57XVhn7UD4ln9fdA/gzuHwykAU8gSWFk4IPrIOjOAY5930kuO9uQHWgU/D8VYH3gSERz/0NeT7Y2TlRrAqO7y7A28CgYFuN4IPvvGDbjcExKChRLAF6FPL3rx88d/8g9iOxD91Dg+0tgNbBc9UHfgV654n7y+DY5CTPS4NjsAvQJ4ihUrDtVuw9djAgwfNVz3sMguvNgWVAKyzBdMPerxUj3rs/YYlmt4jbct7P44CuweXdgdZ5XvMuEc/Vndz3ZFUsKfYBKgXXW4X9v5oKP6EH4D8l/MPZP9Y67NudAl8DewbbBPvAjPw2ewy53xxfBPrm85j7Bh82kWceFwGjgsuR/5SCfcM7Mbh+JTAyuNwKWJDnse8AXg0u3wOMLuS11Qle0yH5bGsHbA0un4x92FeJ2P4e8N8ojsHJwJacD8IC4mgGrI64/g1FJ4oBEdvOAmYGly8DxkVsEyzRFpQothKc5RWwPedDs07EbROBLgXs3xsYnCfuU4t4j60GjgwuzwI6FLBf3kTxPHB/nn1mASdFvHcvz+f9nJMoRgP3AjUKeM0FJYqLgCmx/L9L1x9vH0xuHVX1KxE5CXgH+9a6BqiJfSv+QURy9hXs2x3YN7nh+TxePWBX4M+I+5XDPtB2oKoqIoOwf87RwMVYc0nO49QSkTURdymPNSfl2OkxI6wGtgH7AzPzbNsfa2bZvq+qro+4Ph87qynqGAAsV9VN2zeKVAb6Yslor+DmqiJSXlWzC4k30pKIyxuwb8QEMW1/zcHxyyzkcVZir7VEzycijbEzrQzsOOyCneVF2uFvICJ9gJ5BrArsgb2nwN4zc6KIB+zv301Ero+4rULwuPk+dx5XAPcBM0VkHnCvqn4SxfMWJ0ZXDN6ZnQJU9Vvs2+xjwU0rsGagw1R1z+CnmlrHN9g/acN8HmohdkZRI+J+e6jqYQU89UDgfBGph51FfBjxOPMiHmNPVa2qqmdFhl3I61mPNT9ckM/mztjZU469RKRKxPW6wOIojkF+MfTBmlZaqeoeWPMaWIIpNOYo/ImdKdkDWvaqU/DufIU1g5XU81iSbRS8ln+T+zpybH89InIC1m/QGdhLVffEmidz7lPQeyY/C4EH8/z9K6vqwPyeOy9V/V1VL8KaPh8BPgj+xkUd/+LE6IrBE0XqeBJoKyLNVHUb1nbdV0T2ARCR2iJyRrDvy0APEWkjIuWCbYeo6p/YSKPHRWSPYFvD4IxlJ6o6Bev4HQCMUNWcM4iJwN8icpuI7CYi5UWkqYgcXYzXczv2rfQGEakqInuJyANY89G9efa9V0QqBB927YH3ozgG+amKJZc1IrI3cHee7Uux/paS+BQ4XEQ6BiN9rgX2K2T/u4FjReR/IrJfEP9BIvKWiOwZxfNVxfpE1onIIcDVUeyfhf09dxGRu7AzihwDgPtFpJGYI0SkerAt73HpD1wlIq2CfauIyNkiEtVoLRG5VERqBn/DnPdUdhDbNgr+G3wC7CcivUWkYvC+aRXNc7rCeaJIEaq6HHgDa58H+3Y4GxgvIn9j31APDvadiHUK98W+NX6LNReAtaVXAGZgTUAfUHgTyEDgNKzpKyeWbOAcrI1/HvbtfgA2oira1zMGOAPr/P0Ta1I6CjheVX+P2HVJEOdirPP4KlXNaa4q8BgU4EmsY3gFMB74PM/2p7AzqNUi8nS0ryV4PSuwM6RHsWalJtjIns0F7D8HS4r1geki8hd2xjYZ65cqyi1Yc+Ba7IP73SL2H4GNKPsNO9ab2LF56Ams/+cLLAG9jB0rsD6n10VkjYh0VtXJWJ9VP+xvMxvrS4hWO+w1r8OOeRdV3aSqG7DRZ2OD52odeSdVXYsN0DgHe1/8DpxSjOd1BcgZseJc0glm8r6lqoU14SQkESmHDc+9RFVHhR2Pc4XxMwrn4kREzhCRPUWkIrl9BuNDDsu5IsUsUYjIKyKyTESmFbBdRORpEZkdlCZoHqtYnEsQx2CjclZgzSMdVXVjuCE5V7SYNT2JyInYOP83VLVpPtvPAq7Hxpq3wiaLeceTc84lmJidUajqaGyWakE6YElEVXU8sKeIRDNu3DnnXByFOeGuNjuOqsgMbvsz744i0gvoBVClSpUWhxxySFwCdM65RKRqP2vXwrJlBe/3999Ql/nsyRp+IWuFqtYsyfOFmSjyTv6BAibUqOpLwEsAGRkZOnny5FjG5ZxzCWfLFpgzB/r2hf79d9zWsmWenYMuBUW4Mut52rdcRq0X75lf0ucOM1FkYlPuc9TBxsI751xayTlDAMjMhLFjYf58GDkSqlSBIUN2vs8tt0DNmnDkkXBG5DTSRYvg6qvhwgvhkkvYPtfyxXtKHF+YiWIocF1QL6gV8FcwM9g559LGH39AgwYFb69fHw4/HNavhyuugIYN4dRTLUnsQBUGDLAMsnUrnH12mcUYs0QhIgOxCp01guJnd2MF51DVF7CidGdhszY3YDOFnXMu5WRlwVdfwcaN8MMPMHMmfPjhjvs0agSXXmqX69SB446DvfaCffaJ4gnmzIErr4RRo+CUU6xtqmHZlb2KWaIIinoVtl2xejfOOZdSNmywZqP+/aFqVfj6a1iyZMd9GjWyBHLppbDfftZaJPn13EZj6lTLQC+9BD17luKB8udlxp1zrhi2bYMxY2Dduvy3f/yxfV5HatAA6taFN96APfeE2rWhRo387x+1adPgxx/hssugY0eYOxeqVy/6fiXgicI55woxb559+N9/vw03zcqK7n6NG8MHH0DTpmX8BX/LFvi//7OfffeFzp2hUqWYJQnwROGcc9vNnm0jjEaPhmHDoHJla0bKUbky3HADbNoEXbpAxYr5P87hh8Nuu+W/rVQmTLAe7enTrc2qb19LEjHmicI5l/ays+Hhh+E//8m9rVIl6xc+8EA45BAbRFSvXsGPEXOLFsEJJ9hZxCeflOmopqJ4onDOpaSsLOvf/fpruPNOa5nZpYBPvKVLcy8/9RScd56NPEoIv/1m7Vi1a8O770KbNrDHHkXfrwx5onDOJTRV+OUXa+5Rhbffhl133Xm/oUOtgzknGSxatOP2gw+2JqGCbNgAt98OTZqUXeylsmYN/OtfNjfim2/gxBPhH/8IJRRPFM65hLJkic1O/vFH60DOzMx/v6p5FlbdutWSyRVX7HjbpZfaUNT69WMWctkbOtTGyy5ZArfeCkcXZxXhsueJwjkXuvXr4fdggdujjtp5+3nnQffudrZQoYJ9uc7vrCIl9OwJL79spz8ffwwZGWFH5InCORd/a9bAiy/a8NFVq2wKQKSMDLj7bmsGOvDAcGKMq5xCTyL24uvVg9tus6yYADxROOfirlEjWLEi93qXLlCtGrRrB+XKwcknx72/NjwLF8JVV9lB6NrVLicYTxTOubj66CNLEjVq2LyFatXCjigk27bZadVtt9n43JA6qqPhicI5F1Nr18Krr8KgQVYU76ef7PYvvkjjJPH779YXMXo0nHaa1fworIRsyDxROOfKzJw5MHiwXZ45E8aNgxkzdtynfXubwJZfp3XamDHDxvy+8or10pdxEb+y5onCOVdiWVlW6mL+fGs9ueWWnfdp1Qpat7ZJbzVqJPxnYuz8/LOdTnXrBh06WA/+XnuFHVVUPFE453ayeTP89dfOt69cCZ06wd572wf+mDE773PSSVZhAmzQToIM3AnP5s3wwANWI2T//W3luUqVkiZJgCcK51wezz0H10axUsypp1otpMqV7XOwfn0oX37niXBpbdw4mwH4669WDvyJJ+JSxK+seaJwzrF2LSxfbhPZckpfnHtunrWYA/vsA+efH9/4ktKiRXZ6td9+MHw4nHlm2BGVmCcK59KIqtU02rTJPru2bt2x5EWOCROgZcv4x5cSfv0VDj3Uivi9954V8Uvy0yxPFM6lmC1bbOjpqlW5t73+uq2P8OmnBd/v8cft86xHj4KrrLpCrF4NffrYWODRo60keMeOYUdVJvzt4FyKmDHDRhgVtEQnQPPmdhbRtav1J5x3ntVMql07fnGmpMGD4ZprrP3ujjtCL+JX1jxROJekxo61ZvBPP7Xk8NFHdvvee8NNN9m6NjkT2sqVs/JBaTs0NZYuv9zOIpo1sz9G8+ZhR1TmPFE4l2Q+/jj/Fo1DD7XPqLfein9MaSeyiF/r1la86pZbUrakrScK55LEihXWqjFggF3v3dvmbe2zj1V/iMkazW5n8+fDP/8JF19sQ1579Qo7opjzROFcAlu3Dv73PyuNMWJEbsXVCy6Avn3DjS3tbNsGzz9vy+Cp2h8hTXiicC5Bbdq046jKevXggAPgq6+sH8LF0axZVsRvzBg4/XSr+ppUS+aVTrmwA3DO5Vq50r6wiuQ2JdWoAcuWwR9/2PKgniRCMGsWTJ8Or70Gn3+eVkkC/IzCuYTRrx9cf33u9Xr1rHXj//4vZftIE9uUKVbEr0cPm6Y+dy7suWfYUYXCzyicSwADB+YmiXvusblbf/xh/ROeJOJs0yb4979tLsQ999h1SNskAX5G4VxoVq2yFg1VG0ADNrT1kkvCjSutjR1rNU1mzbIziccfT8oifmXNE4VzcfTll/DZZzYr+rHHdtyWkeFJIlSLFlk53Nq1bYjZ6aeHHVHC8EThXIxNngw332wrvi1fbrdVrmz1lFq1gv/+1xLH8ceHG2famjEDmjSxBPHhh5Ysdt897KgSiicK58rYtm1WNLRHj9zm7RwdO9rKlx06hBKai7RqlWXw11+Hb7+1GuvnnBN2VAnJE4VzZSAz08p2L14M996be3ujRtC4MVx3HbRrF158Lo8PP7TVmVautDVavaZ6oTxROFcK2dnw9dc7L/BTsaI1OTVtGk5crhDdu9tZRPPmNieiWbOwI0p4PjzWuVK4997cJNGzp51ZqFqTkyeJBKKaW8jv2GNt/eoJEzxJRCmmZxQi0g54CigPDFDVh/Nsrwu8DuwZ7HO7qg6PZUzOFZeqJYCtW63FIseYMTB0qM2gfucdK+vtcx4S0Lx5Vrjv0kuhW7e0KOJX1mKWKESkPPAs0BbIBCaJyFBVnRGx23+A91T1eRFpAgwH6scqJudK4umnrVJrQe68M2UWMkst2dnw7LNWcrdcOR97XAqxPKNoCcxW1bkAIjII6ABEJgoF9gguVwMWxzAe5wq0apWdMeTVrx888IBdfuUVqFBhxzOHihV92dCE9OuvNnFu3Dg480x44QWoWzfsqJJWLN/itYGFEdczgVZ59rkH+EJErgeqAKfl90Ai0gvoBVDX/9iuDM2aBS1awPr1he93/fU23NUlidmz7Y/75pt2JuFL+5VKLBNFfn8ZzXP9IuA1VX1cRI4B3hSRpqq6bYc7qb4EvASQkZGR9zGcK5avvrI5VnfdBX/9Zbftsgs88cTOZweq1lndsGH843TF9MMP8PPPtjTpOedY38QeexR9P1ekWCaKTOCAiOt12Llp6QqgHYCqjhORSkANYFkM43JpbMUKaNt2x9see8zmXfmXziS1caMNP3vsMVuw4+KLrT6TJ4kyE8vhsZOARiLSQEQqAF2AoXn2WQC0ARCRQ4FKwPIYxuTSXM2a9vu//7WkoQp9+niSSFqjR8ORR8Ijj9j8iClTvIhfDMTsjEJVs0TkOmAENvT1FVWdLiL3AZNVdSjQB+gvIjdhzVLdVdWbllxMfPGF/a5Rw76AenJIcosWQZs2ucv+tWkTdkQpK6bjNYI5EcPz3HZXxOUZwHGxjMGlt8ivHfPm2e+PP/YkkdSmToXDD7cifoMHWxG/KlXCjiql+cxsl3LmzrW5VVWq2PD5nJ+rrrLt3jGdpFasgK5d4YgjrMkJoH17TxJx4CPAXcpQtZFLt9xi16tXt/7MnAQBsP/+sO++4cTnSkgV3n/fKiuuXg1332312V3ceKJwSW/bNptb9dprdr1yZfsc+fxzmyDnkly3bjYfIiPDKjAefnjYEaUdTxQuaW3ZYi0QkcNde/SA55+3GdMuieV0LonASSdZc1Pv3j4NPiR+1F3SWLcOxo+3z5ARI2w540jLluUOf3VJbO5cuPJK62jq0cNOF12oPFG4pLBhA1StuvPtDRpY83WzZracqEti2dnwzDNWZbF8ebjssrAjcgFPFC7hjRoFp55ql2vVsmVGwZqqffJtipgxw0pvTJhgVRdfeAHq1Ak7KhfwROESXufO9rtbN+jf39d8SEnz5sGcObawR5cuPtElwXiicAlj61YYNgy+/976GwYNslnUK1ZYH+arr/rnR0qZNAl++sn6I84+2/om8mtfdKHzROFC9/vvMGCADW9dtsxGLKla4mjYEM46yz5LPEmkiA0brHRv375Qr55NoqtUyZNEAvNE4UKxaRN89JE1JX3zjfVdtm9vCaFdO++YTlnffGOLi8+ZA//8pxXz8yJ+Cc8ThYuradMsObz5pk2ybdAAHnzQCn/WqhV2dC6mMjNt0ku9ejBypNVocknBE4WLuXXr4N13rXlp/HibLf2Pf9jZwymnWB0ml8J+/tlKgdepYxUZTz7Zps+7pOGJwsXE7bfDZ5/Z5XnzYO1aOOQQmyR32WXWSe1S3PLlcOONMHCgNTmddJJ1OLmk44nClalffrEaSwMGWNPz0UdD69aWHI491juk04KqDVm74QZba/bee+GYY8KOypVCVIkiWKGurqrOjnE8LglddhnMnGlJYOLE3Nv/8x+4//7w4nIh6doV3n7bKjO+/DIcdljYEblSKjJRiMjZwBNABaCBiDQD7lbVf8Q6OJe4xo+3JUTHjcut39aunf20bWulvb0ZOo1s22bfFESs46lFCzuj8OFrKSGaM4r7gFbAKABV/UlEDoppVC5hqcKjj1ofRI4WLWyi3P77hxeXC9Hs2TYyoWtXK8PhRfxSTjTjTbaq6po8t/m61mlIFY47LjdJPPywfZGcPNmTRFrKyoLHHrOiW1Om+OIfKSyaM4pfRaQzUE5EGgA3AuNjG5ZLFKo2vHXtWluiGODEE60kT851l4amTbMS4JMnQ4cO8NxzPhEmhUVzRnEd0ALYBnwEbMKShUtxffrYHIc99tgxKXz4oSeJtLdgAcyfb6ObBg/2JJHiojmjOENVbwNuy7lBRM7DkoZLQatXw/HHW+VnsMErF1wAu+8OvXr5ENe0NWGCTZ7r1cvmQ8yda28Kl/KiSRT/YeekcGc+t7kUsGED7L137vWJE20uhEtj69fDf/8LTz4JBx5o9d4rVvQkkUYKTBQicgbQDqgtIk9EbNoDa4ZyKWbLFlsKAKB+ffvC6GcPaW7kSBvRNHcuXH21jWDwBcnTTmFnFMuAaVifxPSI29cCt+d7D5e0srN3/P+fNs2TRNrLzIQzzrDKjd9+a6MYXFoqMFGo6hRgioi8raqb4hiTC8E/IqZP/vknVKkSXiwuZFOmwFFHWRG/YcOsRtNuu4UdlQtRNKOeaovIIBH5RUR+y/mJeWQubn7/3T4PAP7+G/bbL9x4XEiWLoULL4Tmze0MAmyqvSeJtBdNongNeBUQ4EzgPWBQDGNycfboo/Z72DBfZCwtqcJbb0GTJjBkCDzwgFVwdC4QTaKorKojAFR1jqr+B/AVR1LEkiXwxhtWm6l9+7CjcaG4+GIrv3HwwbaG9Z13wq67hh2VSyDRDI/dLCICzBGRq4BFwD6xDcvFS79+tjb1zTeHHYmLq8gifqefbmXAr73Wi/i5fEVzRnETsDtwA3AccCVweSyDcvGxbp1VXujYERo1CjsaFze//WYVXl95xa736OGVXl2hijyjUNUJwcW1QFcAEakTy6BcfBx7rM3CvvXWsCNxcZGVBU88AXffbatKeSe1i1KhZxQicrSIdBSRGsH1w0TkDbwoYNJbtAimTrUlSX3xsTTwyy+21OBtt8GZZ1p9losvDjsqlyQKTBQi8hDwNnAJ8LmI3ImtSfEz0Dg+4blY+OMPaBz8BR98MNRQXLxkZsLChfD++1bV0evCu2IorOmpA3Ckqm4Ukb2BxcH1WdE+uIi0A54CygMDVPXhfPbpDNyDrXHxs6r615wY2bwZvvwSzjnHrtesac3TLkV9/72dSVx1VW4RP59J6UqgsKanTaq6EUBVVwEzi5kkygPPYnMvmgAXiUiTPPs0Au4AjlPVw4DexYzfRWnWLGuWzkkSF10Ey5b5KMiUtG4d3HijlQB+/HH7hgCeJFyJFXZGcaCI5FSIFaB+xHVU9bwiHrslMFtV5wKIyCDsLGVGxD5XAs+q6urgMZcVM34XBVX73AA7i3j7bTjttHBjcjHyxRdWBnzBAhvu+n//50X8XKkVlig65bner5iPXRtYGHE9E1t7O1JjABEZizVP3aOqn+d9IBHpBfQCqFu3bjHDSG/r19vSpSNGQL16MG+eF/tLWQsXwtlnQ8OGMHq0nVE4VwYKKwr4dSkfO7+Po7xrbe8CNAJOBuoA34lI07xrdKvqS8BLABkZGb5ed5RWrLAziByDB3uSSEk//AAtWsABB8Dw4XDCCdbO6FwZiWbCXUllAgdEXK+DdYjn3edjVd2qqvOAWVjicKWUmZmbJBo2hDFjrCCoSyFLltjSgxkZuUX82rb1JOHKXCwTxSSgkYg0EJEKQBdgaJ59hhDUjQrmajQG5sYwppQ3f76V5TggSNGtWsHs2XDcceHG5cqQKrz+uhXxGzbM+iG8iJ+LoWhqPQEgIhVVdXO0+6tqlohcB4zA+h9eUdXpInIfMFlVhwbbTheRGUA2cKuqrizeS3CR7r0XXn019/pXX4UXi4uRLl3gvfcs+w8YAIccEnZELsWJauFN/iLSEngZqKaqdUXkSKCnql4fjwDzysjI0MmTJ4fx1AnvttusZPiee9oaE3vvDeViec7o4ieyiN/rr8PatXDNNf4HdlETkR9UNaMk943mjOJpoD3WTISq/iwiXmY8gfz0k/VlbgtWMn/gASvN4VLEzJnQsyd0726/u3ULOyKXZqJJFOVUdb7sOFwmO0bxuBK47LLcJDF3ri1x7FLA1q3wv/9Ze2KVKrD77mFH5NJUNOetC4PmJxWR8iLSG/ClUBPEa69Zcb9jj7Vk4UkiRfz0E7RsaYsInXuuFfHr0iXsqFyaiuaM4mqs+akusBT4KrjNhWzevNxaTf/8p8+RSClLltjPhx/CeUUVQXAutqJJFFmq6l9lEtCkSfb7oYes+ckluTFjrIjfNddAu3YwZw5Urhx2VM5F1fQ0SUSGi0g3Eaka84hcVO66Cy680C63bRtuLK6U1q6F666zGdVPPplbxM+ThEsQRSYKVW0IPAC0AKaKyBAR8TOMEGVkwP332+U77rARTy5JjRgBTZvamrQ33gg//uhF/FzCiWrCnap+D3wvIvcAT2ILGg2KYVyuANnZVtoHrH/z0EPDjceVwsKF0L49HHSQNTv57GqXoIo8oxCR3UXkEhEZBkwElgP+jg7Zffd5kkhKqjBxol0+4AD47DOYMsWThEto0fRRTANaA4+q6kGq2kdVJ8Q4LpePxYvh5pvDjsKV2J9/QqdOVoArp4jfaad5ET+X8KJpejpQVbfFPBJXKFWoXdsu77qrV4JNKqo24eXmm2HTJnjkEa/S6JJKgYlCRB5X1T7AhyKyU0GoKFa4c2Vk9Gg46aTc65s3+5yJpNK5M3zwgY1qGjAAGjcOOyLniqWwM4p3g9/FXdnOlRFVq95w7725t61Y4UkiKWRn2x+qXDlbqPzUU21WpBfxc0mowHetqgY9bhyqql9H/gDejRoHDz2UmyTuuccSR/XqoYbkovHrr3b28PLLdv2yy+Dqqz1JuKQVzTv38nxuu6KsA3E72rrVyvwAjBwJd98dbjwuClu3WuneZs1g1iyoVi3siJwrE4X1UVyIrUrXQEQ+ithUFViT/71cWXvgATjFi7onvilTrAz4L7/YlPmnn4Z99r+l7+wAAB5aSURBVAk7KufKRGF9FBOBldha189G3L4WmBLLoNLd/PnQv3/YUbhiWbrUOpCGDIEOHcKOxrkyVWCiUNV5wDysWqyLoyOOgL//tsuNGoUbiyvE6NFW4/3aa62I3+zZsNtuYUflXJkrsI9CRL4Nfq8WkVURP6tFZFX8Qkwv69dbkjjwQMjKspGVLsH8/bdVeD3pJGtiyini50nCpajCOrNzWsZrADUjfnKuuxj44gv73aYNlC8fbiwuH8OHw2GHwYsv2gQ6L+Ln0kBhw2NzZmMfAJRX1WzgGOCfQJU4xJaWvv7aft94Y7hxuHwsXGj9D9Wqwfffw+OP2xKlzqW4aIbHDsGWQW0IvIHNoXgnplGlqUmT4Nlg2ECNGuHG4gKqMH68XT7gADvl+/FHq9fkXJqIJlFsU9WtwHnAk6p6PVA7tmGln3HjbIlkgOefh333DTceh1Vh7NgRjjkmt4jfKadAhQrhxuVcnEWTKLJE5AKgK/BJcNuusQsp/WzdCqefbpd79YKePcONJ+2pWk2mJk3sDOKxx7yIn0tr0VSPvRy4BiszPldEGgADYxtW+ti61Zq8N260PtEXXww7Isf558NHH9mopgEDbGEh59JYkYlCVaeJyA3AQSJyCDBbVR+MfWipT9W+tG7cCPvvDz/9FHZEaSyyiF/HjnaKd+WVXp/JOaJb4e4EYDbwMvAK8JuI+Hl4GWjb1uZoVa1qScIrPoRk2jRrWsop4te1q1d6dS5CNP8JfYGzVPU4VT0WOBt4KrZhpYdff7XfU6d6kgjFli1Wnrd5c5gzB/baK+yInEtI0fRRVFDVGTlXVPVXEfFhH6UwfTo0bWqXe/aEevXCjSct/fCDFfGbNg0uvhiefBJq+jxS5/ITTaL4UUReBN4Mrl+CFwUslZxRTVWrQu/e4caStlauhDVrYNgwaN8+7GicS2jRJIqrgBuAfwECjAaeiWVQqerPP6FWLbtcvz7MmxdqOOln1Chr57vhBuus/v13qFQp7KicS3iFJgoRORxoCAxW1UfjE1JqWrcuN0k0bmyT6lyc/PUX/Otf8NJLcMgh1lFdsaInCeeiVFj12H9j5TsuAb4UkfxWunNR2Lo1t5+0cWPrxD711HBjShvDhtkY5AED4JZbrG/Ci/g5VyyFnVFcAhyhqutFpCYwHBse64ph2zZr6cjKsuvTp/uoy7hZuBA6dbKziCFD4Oijw47IuaRUWKLYrKrrAVR1uYj4x1sxqULt2rBkiV1fuRJ2iaZXyJWcqhXOOvbY3CJ+xx7r9ZmcK4XCPvwPFJGPgp/BQMOI6x8Vcr/tRKSdiMwSkdkicnsh+50vIioiGcV9AYnqr7+gRYvcJDF1Kuy9d7gxpbzMTDj3XJs8l1PE7+STPUk4V0qFfb/tlOd6v+I8sIiUx9babgtkApNEZGjknIxgv6rYqKoJxXn8RLZhA+y5Z+71qVNz5024GNi2zRYZv/VWa+N74gk4/viwo3IuZRS2ZvbXpXzsllhdqLkAIjII6ADMyLPf/cCjwC2lfL6EkXMWUbeuDYH1PokY69TJ+iBOPdUSxoEHhh2Rcykllh9htYGFEdczybOOhYgcBRygqp9QCBHpJSKTRWTy8uXLyz7SMpYz9PX++z1JxExWlp1JgCWK/v3hq688STgXA7H8GJN8btPtG61zvC/Qp6gHUtWXVDVDVTNqJniZhc2bbfkC8CGwMfPLL7aYUP/+dv3SS226u+T3lnPOlVbUiUJEijv4PBNbbztHHWBxxPWqQFPgGxH5A2gNDE3mDm1VOO00u9yjB9SpE248KWfzZrj7bhslMH++12ZyLk6iKTPeUkSmAr8H148UkWhKeEwCGolIg6CIYBdgaM5GVf1LVWuoan1VrQ+MB85V1ckleSGJ4PLLYcwYu3zrreHGknImTbIqr/fdBxddZLMWzzsv7KicSwvRjOp/GmiPzdJGVX8WkVOKupOqZonIdcAIoDzwiqpOF5H7gMmqOrTwR0guK1bAa6/Z5aVLvWx4mVu92uqgDB8OZ54ZdjTOpZVoEkU5VZ0vO7b/Zkfz4Ko6HJvRHXnbXQXse3I0j5mIfvsNDj7YLt96qyeJMjNypI0tvvFGK+L3229efsO5EETTR7FQRFoCKiLlRaQ38FuM40oan3+emyTuugse9dKJpbdmjS1D2qaNLSK+ebPd7knCuVBEkyiuBm4G6gJLsU7nq2MZVLIYMiS3FeS226yf1ZXSxx9bEb9XXrGKr17Ez7nQFdn0pKrLsI5oF9i40VbQfOQRu37XXXbdldKCBXDBBXDooTB0KGQk7QA451JKkYlCRPoTMf8hh6r2iklECe7LL625PMeff8J++4UXT9JTtaFiJ5xgU9m/+gpat/b6TM4lkGianr4Cvg5+xgL7AJtjGVSieu213CRx440wZ44niVJZsADOPhtOPDG3iN+JJ3qScC7BRNP09G7kdRF5E/gyZhElqA0b4Lrr7PL558OTT4YbT1Lbtg1eeME6dlTh6ae9iJ9zCawkqyM0AOqVdSCJbsoUWL8e+vWDa68NO5okd9551mndtq0tT1q/ftgROecKEU0fxWpy+yjKAauAAteWSHWNG4cdQZLKyrIKieXKwYUXQocO0L2712dyLgkUmijEZtkdCSwKbtqmqjt1bDtXqJ9/tvomV14JV11lJTicc0mj0M7sICkMVtXs4Cdtk8TGjfbbvwAXw6ZN8J//2DDXzEzv+XcuSUUz6mmiiDSPeSQJ7sUXoUoVK1zqojBxIhx1FDz4IFxyiRXx69gx7KiccyVQYNOTiOyiqlnA8cCVIjIHWI+tM6GqmjbJY/Bg+OADW4hor73CjiZJ/P23nYZ9/jmccUbY0TjnSqGwPoqJQHMg7b8GDhsGNWrA7WnbhR+lL76A6dPhpptsYY5Zs7z8hnMpoLBEIQCqOidOsSS03XaDXUoymDgdrF4NN99sMxIPOwyuucYShCcJ51JCYR99NUXk5oI2quoTMYgn4WzZAj/9ZInC5eOjj2xiyfLlcMcdVvjKE4RzKaWwRFEe2J38175OG7fdZpPt3nsv7EgS0IIF0KULNG1qCwoddVTYETnnYqCwRPGnqt4Xt0gS0EcfWamO66+3oqYOK7kxejScdJIV8Rs5Elq1gl13DTsy51yMFDY8Nq3PJNavt/lhRx8Njz0WdjQJYv58W4Dj5JNzi/gdf7wnCedSXGFnFG3iFkUCev11WLXKRjylfTHTbdvguedyh30984yVBXfOpYUCE4WqropnIIlk2zZ46ik7mzjmmLCjSQAdO1rGPOMMm3lYL+1qQjqX1nzAZz4+/xx++w3efjuNS3Zs3Qrly1sRv4sustrqXbum8QFxLn1FU8Ij7fTtC7VqpXEH9o8/QsuWtmYEWKK47DJPEs6lKU8UeUybZqtxXnddGvbRbtxocyFatoQlS+CAA8KOyDmXALzpKY+nnrLJdb3SbUXw8eOhWzdrc7v8chvq5YWtnHN4otjB8uXw5pu2nk716mFHE2fr11u/xJdfWp0m55wLeKKI8OKLsHkz3HBD2JHEyeefWxG/Pn2gTRuYOdPHAjvnduJ9FIEtW+DZZ20EaJMmYUcTYytXWjPTmWfahJEtW+x2TxLOuXx4ogi8+6713950U9iRxJCqLazRpAm8846tPjdpkicI51yhvOkJ+/zs2xcOPRROPz3saGJowQK4+GI44ghbO+LII8OOyDmXBPyMAhgzxirE3nhjCk4VULXCfWAzqr/5xkY4eZJwzkXJEwV2NrH33jbxOKXMm2enSG3a5BbxO/ZYX4HJOVcsaZ8o5s6FIUPgn/+EypXDjqaMZGfbhJCmTWHCBHj+eS/i55wrsbT/atmvn5U0uvbasCMpQx06wKefwllnWRkOn2HtnCuFtE4Uf/8NAwZA585Qu3bY0ZRSZBG/rl2tPtPFF6dgp4tzLt5i2vQkIu1EZJaIzBaR2/PZfrOIzBCRX0TkaxGJa/3qV1+FtWutEzupTZ4MGRnWxARw4YVwySWeJJxzZSJmiUJEygPPAmcCTYCLRCTvVLYpQIaqHgF8ADwaq3jyys6Gp5+2vt2WLeP1rGVs40Zb1LtVK6s/4utEOOdiIJZnFC2B2ao6V1W3AIOADpE7qOooVd0QXB0P1IlhPDv45BPryE7aCXbjxtkQ10cftSJ+M2ZA+/ZhR+WcS0Gx7KOoDSyMuJ4JtCpk/yuAz/LbICK9gF4AdevWLZPg+vaFunVt8baktHGjLcX31Vc2/NU552IklmcU+TWQa747ilwKZAD/y2+7qr6kqhmqmlGzZs1SBzZlik0ruP76JJtSMHw4/C84RKeeCr/+6knCORdzsUwUmUDkuMw6wOK8O4nIacCdwLmqujmG8Wz31FNQpQr07BmPZysDK1bApZfC2Wfb+qw5RfzSbmUl51wYYpkoJgGNRKSBiFQAugBDI3cQkaOAF7EksSyGsWy3ZAkMHAg9esCee8bjGUtBFQYNsiJU770Hd98NEyd6ET/nXFzFrOFFVbNE5DpgBFAeeEVVp4vIfcBkVR2KNTXtDrwvNpRzgaqeG6uYwEaQbt2aJGtOLFhg5cCPPBJefhkOPzzsiJxzaUhU8+02SFgZGRk6efLkEt130ybrwG7dGoYOLXr/UKjC11/nrjI3fjwcfbRNpnPOuRISkR9UNaMk902rWk/vvGPTDXr3DjuSAsyZY53TbdvmFvFr3dqThHMuVGmTKFThySdtKYZTTgk7mjyys+GJJ6xp6YcfbE1WL+LnnEsQyTQ4tFRGjYKpU+GVVxKwssU558Bnn9mEueefhzpxm3fonHNFSptE0bcv1KxptfISwpYtNomjXDno3t0K+XXpkoBZzDmX7tKi6en3361kx9VXQ6VKYUeDDXFt0QKee86ud+5sGcyThHMuAaVFonj6aZt6cPXVIQeyYQP06QPHHAOrV0PDhiEH5JxzRUv5pqc1a6yc+EUXwX77hRjImDE2J2LuXFtO75FHoFq1EANyzrnopHyiGDAA1q9PgCGxOQsLjRoFJ58ccjDOORe9lE4UWVnwzDP2udysWQgBDBtmhfv+9S8bkztjRpJVIXTOuRTvoxgyxKpgxP1sYvlyW4b03HOtsFROET9PEs65JJTSiaJvXzjwwDiu56Nq078PPRQ++ADuuw8mTPAifs65pJayX3EnToTvv7eS4nGrgLFggZWlPeooK+J32GFxemLnnIudlD2jeOop2GMP+9yOqW3bYMQIu1yvHnz3HYwd60nCOZcyUjJRLFpkyzdccQVUrRrDJ/r9d1tprl07GD3abmvZ0ov4OedSSkomimeftS/6118foyfIyrIlSY84An76yZqZvIifcy5FpVwfxYYNVny1Y0do0CBGT9K+vTU3dehgZThq1YrREzmX3LZu3UpmZiabNm0KO5S0UalSJerUqcOuZbhUcsolijffhFWrYjAkdvNmW6O6XDlbbPvyy+GCC7w+k3OFyMzMpGrVqtSvXx/x/5WYU1VWrlxJZmYmDcrwm3JKNT1t22ZrTrRoAccfX4YPPH48NG9ubVoA559vhfz8je9coTZt2kT16tU9ScSJiFC9evUyP4NLqUTx5Zcwc6adTZTJ+3L9erjpJjj2WFi7Fho1KoMHdS69eJKIr1gc75RqeurbF/bf377sl9p331kRv3nz4Jpr4KGHbLytc86lmZQ5o5gxw/qXr722jCZCZ2VZn8S331qTkycJ55LW4MGDERFmzpy5/bZvvvmG9nnKNnTv3p0PPvgAsI7422+/nUaNGtG0aVNatmzJZ599VupYHnroIQ466CAOPvhgRuTMwcrjhBNOoFmzZjRr1oxatWrRsWPHHbZPmjSJ8uXLb4811lLmjOLpp21Rol69SvEgQ4ZYEb877rAiftOne30m51LAwIEDOf744xk0aBD33HNPVPf573//y59//sm0adOoWLEiS5cu5dtvvy1VHDNmzGDQoEFMnz6dxYsXc9ppp/Hbb79RPs/cq++++2775U6dOtGhQ4ft17Ozs7nttts444wzShVLcaTEp+DKlfDGG3DppbbcabEtXWqTLt5/3zqt+/Sx0xJPEs6Vmd69bdpRWWrWzAawFGbdunWMHTuWUaNGce6550aVKDZs2ED//v2ZN28eFStWBGDfffelcynbtT/++GO6dOlCxYoVadCgAQcddBATJ07kmGOOyXf/tWvXMnLkSF599dXttz3zzDN06tSJSZMmlSqW4kiJpqeXXoKNG0swJFbVxtM2aQIffwwPPmgjnLyIn3MpY8iQIbRr147GjRuz99578+OPPxZ5n9mzZ1O3bl32iKLJ+aabbtreTBT58/DDD++076JFizjggAO2X69Tpw6LFi0q8LEHDx5MmzZttsexaNEiBg8ezFVXXVVkXGUp6b8yb90K/fpB27YlKK+0YIHNicjIsNnVhxwSkxidc0V/84+VgQMH0jv4FtmlSxcGDhxI8+bNCxwdVNxRQ3379o16X1Ut1vMNHDiQnj17br/eu3dvHnnkkZ2aqmIt6RPF++/D4sXQv3+Ud8gp4nfmmVbEb+xYq/bq9ZmcSzkrV65k5MiRTJs2DREhOzsbEeHRRx+levXqrF69eof9V61aRY0aNTjooINYsGABa9eupWoRBeNuuukmRo0atdPtXbp04fbbb9/htjp16rBw4cLt1zMzM6lVQGWHlStXMnHiRAYPHrz9tsmTJ9OlSxcAVqxYwfDhw9lll1126uwuc6qaVD8tWrTQHNu2qWZkqB58sGp2thZt1izVE05QBdVvvoniDs650pgxY0aoz//CCy9or169drjtxBNP1NGjR+umTZu0fv3622P8448/tG7durpmzRpVVb311lu1e/fuunnzZlVVXbx4sb755pulimfatGl6xBFH6KZNm3Tu3LnaoEEDzcrKynff559/Xi+77LICH6tbt276/vvv57stv+MOTNYSfu4mdR/FuHEweTLceKNV1ihQVhY88ogV8Zs6FV59FU48MW5xOufCMXDgQP7xj3/scFunTp145513qFixIm+99RY9evSgWbNmnH/++QwYMIBq1aoB8MADD1CzZk2aNGlC06ZN6dixIzVLNFom12GHHUbnzp1p0qQJ7dq149lnn93ejHTWWWexePHi7fsOGjSIiy66qFTPV1ZE82kzS2QZGRk6efJkwCbWffUVLFwIVaoUcqczzoAvvoDzzrM5EfvtF59gnUtzv/76K4ceemjYYaSd/I67iPygqhklebykPaOYPx8+/NDmTeSbJDZtguxsu9yrly1N+uGHniScc66YkjZR9Otn9ZyuvTafjWPH2gDrnCJ+nTrZj3POuWJLykSxbp2Ncjr/fIgYkmwbbrjBFhHatAn8lNe50CVb83ayi8XxTspE8dpr8NdfVth1u2+/haZN7VTjuutg2jSbXOGcC02lSpVYuXKlJ4s40WA9ikqVKpXp4yblPIqnnoLWraFVqzwbKle2qq/HHRdKXM65HdWpU4fMzEyWL18edihpI2eFu7KUdKOeGjXK0NmzJzNoEFy460e2AMW//20bs7N94pxzzuUjYUc9iUg7EZklIrNF5PZ8tlcUkXeD7RNEpH5Rj7l0KTSvtYQL3jvfOqgHD4YtW2yjJwnnnCtzMUsUIlIeeBY4E2gCXCQiTfLsdgWwWlUPAvoCjxT1uBXWrmTs6kMp9+kntpjQ9997ET/nnIuhWJ5RtARmq+pcVd0CDAI65NmnA/B6cPkDoI0UUZGrHvMpf2RT+PlnuP12W1zIOedczMSyM7s2sDDieiaQt/t5+z6qmiUifwHVgRWRO4lILyBnSaLNFcaPmeaVXgGoQZ5jlcb8WOTyY5HLj0Wug0t6x1gmivzODPL2nEezD6r6EvASgIhMLmmHTKrxY5HLj0UuPxa5/FjkEpHJJb1vLJueMoHI6XB1gMUF7SMiuwDVgFUxjMk551wxxTJRTAIaiUgDEakAdAGG5tlnKNAtuHw+MFKTbbyuc86luJg1PQV9DtcBI4DywCuqOl1E7sPqog8FXgbeFJHZ2JlElyge+qVYxZyE/Fjk8mORy49FLj8WuUp8LJJuwp1zzrn4SspaT8455+LHE4VzzrlCJWyiiEX5j2QVxbG4WURmiMgvIvK1iNQLI854KOpYROx3voioiKTs0MhojoWIdA7eG9NF5J14xxgvUfyP1BWRUSIyJfg/OSuMOGNNRF4RkWUiMq2A7SIiTwfH6RcRaR7VA5d0se1Y/mCd33OAA4EKwM9Akzz7XAO8EFzuArwbdtwhHotTgMrB5avT+VgE+1UFRgPjgYyw4w7xfdEImALsFVzfJ+y4QzwWLwFXB5ebAH+EHXeMjsWJQHNgWgHbzwI+w+awtQYmRPO4iXpGEZPyH0mqyGOhqqNUdUNwdTw2ZyUVRfO+ALgfeBTYFM/g4iyaY3El8KyqrgZQ1WVxjjFeojkWCuwRXK7GznO6UoKqjqbwuWgdgDfUjAf2FJH9i3rcRE0U+ZX/qF3QPqqaBeSU/0g10RyLSFdg3xhSUZHHQkSOAg5Q1U/iGVgIonlfNAYai8hYERkvIu3iFl18RXMs7gEuFZFMYDhwfXxCSzjF/TwBEnfhojIr/5ECon6dInIpkAGcFNOIwlPosRCRclgV4u7xCihE0bwvdsGan07GzjK/E5GmqromxrHFWzTH4iLgNVV9XESOweZvNVXVbbEPL6GU6HMzUc8ovPxHrmiOBSJyGnAncK6qbo5TbPFW1LGoCjQFvhGRP7A22KEp2qEd7f/Ix6q6VVXnAbOwxJFqojkWVwDvAajqOKASVjAw3UT1eZJXoiYKL/+Rq8hjETS3vIgliVRth4YijoWq/qWqNVS1vqrWx/przlXVEhdDS2DR/I8MwQY6ICI1sKaouXGNMj6iORYLgDYAInIolijScX3WocBlwein1sBfqvpnUXdKyKYnjV35j6QT5bH4H7A78H7Qn79AVc8NLegYifJYpIUoj8UI4HQRmQFkA7eq6srwoo6NKI9FH6C/iNyENbV0T8UvliIyEGtqrBH0x9wN7Aqgqi9g/TNnAbOBDUCPqB43BY+Vc865MpSoTU/OOecShCcK55xzhfJE4ZxzrlCeKJxzzhXKE4VzzrlCeaJwCUdEskXkp4if+oXsW7+gSpnFfM5vguqjPwclLw4uwWNcJSKXBZe7i0itiG0DRKRJGcc5SUSaRXGf3iJSubTP7dKXJwqXiDaqarOInz/i9LyXqOqRWLHJ/xX3zqr6gqq+EVztDtSK2NZTVWeUSZS5cT5HdHH2BjxRuBLzROGSQnDm8J2I/Bj8HJvPPoeJyMTgLOQXEWkU3H5pxO0vikj5Ip5uNHBQcN82wRoGU4Na/xWD2x+W3DVAHgtuu0dEbhGR87GaW28Hz7lbcCaQISJXi8ijETF3F5FnShjnOCIKuonI8yIyWWztiXuD227AEtYoERkV3Ha6iIwLjuP7IrJ7Ec/j0pwnCpeIdotodhoc3LYMaKuqzYELgafzud9VwFOq2gz7oM4MyjVcCBwX3J4NXFLE858DTBWRSsBrwIWqejhWyeBqEdkb+AdwmKoeATwQeWdV/QCYjH3zb6aqGyM2fwCcF3H9QuDdEsbZDivTkeNOVc0AjgBOEpEjVPVprJbPKap6SlDK4z/AacGxnAzcXMTzuDSXkCU8XNrbGHxYRtoV6Be0yWdjdYvyGgfcKSJ1gI9U9XcRaQO0ACYF5U12w5JOft4WkY3AH1gZ6oOBear6W7D9deBaoB+21sUAEfkUiLqkuaouF5G5QZ2d34PnGBs8bnHirIKVq4hcoayziPTC/q/3xxbo+SXPfVsHt48NnqcCdtycK5AnCpcsbgKWAkdiZ8I7LUqkqu+IyATgbGCEiPTEyiq/rqp3RPEcl0QWEBSRfNc3CWoLtcSKzHUBrgNOLcZreRfoDMwEBquqin1qRx0ntorbw8CzwHki0gC4BThaVVeLyGtY4bu8BPhSVS8qRrwuzXnTk0sW1YA/g/UDumLfpncgIgcCc4PmlqFYE8zXwPkisk+wz94S/ZriM4H6InJQcL0r8G3Qpl9NVYdjHcX5jTxai5U9z89HQEdsjYR3g9uKFaeqbsWakFoHzVZ7AOuBv0RkX+DMAmIZDxyX85pEpLKI5Hd25tx2nihcsngO6CYi47Fmp/X57HMhME1EfgIOwZZ8nIF9oH4hIr8AX2LNMkVS1U1Ydc33RWQqsA14AfvQ/SR4vG+xs528XgNeyOnMzvO4q4EZQD1VnRjcVuw4g76Px4FbVPVnbH3s6cArWHNWjpeAz0RklKoux0ZkDQyeZzx2rJwrkFePdc45Vyg/o3DOOVcoTxTOOecK5YnCOedcoTxROOecK5QnCuecc4XyROGcc65Qniicc84V6v8BBM0+ON7Y9BEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph_roc(y_test.to_numpy(), test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I obtained an AUC in the test data for this model of 0.74 that is wors that the one obtained woth neural networks but was much better than the one obtaine with XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted linear-learner-2020-11-12-19-40-43-979\n"
     ]
    }
   ],
   "source": [
    "delete_endpoint(linear_predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally I create a last model, a SVM with rbf kernel. As in XGBoost I decided to tune hyperparameters witj cross-validation with sklearn package locally wothout the use of SageMaker.\n",
    "\n",
    "In this case I decided to change the values of C and gamma,changing them with log steps. The possible values that can take this parameters can be seen in the next cell. This model uses the Bag of words method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_range = np.logspace(-2, 1, 3)\n",
    "C_range = np.logspace(-2, 1, 3)\n",
    "todos_scores=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I created the grid search and the CV for the model in order of finding the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "lista={}\n",
    "output = pd.DataFrame()\n",
    "for c in C_range:\n",
    "    for gamma in gamma_range:\n",
    "        clf = svm.SVC(kernel='rbf', C=c, gamma=gamma, max_iter=1000).fit(Xtrain, y_train)\n",
    "        scores = cross_val_score(clf, Xtrain, y_train, cv=3,scoring='roc_auc')\n",
    "        lista.update({'AUC Promedio':np.mean(scores), 'AUC SDV':np.std(scores),'C':c,'Gamma':gamma})\n",
    "        output=output.append(lista, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados CV: 1\n",
      "   AUC Promedio   AUC SDV          C      Gamma\n",
      "0      0.641110  0.015556   0.010000   0.010000\n",
      "1      0.709707  0.013768   0.010000   0.316228\n",
      "2      0.655971  0.010059   0.010000  10.000000\n",
      "3      0.659094  0.009428   0.316228   0.010000\n",
      "4      0.740701  0.010111   0.316228   0.316228\n",
      "5      0.658891  0.009728   0.316228  10.000000\n",
      "6      0.748458  0.007049  10.000000   0.010000\n",
      "7      0.724706  0.002430  10.000000   0.316228\n",
      "8      0.638756  0.011864  10.000000  10.000000\n"
     ]
    }
   ],
   "source": [
    "print('Resultados CV: '+ str(1))\n",
    "print(output)\n",
    "mejorauc=max(output['AUC Promedio'])\n",
    "mejorc=list(output['C'][output['AUC Promedio'].isin([max(output['AUC Promedio'])])])[0]\n",
    "mejorgamma=list(output['Gamma'][output['AUC Promedio'].isin([max(output['AUC Promedio'])])])[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case the best C was 10 and the best gamma 0.1.\n",
    "\n",
    "I decided to create a Sagemaker model of SKLearn with those hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "# specify an output path\n",
    "prefix = 'SVM'\n",
    "\n",
    "# import a sklearn wrapper\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "role = sagemaker.get_execution_role()\n",
    "# specify an output path\n",
    "output_path='s3://{}/{}'.format(bucket,prefix)\n",
    "\n",
    "# instantiate a SKLearn estimator\n",
    "estimator = SKLearn(entry_point='train.py',\n",
    "                    source_dir='train_sl',\n",
    "                    role=role,\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type='ml.c4.xlarge',\n",
    "                    framework_version='0.20.0',\n",
    "                    output_path=output_path, # specified, above\n",
    "                    sagemaker_session=sagemaker_session,\n",
    "                    hyperparameters={\n",
    "                        'gamma':mejorgamma,\n",
    "                        'Creg':mejorc\n",
    "                    }\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data_svm = 'Data//SVM'\n",
    "pd.concat([y_train, pd.DataFrame(Xtrain)], axis=1).to_csv(os.path.join(data_svm, 'train.csv'), header=False, index=False)\n",
    "pd.DataFrame(Xtest).to_csv(os.path.join(data_svm, 'test.csv'), header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set prefix, a descriptive name for a directory  \n",
    "prefix = 'twitter_svm'\n",
    "\n",
    "data = sagemaker_session.upload_data(path=data_svm, bucket=bucket, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I train and deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-13 21:58:01 Starting - Starting the training job...\n",
      "2020-11-13 21:58:03 Starting - Launching requested ML instances......\n",
      "2020-11-13 21:59:07 Starting - Preparing the instances for training...\n",
      "2020-11-13 21:59:56 Downloading - Downloading input data......\n",
      "2020-11-13 22:00:46 Training - Training image download completed. Training in progress.\u001b[34m2020-11-13 22:00:46,419 sagemaker-training-toolkit INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2020-11-13 22:00:46,421 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-11-13 22:00:46,430 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-11-13 22:00:46,634 botocore.utils INFO     IMDS ENDPOINT: http://169.254.169.254/\u001b[0m\n",
      "\u001b[34m2020-11-13 22:00:46,781 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-11-13 22:00:48,228 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-11-13 22:00:48,240 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-11-13 22:00:48,250 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"Creg\": 10.0,\n",
      "        \"gamma\": 0.01\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-scikit-learn-2020-11-13-21-58-01-563\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-428747017283/sagemaker-scikit-learn-2020-11-13-21-58-01-563/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"Creg\":10.0,\"gamma\":0.01}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-428747017283/sagemaker-scikit-learn-2020-11-13-21-58-01-563/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"Creg\":10.0,\"gamma\":0.01},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2020-11-13-21-58-01-563\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-428747017283/sagemaker-scikit-learn-2020-11-13-21-58-01-563/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--Creg\",\"10.0\",\"--gamma\",\"0.01\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_CREG=10.0\u001b[0m\n",
      "\u001b[34mSM_HP_GAMMA=0.01\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python train.py --Creg 10.0 --gamma 0.01\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\u001b[0m\n",
      "\n",
      "2020-11-13 22:08:36 Uploading - Uploading generated training model\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/numpy_pickle.py:104: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/numpy_pickle.py:104: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/numpy_pickle.py:104: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/numpy_pickle.py:104: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/numpy_pickle.py:104: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/numpy_pickle.py:104: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/numpy_pickle.py:104: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/numpy_pickle.py:104: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/numpy_pickle.py:104: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/numpy_pickle.py:104: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/numpy_pickle.py:104: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/numpy_pickle.py:104: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/numpy_pickle.py:104: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/numpy_pickle.py:104: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/numpy_pickle.py:104: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/numpy_pickle.py:104: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/numpy_pickle.py:104: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/numpy_pickle.py:104: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/numpy_pickle.py:104: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/numpy_pickle.py:104: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/numpy_pickle.py:104: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  pickler.file_handle.write(chunk.tostring('C'))\u001b[0m\n",
      "\u001b[34m2020-11-13 22:08:33,641 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-11-13 22:08:42 Completed - Training job completed\n",
      "Training seconds: 526\n",
      "Billable seconds: 526\n",
      "CPU times: user 1.5 s, sys: 50.6 ms, total: 1.55 s\n",
      "Wall time: 11min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Train your estimator on S3 training data\n",
    "estimator.fit({'train': data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!CPU times: user 297 ms, sys: 18.5 ms, total: 316 ms\n",
      "Wall time: 7min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# uncomment, if needed\n",
    "# from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "\n",
    "# deploy your model to create a predictor\n",
    "predictor = estimator.deploy(initial_instance_count=1,instance_type='ml.t2.medium')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally I test the model with the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import csv_serializer\n",
    "predictor.serializer = csv_serializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictsvm(data, rows=512):\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = []\n",
    "    for array in split_array:\n",
    "        predictions =predictions + list(predictor.predict(array))\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The csv_serializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The csv_serializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The csv_serializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "test_X = pd.read_csv(os.path.join(data_svm, 'test.csv'), header=None).values\n",
    "\n",
    "predictions = predictsvm(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted sagemaker-pytorch-2020-11-15-00-24-03-321\n"
     ]
    }
   ],
   "source": [
    "delete_endpoint(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='rbf', C=mejorc, gamma=mejorgamma, max_iter=10000, probability=True).fit(Xtrain, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "yres=clf.predict_proba(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_auc=yres[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7979644793483585"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import sklearn.metrics as metrics\n",
    "roc_auc_score(y_test.to_numpy(), y_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph_roc(y_test.to_numpy(), y_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "resul=clf.predict(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I got an AUC of 0.8 and a good ROC curve. This model got the best AUC of all the models proven, however it was almost the same that the one obtained with neural networks, the small difference can be explained for the randomness in the training of models, so we can conclude that both models have a similar performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order of simplify a little the chosen model, and taken ito account that the Pytorch model and SVM get similar results in the AUC metric, the selected model to deploy in the application will be the Pytorch model.\n",
    "The Pytorch model was selected over the SVM model basically because it can use GPU so is fastest to train, and second because it does not require the variables of sentiment, emojis or spelling, that could be difficult to obtain in the deployed model and get the model more complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I will train and deploy again the Pytorch model with the best found parameters\n",
    "import sagemaker\n",
    "data_dir='Data//FinalData'\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'sagemaker/twitter_final_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-14 21:40:18 Starting - Starting the training job...\n",
      "2020-11-14 21:40:21 Starting - Launching requested ML instances......\n",
      "2020-11-14 21:41:23 Starting - Preparing the instances for training......\n",
      "2020-11-14 21:42:42 Downloading - Downloading input data...\n",
      "2020-11-14 21:43:11 Training - Downloading the training image....\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-11-14 21:43:51,166 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-11-14 21:43:51,192 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-11-14 21:43:51,195 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-11-14 21:43:51,435 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-11-14 21:43:51,435 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-11-14 21:43:51,435 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-11-14 21:43:51,436 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pip install -U . -r requirements.txt\u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mCollecting pandas (from -r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34m  Downloading https://files.pythonhosted.org/packages/74/24/0cdbf8907e1e3bc5a8da03345c23cbed7044330bb8f73bb12e711a640a00/pandas-0.24.2-cp35-cp35m-manylinux1_x86_64.whl (10.0MB)\u001b[0m\n",
      "\u001b[34mCollecting numpy (from -r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/b5/36/88723426b4ff576809fec7d73594fe17a35c27f8d01f93637637a29ae25b/numpy-1.18.5-cp35-cp35m-manylinux1_x86_64.whl (19.9MB)\u001b[0m\n",
      "\u001b[34mCollecting nltk (from -r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\u001b[0m\n",
      "\u001b[34mCollecting beautifulsoup4 (from -r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/41/e6495bd7d3781cee623ce23ea6ac73282a373088fcd0ddc809a047b18eae/beautifulsoup4-4.9.3-py3-none-any.whl (115kB)\u001b[0m\n",
      "\u001b[34mCollecting html5lib (from -r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/6c/dd/a834df6482147d48e225a49515aabc28974ad5a4ca3215c18a882565b028/html5lib-1.1-py2.py3-none-any.whl (112kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /usr/local/lib/python3.5/dist-packages (from pandas->-r requirements.txt (line 1)) (2.7.5)\u001b[0m\n",
      "\u001b[34mCollecting pytz>=2011k (from pandas->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/12/f8/ff09af6ff61a3efaad5f61ba5facdf17e7722c4393f7d8a66674d2dbd29f/pytz-2020.4-py2.py3-none-any.whl (509kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.5/dist-packages (from nltk->-r requirements.txt (line 3)) (7.0)\u001b[0m\n",
      "\u001b[34mCollecting joblib (from nltk->-r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/28/5c/cf6a2b65a321c4a209efcdf64c2689efae2cb62661f8f6f4bb28547cf1bf/joblib-0.14.1-py2.py3-none-any.whl (294kB)\u001b[0m\n",
      "\u001b[34mCollecting regex (from nltk->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34m  Downloading https://files.pythonhosted.org/packages/2e/e4/3447fed9ab29944333f48730ecff4dca92f0868c5b188d6ab2b2078e32c2/regex-2020.11.13.tar.gz (694kB)\u001b[0m\n",
      "\u001b[34mCollecting tqdm (from nltk->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34m  Downloading https://files.pythonhosted.org/packages/93/3a/96b3dc293aa72443cf9627444c3c221a7ba34bb622e4d8bf1b5d4f2d9d08/tqdm-4.51.0-py2.py3-none-any.whl (70kB)\u001b[0m\n",
      "\u001b[34mCollecting soupsieve>1.2; python_version >= \"3.0\" (from beautifulsoup4->-r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/6f/8f/457f4a5390eeae1cc3aeab89deb7724c965be841ffca6cfca9197482e470/soupsieve-2.0.1-py3-none-any.whl\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: six>=1.9 in /usr/local/lib/python3.5/dist-packages (from html5lib->-r requirements.txt (line 5)) (1.11.0)\u001b[0m\n",
      "\u001b[34mCollecting webencodings (from html5lib->-r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/f4/24/2a3e3df732393fed8b3ebf2ec078f05546de641fe1b667ee316ec1dcf3b7/webencodings-0.5.1-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: nltk, train, regex\n",
      "  Running setup.py bdist_wheel for nltk: started\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for nltk: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n",
      "  Running setup.py bdist_wheel for train: started\n",
      "  Running setup.py bdist_wheel for train: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-faebet3r/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\n",
      "  Running setup.py bdist_wheel for regex: started\u001b[0m\n",
      "\n",
      "2020-11-14 21:43:50 Training - Training image download completed. Training in progress.\u001b[34m  Running setup.py bdist_wheel for regex: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/27/f6/66/a4243e485a0ebc73dc59033ae26c48e82526f77dbfe158ac59\u001b[0m\n",
      "\u001b[34mSuccessfully built nltk train regex\u001b[0m\n",
      "\u001b[34mInstalling collected packages: numpy, pytz, pandas, joblib, regex, tqdm, nltk, soupsieve, beautifulsoup4, webencodings, html5lib, train\n",
      "  Found existing installation: numpy 1.15.4\n",
      "    Uninstalling numpy-1.15.4:\u001b[0m\n",
      "\u001b[34m      Successfully uninstalled numpy-1.15.4\u001b[0m\n",
      "\u001b[34mSuccessfully installed beautifulsoup4-4.9.3 html5lib-1.1 joblib-0.14.1 nltk-3.5 numpy-1.18.5 pandas-0.24.2 pytz-2020.4 regex-2020.11.13 soupsieve-2.0.1 tqdm-4.51.0 train-1.0.0 webencodings-0.5.1\u001b[0m\n",
      "\u001b[34mYou are using pip version 18.1, however version 20.3b1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-11-14 21:44:15,298 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"network_interface_name\": \"eth0\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ]\n",
      "    },\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-14-21-40-18-359/source/sourcedir.tar.gz\",\n",
      "    \"user_entry_point\": \"train.py\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"job_name\": \"sagemaker-pytorch-2020-11-14-21-40-18-359\",\n",
      "    \"hyperparameters\": {\n",
      "        \"hidden_dim\": 100,\n",
      "        \"epochs\": 50\n",
      "    },\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"log_level\": 20,\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"num_gpus\": 1,\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"output_dir\": \"/opt/ml/output\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=50\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":50,\"hidden_dim\":100}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN_DIM=100\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/lib/python35.zip:/usr/lib/python3.5:/usr/lib/python3.5/plat-x86_64-linux-gnu:/usr/lib/python3.5/lib-dynload:/usr/local/lib/python3.5/dist-packages:/usr/lib/python3/dist-packages\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"50\",\"--hidden_dim\",\"100\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":50,\"hidden_dim\":100},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"job_name\":\"sagemaker-pytorch-2020-11-14-21-40-18-359\",\"log_level\":20,\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-14-21-40-18-359/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-428747017283/sagemaker-pytorch-2020-11-14-21-40-18-359/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m train --epochs 50 --hidden_dim 100\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing device cuda.\u001b[0m\n",
      "\u001b[34mGet train data loader.\u001b[0m\n",
      "\u001b[34mModel loaded with embedding_dim 35, hidden_dim 100, vocab_size 5000.\u001b[0m\n",
      "\u001b[34mEpoch: 1, BCELoss: 0.6642252640290693\u001b[0m\n",
      "\u001b[34mEpoch: 2, BCELoss: 0.4591620862483978\u001b[0m\n",
      "\u001b[34mEpoch: 3, BCELoss: 0.23430134897882288\u001b[0m\n",
      "\u001b[34mEpoch: 4, BCELoss: 0.11446168612350117\u001b[0m\n",
      "\u001b[34mEpoch: 5, BCELoss: 0.074136844412847\u001b[0m\n",
      "\u001b[34mEpoch: 6, BCELoss: 0.07032773609865796\u001b[0m\n",
      "\u001b[34mEpoch: 7, BCELoss: 0.07687031240625815\u001b[0m\n",
      "\u001b[34mEpoch: 8, BCELoss: 0.07661181451244788\u001b[0m\n",
      "\u001b[34mEpoch: 9, BCELoss: 0.07053053717721593\u001b[0m\n",
      "\u001b[34mEpoch: 10, BCELoss: 0.07015701823613861\u001b[0m\n",
      "\u001b[34mEpoch: 11, BCELoss: 0.06096276268362999\u001b[0m\n",
      "\u001b[34mEpoch: 12, BCELoss: 0.054357513108036735\u001b[0m\n",
      "\u001b[34mEpoch: 13, BCELoss: 0.05151334608143026\u001b[0m\n",
      "\u001b[34mEpoch: 14, BCELoss: 0.04939490675248883\u001b[0m\n",
      "\u001b[34mEpoch: 15, BCELoss: 0.04907058094712821\u001b[0m\n",
      "\u001b[34mEpoch: 16, BCELoss: 0.04823079908435995\u001b[0m\n",
      "\u001b[34mEpoch: 17, BCELoss: 0.05287296578965404\u001b[0m\n",
      "\u001b[34mEpoch: 18, BCELoss: 0.05711424012075771\u001b[0m\n",
      "\u001b[34mEpoch: 19, BCELoss: 0.07698837532238527\u001b[0m\n",
      "\u001b[34mEpoch: 20, BCELoss: 0.12887776812369173\u001b[0m\n",
      "\u001b[34mEpoch: 21, BCELoss: 0.1877117075703361\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mEpoch: 22, BCELoss: 0.21191680973226373\u001b[0m\n",
      "\u001b[34mEpoch: 23, BCELoss: 0.2303805405443365\u001b[0m\n",
      "\u001b[34mEpoch: 24, BCELoss: 0.23620147732171146\u001b[0m\n",
      "\u001b[34mEpoch: 25, BCELoss: 0.2213162820447575\u001b[0m\n",
      "\u001b[34mEpoch: 26, BCELoss: 0.21916205503723837\u001b[0m\n",
      "\u001b[34mEpoch: 27, BCELoss: 0.2050205861980265\u001b[0m\n",
      "\u001b[34mEpoch: 28, BCELoss: 0.2015102424404838\u001b[0m\n",
      "\u001b[34mEpoch: 29, BCELoss: 0.1907743296839974\u001b[0m\n",
      "\u001b[34mEpoch: 30, BCELoss: 0.21126232634891162\u001b[0m\n",
      "\u001b[34mEpoch: 31, BCELoss: 0.22058837657625024\u001b[0m\n",
      "\u001b[34mEpoch: 32, BCELoss: 0.20558805492791263\u001b[0m\n",
      "\u001b[34mEpoch: 33, BCELoss: 0.220831189643253\u001b[0m\n",
      "\u001b[34mEpoch: 34, BCELoss: 0.25948967852375726\u001b[0m\n",
      "\u001b[34mEpoch: 35, BCELoss: 0.3043416535312479\u001b[0m\n",
      "\u001b[34mEpoch: 36, BCELoss: 0.31074008074673737\u001b[0m\n",
      "\u001b[34mEpoch: 37, BCELoss: 0.29572338272224774\u001b[0m\n",
      "\u001b[34mEpoch: 38, BCELoss: 0.28435286473144183\u001b[0m\n",
      "\u001b[34mEpoch: 39, BCELoss: 0.2780801870606162\u001b[0m\n",
      "\u001b[34mEpoch: 40, BCELoss: 0.26613285731185565\u001b[0m\n",
      "\u001b[34mEpoch: 41, BCELoss: 0.25735638764771546\u001b[0m\n",
      "\u001b[34mEpoch: 42, BCELoss: 0.2529178112745285\u001b[0m\n",
      "\u001b[34mEpoch: 43, BCELoss: 0.23651778427037326\u001b[0m\n",
      "\u001b[34mEpoch: 44, BCELoss: 0.2462076788598841\u001b[0m\n",
      "\u001b[34mEpoch: 45, BCELoss: 0.24923172728581863\u001b[0m\n",
      "\u001b[34mEpoch: 46, BCELoss: 0.2579003884033723\u001b[0m\n",
      "\u001b[34mEpoch: 47, BCELoss: 0.23476044833660126\u001b[0m\n",
      "\u001b[34mEpoch: 48, BCELoss: 0.21269097924232483\u001b[0m\n",
      "\u001b[34mEpoch: 49, BCELoss: 0.19082450324838812\u001b[0m\n",
      "\u001b[34mEpoch: 50, BCELoss: 0.18160998143933035\u001b[0m\n",
      "\u001b[34m2020-11-14 21:44:32,771 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-11-14 21:44:43 Uploading - Uploading generated training model\n",
      "2020-11-14 21:44:43 Completed - Training job completed\n",
      "Training seconds: 121\n",
      "Billable seconds: 121\n",
      "------"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "role = sagemaker.get_execution_role()\n",
    "input_data = sagemaker_session.upload_data(path=data_dir, bucket=bucket, key_prefix=prefix)\n",
    "estimator = PyTorch(entry_point=\"train.py\",\n",
    "                source_dir=\"trainf\",\n",
    "                role=role,\n",
    "                framework_version='0.4.0',\n",
    "                py_version='py3',\n",
    "                train_instance_count=1,\n",
    "                train_instance_type='ml.p2.xlarge',\n",
    "                hyperparameters={\n",
    "                    'epochs': 50,\n",
    "                    'hidden_dim': 100,\n",
    "                })\n",
    "estimator.fit({'training': input_data})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import RealTimePredictor\n",
    "\n",
    "class StringPredictor(RealTimePredictor):\n",
    "    def __init__(self, endpoint_name, sagemaker_session):\n",
    "        super(StringPredictor, self).__init__(endpoint_name, sagemaker_session, content_type='text/plain')\n",
    "\n",
    "\n",
    "model = PyTorchModel(model_data=estimator.model_data,\n",
    "                 role = role,\n",
    "                 framework_version='1.0',\n",
    "                 entry_point='predict.py',\n",
    "                 source_dir='servef',\n",
    "                 py_version='py3',\n",
    "                 predictor_cls=StringPredictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The class RealTimePredictor has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "content_type is a no-op in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "predictor=model.deploy(initial_instance_count = 1, instance_type = 'ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model was the one that are going to be used in the final application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "model_dir='Data//FinalData'\n",
    "word_dict_path = os.path.join(model_dir, 'word_dict.pkl')\n",
    "with open(word_dict_path, 'rb') as f:\n",
    "    word_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hac': 2, 'q': 3, 'buen': 4, 'hoy': 5, 'dios': 6, 'graci': 7, 'vid': 8, 'dia': 9, 'ser': 10, 'quier': 11, 'pued': 12, 'mejor': 13, 'sol': 14, 'nuev': 15, 'pas': 16, 'siempr': 17, 'esper': 18, 'feliz': 19, 'dej': 20, 'sab': 21, 'voy': 22, 'tod': 23, '3': 24, 'viv': 25, 'trabaj': 26, 'lleg': 27, 'bien': 28, 'qued': 29, 'com': 30, 'cuent': 31, 'ahor': 32, 'pais': 33, 'mas': 34, 'va': 35, 'dias': 36, 'sant': 37, 'amig': 38, 'ver': 39, '2': 40, 'mal': 41, 'seman': 42, 'tiemp': 43, 'amor': 44, 'amo': 45, 'años': 46, 'part': 47, 'cos': 48, 'sal': 49, 'namast': 50, 'cas': 51, 'pod': 52, 'vam': 53, 'ciud': 54, 'tan': 55, 'gust': 56, 'person': 57, 'phot': 58, 'in': 59, 'fot': 60, 'm': 61, 'hij': 62, 'noch': 63, 'habl': 64, 'nunc': 65, 'volv': 66, 'hag': 67, 'ahre': 68, 'envi': 69, 'gan': 70, 'segu': 71, 'gran': 72, 'hermos': 73, 'cre': 74, 'octubr': 75, 'jajajaj': 76, 'sig': 77, 'dic': 78, 'mund': 79, 'mism': 80, 'quer': 81, 'lind': 82, '1': 83, 'salud': 84, 'famili': 85, 'disfrut': 86, 'deb': 87, 'moment': 88, 'comun': 89, 'igual': 90, 'tom': 91, 'alcald': 92, 'i': 93, 'dec': 94, 'gent': 95, 'hor': 96, 'tiend': 97, 'fin': 98, 'cad': 99, 'san': 100, 'ayud': 101, 'ten': 102, 'usted': 103, 'mir': 104, 'señor': 105, '10': 106, 'vide': 107, 'mañan': 108, 'fisic': 109, 'barri': 110, 'indi': 111, 'import': 112, 'llam': 113, 'necesit': 114, 'invit': 115, 'verd': 116, 'conoc': 117, 'nadi': 118, 'much': 119, 'chau': 120, 're': 121, 'llev': 122, 'd': 123, 'man': 124, 'despues': 125, 'cumpleañ': 126, 'vez': 127, 'junt': 128, 'pa': 129, 'parqu': 130, 'sector': 131, 'cambi': 132, 'pon': 133, 'baj': 134, 'tkm': 135, 'at': 136, 'music': 137, 'felic': 138, 'vos': 139, 'falt': 140, 'aqu': 141, 'primer': 142, 'cumpl': 143, 'segur': 144, 'mes': 145, 'llen': 146, 'call': 147, 'busc': 148, 'unic': 149, 'da': 150, 't': 151, 'favor': 152, 'celebr': 153, 'regal': 154, 'line': 155, 'año': 156, 'pregunt': 157, 'put': 158, 'algun': 159, 'equip': 160, '2020': 161, 'centr': 162, 'dij': 163, 'ahi': 164, 'grand': 165, 'pobl': 166, 'hol': 167, 'algui': 168, 'medi': 169, 'llor': 170, 'clar': 171, 'lug': 172, 'encuentr': 173, 'van': 174, 'jajajajajjajj': 175, 'pag': 176, 'hallow': 177, 'pap': 178, 'encontr': 179, 'audi': 180, 'acab': 181, 'bonit': 182, 'tal': 183, 'prim': 184, 'apoy': 185, 'proyect': 186, 'sient': 187, 'list': 188, 'mand': 189, 'carib': 190, '4': 191, 'bell': 192, 'hic': 193, 'dispon': 194, 'mat': 195, 'termin': 196, 'ja': 197, 'constru': 198, 'x': 199, 'dal': 200, 'camin': 201, 'herman': 202, 'ven': 203, 'inici': 204, 'compart': 205, 'aca': 206, 'tard': 207, 'pens': 208, 'asi': 209, 'escuch': 210, 'jajaj': 211, 'doming': 212, '7': 213, 'cuid': 214, 'jueg': 215, 'abraz': 216, 'fe': 217, 'tem': 218, 'vien': 219, 'pid': 220, 'recuerd': 221, 'visit': 222, 'dig': 223, 'ultim': 224, 'public': 225, 'dos': 226, 'seri': 227, 'corazon': 228, 'sub': 229, 'razon': 230, 'car': 231, 'men': 232, 'servici': 233, 'ped': 234, 'odi': 235, 'luch': 236, 'bendicion': 237, '000': 238, 'mil': 239, 'pront': 240, 'polic': 241, 'sent': 242, 'mierd': 243, '5': 244, 'histori': 245, 'ir': 246, 'paz': 247, 'logr': 248, 'mam': 249, 'president': 250, 'xtrem': 251, '6': 252, 'polit': 253, 'dar': 254, 'mied': 255, 'cancion': 256, '13': 257, 'misterp': 258, 'lad': 259, 'piens': 260, 'comercial': 261, 'dorm': 262, 'descans': 263, 'loc': 264, 'sup': 265, 'alma': 266, 'jug': 267, 'compr': 268, 'pes': 269, 'mar': 270, 'extrañ': 271, 'especial': 272, 'ojal': 273, 'viern': 274, 'urib': 275, 'ric': 276, 'fuerz': 277, 'perfect': 278, 'sueñ': 279, 'olvid': 280, 'restaur': 281, 'acompañ': 282, 'maner': 283, 'aprend': 284, 'cualqui': 285, 'gener': 286, 'met': 287, 'libr': 288, 'color': 289, 'niñ': 290, 'sos': 291, 'ufffffff': 292, 'cundinamarc': 293, 'disc': 294, 'proces': 295, 'mensaj': 296, 'sid': 297, 'product': 298, 'salv': 299, 'casi': 300, 'social': 301, '15': 302, 'segund': 303, 'lun': 304, 'salg': 305, 'futur': 306, 'problem': 307, 'felicit': 308, 'trist': 309, 'gobiern': 310, 'parec': 311, 'entiend': 312, 'vec': 313, 'facil': 314, 'empez': 315, 'cerr': 316, 'ltda': 317, 'whatsapp': 318, 'veo': 319, 'caf': 320, 'puesssss': 321, 'excelent': 322, 'acuerd': 323, 'pierd': 324, 'pint': 325, 'cual': 326, 'inform': 327, 'viej': 328, 'perd': 329, 'vist': 330, 'plat': 331, 'jajajajaj': 332, 'toc': 333, 'traves': 334, 'twitt': 335, 'plaz': 336, 'activ': 337, 'cuant': 338, 'gol': 339, 'noviembr': 340, 'empres': 341, 'verdader': 342, 'hech': 343, 'bellez': 344, 'direct': 345, 'marc': 346, 'pq': 347, 'cag': 348, 'proxim': 349, 'estudi': 350, 'radi': 351, 'vay': 352, 'asesin': 353, 'espaci': 354, 'ignor': 355, 'interes': 356, 'control': 357, 'vas': 358, 'conmig': 359, 'pues': 360, 'hombr': 361, 'oportun': 362, 'mogol': 363, 'entonc': 364, 'vot': 365, 'novi': 366, 'viend': 367, '20': 368, 'desarroll': 369, 'distrit': 370, 'maravill': 371, 'present': 372, 'juan': 373, 'respond': 374, 'diferent': 375, 'permit': 376, '12': 377, 'encant': 378, 'tort': 379, 'verg': 380, 'digital': 381, 'muj': 382, 'santiag': 383, 'larg': 384, 'deport': 385, 'vill': 386, 'peg': 387, 'rey': 388, 'barb': 389, 'form': 390, 's': 391, 'futbol': 392, 'alegr': 393, 'punt': 394, 'sac': 395, 'mayor': 396, 'puent': 397, 'energ': 398, 'perdon': 399, 'madr': 400, 'mor': 401, 'priv': 402, 'alla': 403, 'band': 404, 'sin': 405, 'capital': 406, '8': 407, 'mientr': 408, 'instal': 409, 'pandemi': 410, 'tare': 411, 'dud': 412, 'favorit': 413, 'etern': 414, 'tip': 415, 'enseñ': 416, 'valor': 417, 'recib': 418, 'tir': 419, 'ant': 420, 'crec': 421, '11': 422, 've': 423, 'final': 424, 'bail': 425, 'local': 426, 'cort': 427, 'cont': 428, 'tres': 429, 'negr': 430, 'nacional': 431, 'aunqu': 432, 'medeiin': 433, 'val': 434, 'sex': 435, 'client': 436, 'grup': 437, 'merec': 438, 'diseñ': 439, 'c': 440, 'petr': 441, 'colombian': 442, 'ningun': 443, 'program': 444, 'karchez': 445, 'culp': 446, 'entren': 447, 'exist': 448, 'cuerp': 449, 'ah': 450, 'doy': 451, 'collezioni': 452, 'maestr': 453, 'boliv': 454, 'numer': 455, 'rat': 456, 'dur': 457, 'lanzamient': 458, 'todav': 459, 'info': 460, 'aburr': 461, 'r': 462, 'personal': 463, 'xq': 464, 'exit': 465, '30': 466, 'dich': 467, 'inteligent': 468, 'muak': 469, 'agu': 470, 'calid': 471, 'muert': 472, 'palabr': 473, 'agradec': 474, 'cant': 475, 'contig': 476, 'vend': 477, 'univers': 478, 'canal': 479, 'mart': 480, 'atras': 481, 'delincuent': 482, 'carg': 483, 'prueb': 484, 'propi': 485, 'escuel': 486, 'copacaban': 487, 'quien': 488, 'territori': 489, 'mujer': 490, 'respet': 491, 'adel': 492, 'beb': 493, 'viaj': 494, 'quit': 495, 'tranquil': 496, 'internacional': 497, 'argentin': 498, 'ide': 499, 'amen': 500, 'par': 501, 'virtual': 502, 'mot': 503, 'complet': 504, 'liv': 505, 'bienven': 506, 'pm': 507, 'hotel': 508, 'bes': 509, 'not': 510, 'aun': 511, 'ciudadan': 512, 'peor': 513, 'mentir': 514, 'trat': 515, '00': 516, 'ojo': 517, 'entend': 518, 'cam': 519, 'vi': 520, 'antoni': 521, 'nombr': 522, 'plan': 523, 'pel': 524, 'via': 525, 'vall': 526, '0': 527, 'mont': 528, 'reconoc': 529, 'juev': 530, 'dan': 531, 'respons': 532, 'fiest': 533, 'soach': 534, 'delici': 535, 'record': 536, 'bloqu': 537, 'ment': 538, 'experient': 539, 'hiz': 540, 'merc': 541, 'youtub': 542, 'tant': 543, 'romp': 544, 'vuelt': 545, 'empiez': 546, 'mod': 547, 'carrer': 548, 'biosegur': 549, 'human': 550, 'libert': 551, 'imagin': 552, 'talent': 553, 'seleccion': 554, '18': 555, 'to': 556, 'club': 557, 'hab': 558, 'amanec': 559, 'manten': 560, 'total': 561, 'une': 562, 'cauc': 563, 'exig': 564, 'pur': 565, 'orgull': 566, 'dese': 567, 'protocol': 568, 'jaj': 569, 'porq': 570, 'practic': 571, 'amurall': 572, 'vuelv': 573, 'negoci': 574, 'ay': 575, 'gat': 576, 'limit': 577, 'acord': 578, 'just': 579, 'rap': 580, 'ciert': 581, 'continu': 582, 'venezuel': 583, 'normal': 584, 'prepar': 585, 'usaquen': 586, 'fotograf': 587, 'herrer': 588, 'ming': 589, 'chic': 590, 'comunic': 591, 'demas': 592, 'gym': 593, 'necesari': 594, 'artist': 595, 'icon': 596, 'primaver': 597, 'toqu': 598, 'event': 599, 'luc': 600, 'abiert': 601, 'tv': 602, 'pan': 603, 'nac': 604, 'derech': 605, 'sencill': 606, 'estadi': 607, 'pobr': 608, 'ojos': 609, 'podr': 610, 'aliment': 611, 'preci': 612, 'aeropuert': 613, 'olay': 614, 'ayer': 615, 'cuev': 616, 'profesional': 617, 'padr': 618, 'solucion': 619, 'iba': 620, 'haci': 621, 'cans': 622, 'lej': 623, 'sals': 624, 'educ': 625, 'comentari': 626, 'pong': 627, 'bendig': 628, 'das': 629, 'encim': 630, 'dulc': 631, 'pud': 632, 'prad': 633, '14': 634, 'tra': 635, 'alto': 636, 'congres': 637, 'distanci': 638, 'increibl': 639, 'dentr': 640, 'gonorre': 641, 'efect': 642, 'enza': 643, 'compañ': 644, 'transform': 645, '9': 646, 'infantil': 647, 'cuadr': 648, 'p': 649, 'post': 650, 'drak': 651, 'arte': 652, 'dm': 653, 'sirv': 654, 'posibl': 655, 'quill': 656, 'haciend': 657, 'coment': 658, 'naturalez': 659, 'mast': 660, 'lopez': 661, 'manej': 662, 'bañ': 663, 'rob': 664, 'unid': 665, 'darl': 666, 'tecnic': 667, 'aplic': 668, 'tall': 669, 'aquell': 670, 'unas': 671, 'minut': 672, 'innov': 673, 'glori': 674, 'cov': 675, 'plataform': 676, 'oig': 677, 'aniversari': 678, '31': 679, 'feri': 680, 'represent': 681, 'model': 682, 'piedr': 683, 'guatap': 684, 'dedic': 685, '70': 686, 'dificil': 687, 'funcion': 688, 'nort': 689, 'clas': 690, 'dañ': 691, 'tampoc': 692, 'the': 693, 'envidi': 694, 'justici': 695, 'premi': 696, 'cul': 697, 'fuert': 698, 'papel': 699, 'sonris': 700, 'crem': 701, 'conozc': 702, 'facebook': 703, 'lag': 704, 'chup': 705, 'ta': 706, 'bol': 707, 'realment': 708, 'frent': 709, 'pensamient': 710, 'verl': 711, 'with': 712, 'red': 713, 'camil': 714, 'oficial': 715, 'princes': 716, 'orne': 717, 'sabor': 718, 'dam': 719, 'new': 720, 'silenci': 721, 'dolor': 722, 'ingeni': 723, 'fundacion': 724, 'reun': 725, 'cit': 726, 'urban': 727, 'particip': 728, 'comod': 729, 'boutiqu': 730, 'telefon': 731, 'movil': 732, 'recuper': 733, 'har': 734, 'lav': 735, 'escrib': 736, 'aprovech': 737, 'suert': 738, 'di': 739, 'pat': 740, 'clav': 741, 'despert': 742, 'lueg': 743, 'puert': 744, '19': 745, 'se': 746, 'iglesi': 747, 'link': 748, 'jod': 749, 'opin': 750, 'afect': 751, 'med': 752, 'brind': 753, 'econom': 754, 'enamor': 755, 'veng': 756, 'u': 757, 'produccion': 758, 'peñol': 759, 'anda': 760, 'puebl': 761, 'buscal': 762, 'cuarenten': 763, 'condicion': 764, 'parej': 765, 'huev': 766, 'carl': 767, 'pus': 768, 'edicion': 769, 'preocup': 770, 'natural': 771, 'lider': 772, 'miercol': 773, 'gaitan': 774, 'agend': 775, 'jajajajajajaj': 776, 'nom': 777, 'atencion': 778, 'ves': 779, 'alta': 780, 'realid': 781, 'lastim': 782, 'roj': 783, 'firm': 784, 'confianz': 785, 'entreg': 786, 'rio': 787, 'rar': 788, 'noo': 789, 'borr': 790, 'accion': 791, 'super': 792, 'onda': 793, '35': 794, 'bat': 795, 'terror': 796, 'col': 797, '26': 798, 'bar': 799, 'estren': 800, 'conect': 801, 'mutuals': 802, 'cabez': 803, 'complic': 804, 'dijeron': 805, '21': 806, 'españ': 807, 'estrategi': 808, 'impos': 809, 'demostr': 810, '57': 811, 'organiz': 812, 'sabi': 813, 'ris': 814, 'uffffff': 815, 'uso': 816, 'atardec': 817, 'blanc': 818, 'ilumin': 819, 'vol': 820, 'absolut': 821, 'horribl': 822, 'rein': 823, 'notici': 824, 'ok': 825, 'decid': 826, 'vari': 827, 'bloq': 828, 'usaqu': 829, 'chocolat': 830, 'quis': 831, 'instagram': 832, '100': 833, 'regres': 834, 'pen': 835, 'ko': 836, 'mim': 837, 'real': 838, 'millon': 839, '16': 840, 'estan': 841, 'rot': 842, 'principal': 843, 'perfil': 844, 'comb': 845, 'precios': 846, 'caid': 847, 'h': 848, 'lik': 849, 'imag': 850, 'pati': 851, 'dat': 852, 'envig': 853, 'fech': 854, 'cdsm': 855, 'emision': 856, 'director': 857, 'francisc': 858, 'narcotraf': 859, 'proteg': 860, 'tecnolog': 861, 'yankis': 862, 'sistem': 863, 'don': 864, 'ley': 865, 'carr': 866, 'asco': 867, 'tierr': 868, 'acept': 869, 'zon': 870, 'perr': 871, 'hp': 872, 'cierr': 873, 'situacion': 874, 'nivel': 875, 'siqu': 876, 'ret': 877, 'estil': 878, 'definit': 879, 'fas': 880, 'lom': 881, 'materi': 882, 'bast': 883, 'sigl': 884, 'l': 885, 'fri': 886, 'peligr': 887, 'son': 888, 'divert': 889, 'sep': 890, 'mit': 891, 'demasi': 892, 'lluvi': 893, 'espectacul': 894, 'ofrec': 895, 'by': 896, 'tempran': 897, 'sed': 898, 'medayork': 899, 'compañer': 900, 'destin': 901, 'consej': 902, 'gestion': 903, 'chil': 904, 'muer': 905, 'boc': 906, 'calm': 907, 'porqu': 908, 'tim': 909, 'proposit': 910, 'qien': 911, 'casual': 912, 'soñ': 913, 'corr': 914, 'tap': 915, 'heroic': 916, 'confirm': 917, 'amad': 918, 'mezcl': 919, 'play': 920, 'stream': 921, 'poc': 922, 'infinit': 923, 'complej': 924, 'pabl': 925, 'pis': 926, 'nos': 927, 'vem': 928, 'siend': 929, 'relacion': 930, 'fracas': 931, 'pequeñ': 932, 'laur': 933, 'ador': 934, 'anunci': 935, 'disfraz': 936, 'acerc': 937, 'album': 938, 'flac': 939, 'deterior': 940, 'gun': 941, 'pil': 942, 'result': 943, 'respir': 944, 'conciert': 945, 'bel': 946, 'pc': 947, 'cost': 948, 'naranj': 949, 'produc': 950, 'tar': 951, 'levant': 952, 'sorprend': 953, 'destac': 954, 'rop': 955, 'palm': 956, 'colegi': 957, 'grab': 958, 'dolar': 959, 'jos': 960, 'ciel': 961, 'internet': 962, 'recurs': 963, 'gord': 964, 'utiliz': 965, 'aguant': 966, 'realiz': 967, 'reserv': 968, 'molest': 969, 'dand': 970, 'hdp': 971, 'atlant': 972, 'martin': 973, 'vent': 974, 'caleñ': 975, 'atac': 976, 'bas': 977, 'juici': 978, 'mati': 979, 'farc': 980, 'trol': 981, 'lament': 982, 'marin': 983, 'campañ': 984, 'orden': 985, 'oro': 986, 'leer': 987, 'usa': 988, 'chimb': 989, 'vacun': 990, 'v': 991, 'salt': 992, 'pelotud': 993, 'gobern': 994, 'ros': 995, 'clinic': 996, 'diner': 997, 'motiv': 998, 'decision': 999, 'luis': 1000, 'crist': 1001, 'carn': 1002, 'construccion': 1003, 'inscripcion': 1004, 'coleccion': 1005, 'poder': 1006, 'bendec': 1007, 'parcer': 1008, 'estim': 1009, 'conjunt': 1010, 'alianz': 1011, 'show': 1012, 'oracion': 1013, 'des': 1014, 'ritm': 1015, 'class': 1016, 'pasion': 1017, 'pendej': 1018, 'zapat': 1019, 'consegu': 1020, 'queres': 1021, 'domicili': 1022, 'vered': 1023, 'bb': 1024, 'veran': 1025, 'emple': 1026, 'luci': 1027, 'cervez': 1028, 'desayun': 1029, 'detall': 1030, 'sur': 1031, 'period': 1032, 'siguient': 1033, 'explic': 1034, 'you': 1035, 'convers': 1036, 'respuest': 1037, 'ingenieri': 1038, 'global': 1039, 'wtf': 1040, 'patri': 1041, 'lengu': 1042, 'imagines': 1043, 'comenz': 1044, 'eli': 1045, 'dond': 1046, 'elen': 1047, 'cuidat': 1048, 'institu': 1049, 'objet': 1050, 'cultur': 1051, 'prefier': 1052, 'rut': 1053, 'recien': 1054, 'gomez': 1055, 'cen': 1056, 'enter': 1057, 'clasic': 1058, 'sombr': 1059, 'n': 1060, 'empresari': 1061, 'defin': 1062, '30pm': 1063, 'entra': 1064, 'cerc': 1065, 'esfuerz': 1066, 'am': 1067, 'actor': 1068, 'pendient': 1069, 'estructur': 1070, 'abuel': 1071, 'atanasi': 1072, 'girardot': 1073, 'muchisim': 1074, 'avanz': 1075, 'venezolan': 1076, 'declar': 1077, 'of': 1078, 'intent': 1079, 'moral': 1080, 'dad': 1081, 'pal': 1082, 'titul': 1083, 'extra': 1084, 'bio': 1085, 'pedr': 1086, 'correct': 1087, 'dc': 1088, 'deteng': 1089, 'lp': 1090, 'helen': 1091, 'maricon': 1092, 'tercer': 1093, 'descubr': 1094, 'ambient': 1095, 'socied': 1096, 'cocin': 1097, 'personaliz': 1098, 'vallenat': 1099, 'b': 1100, 'air': 1101, 'for': 1102, 'victori': 1103, 'jesus': 1104, 'piez': 1105, 'paj': 1106, 'integr': 1107, 'tempor': 1108, 'flor': 1109, 'pow': 1110, 'ademas': 1111, 'dir': 1112, 'suel': 1113, 'fundapedc': 1114, 'her': 1115, 'divin': 1116, 'onlin': 1117, 'oper': 1118, 'contact': 1119, 'aventur': 1120, 'gerent': 1121, 'inclu': 1122, 'usuari': 1123, 'median': 1124, 'cog': 1125, 'recre': 1126, 'gil': 1127, 'march': 1128, 'destru': 1129, 'cuestion': 1130, 'viviend': 1131, 'santaf': 1132, 'recomend': 1133, 'muebl': 1134, 'reencuentr': 1135, 'camis': 1136, 'mmm': 1137, 'tatto': 1138, 'implement': 1139, 'municipi': 1140, 'fortalez': 1141, 'virg': 1142, 'app': 1143, 'eu': 1144, 'nooo': 1145, 'campeon': 1146, 'amist': 1147, 'banc': 1148, 'prob': 1149, 'tel': 1150, 'espos': 1151, 'recorr': 1152, 'jorn': 1153, 'hog': 1154, 'invent': 1155, 'cerebr': 1156, 'categor': 1157, 'compromis': 1158, 'administr': 1159, 'zepet': 1160, 'emocion': 1161, 'ahorr': 1162, 'supuest': 1163, '22': 1164, 'creativ': 1165, 'agarr': 1166, 'canc': 1167, 'cuand': 1168, 'obra': 1169, 'residu': 1170, 'kier': 1171, 'diari': 1172, 'correg': 1173, 'riesg': 1174, 'dim': 1175, 'pudin': 1176, 'hd': 1177, 'escen': 1178, 'captur': 1179, 'recient': 1180, 'biograf': 1181, 'humedal': 1182, 'tus': 1183, 'duel': 1184, 'cosmet': 1185, 'capilar': 1186, 'quirurg': 1187, 'mostr': 1188, '17': 1189, 'comet': 1190, 'odontolog': 1191, 'critic': 1192, 'eleg': 1193, 'espiritual': 1194, 'porf': 1195, 'dirigent': 1196, 'min': 1197, 'ejempl': 1198, 'principi': 1199, 'herramient': 1200, 'sali': 1201, 'payas': 1202, 'cualqu': 1203, 'piern': 1204, 'parqueader': 1205, 'fall': 1206, 'lanz': 1207, 'hum': 1208, 'muse': 1209, 'repet': 1210, '00pm': 1211, '500': 1212, 'aparec': 1213, 'tras': 1214, 'magic': 1215, 'epoc': 1216, 'tantr': 1217, 'habit': 1218, 'fond': 1219, 'caj': 1220, 'tweet': 1221, 'suficient': 1222, 'muestr': 1223, 'simon': 1224, 'ejercici': 1225, 'piñ': 1226, 'sorpres': 1227, 'narc': 1228, 'venc': 1229, 'pacif': 1230, 'altern': 1231, 'etb': 1232, 'candelari': 1233, 'nic': 1234, 'gratis': 1235, 'sosten': 1236, 'saqu': 1237, 'mundial': 1238, 'precis': 1239, 'haz': 1240, 'festiv': 1241, 'vean': 1242, 'europe': 1243, '50': 1244, 'abaj': 1245, 'iphon': 1246, 'presenci': 1247, 'saldr': 1248, 'celel': 1249, 'googl': 1250, 'equivoc': 1251, 'democraci': 1252, 'bastant': 1253, 'cristian': 1254, 'sr': 1255, 'sum': 1256, 'ded': 1257, '07': 1258, 'alex': 1259, 'usme': 1260, 'nariz': 1261, 'fiscal': 1262, 'do': 1263, 'desact': 1264, 'celul': 1265, 'aument': 1266, 'may': 1267, 'rafael': 1268, 'apen': 1269, 'interactu': 1270, 'indes': 1271, 'brot': 1272, 'ose': 1273, 'circul': 1274, 'cat': 1275, 'pertenec': 1276, 'ventan': 1277, 'cajacopi': 1278, 'gooool': 1279, 'uy': 1280, 'signif': 1281, 'apartament': 1282, 'bernal': 1283, 'callat': 1284, 'naa': 1285, 'escap': 1286, 'tit': 1287, 'frail': 1288, 'mobilari': 1289, '90': 1290, 'nomin': 1291, 'gatit': 1292, 'argument': 1293, 'restriccion': 1294, 'res': 1295, 'actitud': 1296, 'apuest': 1297, 'personaj': 1298, 'seguidor': 1299, 'grit': 1300, 'feo': 1301, 'herm': 1302, 'volkaci': 1303, 'plac': 1304, 'sisoy': 1305, 'satisfech': 1306, 'elig': 1307, 'tatuaj': 1308, 'asad': 1309, 'catol': 1310, 'ener': 1311, 'actualiz': 1312, '25': 1313, 'fuent': 1314, 'diran': 1315, 'confi': 1316, 'inocent': 1317, '3155788596': 1318, 'atend': 1319, 'canch': 1320, 'lugar': 1321, 'adopcion': 1322, 'angel': 1323, '150': 1324, 'inf': 1325, '9790001': 1326, '2022': 1327, 'carnaval': 1328, 'enfrent': 1329, 'facher': 1330, 'comerci': 1331, 'gay': 1332, 'evident': 1333, 'guerrill': 1334, 'horror': 1335, 'c1': 1336, 'mastering': 1337, 'parch': 1338, 'uh': 1339, 'ques': 1340, 'famos': 1341, 'hel': 1342, 'tremend': 1343, 'compadr': 1344, 'pedaz': 1345, 'escal': 1346, 'ando': 1347, 'convert': 1348, 'report': 1349, 'amas': 1350, 'one': 1351, 'mem': 1352, 'posit': 1353, 'maldit': 1354, 'mini': 1355, 'rock': 1356, 'uds': 1357, 'braz': 1358, 'tw': 1359, 'fandom': 1360, 'adopt': 1361, 'luz': 1362, 'fals': 1363, 'inspir': 1364, 'ocurr': 1365, 'amorcit': 1366, 'oficin': 1367, 'abre': 1368, 'opcion': 1369, 'jaim': 1370, 'km': 1371, 'dsps': 1372, 'humild': 1373, 'vs': 1374, 'basur': 1375, 'sentimient': 1376, 'amar': 1377, 'coctel': 1378, 'up': 1379, 'brill': 1380, 'aren': 1381, 'asombr': 1382, 'medic': 1383, 'desaparec': 1384, 'dialog': 1385, 'vial': 1386, 'team': 1387, 'literal': 1388, 'unicentr': 1389, 'entrad': 1390, 'sierr': 1391, 'reb': 1392, 'prend': 1393, 'leyend': 1394, 'aprendizaj': 1395, 'emprend': 1396, 'hond': 1397, 'duqu': 1398, 'general': 1399, 'labor': 1400, 'ministr': 1401, 'obras': 1402, 'rest': 1403, 'usand': 1404, 'decepcion': 1405, 'puest': 1406, 'jehov': 1407, 'hermanit': 1408, 'look': 1409, 'w': 1410, 'claudi': 1411, 'cosit': 1412, 'mobiliari': 1413, 'repar': 1414, 'cordial': 1415, '28': 1416, 'contest': 1417, 'cruz': 1418, 'prevencion': 1419, 'holaa': 1420, 'cap': 1421, 'decim': 1422, 'tic': 1423, 'rei': 1424, 'ceped': 1425, 'suspend': 1426, 'orej': 1427, 'quebr': 1428, 'renunci': 1429, 'adivin': 1430, 'electr': 1431, 'delit': 1432, 'buenisim': 1433, 'mari': 1434, 'pres': 1435, 'honr': 1436, 'rol': 1437, 'mencion': 1438, 'recom': 1439, 'adecu': 1440, '24': 1441, 'garantiz': 1442, 'evit': 1443, 'material': 1444, 'autor': 1445, 'voz': 1446, 'vehicul': 1447, 'dibuj': 1448, 'ladron': 1449, 'vincul': 1450, 'edil': 1451, 'ciudad': 1452, 'suegr': 1453, 'hpta': 1454, 'anim': 1455, 'planet': 1456, 'inutil': 1457, 'opositor': 1458, 'colabor': 1459, 'culiau': 1460, 'region': 1461, 'lech': 1462, 'prof': 1463, 'dign': 1464, 'pilot': 1465, 'salvador': 1466, 'virus': 1467, 'apreci': 1468, 'mirador': 1469, 'nen': 1470, '48': 1471, 'prohib': 1472, 'entreten': 1473, 'magi': 1474, 'suced': 1475, 'cuart': 1476, 'eficient': 1477, 'musical': 1478, 'hambr': 1479, 'charl': 1480, 'quem': 1481, 'honor': 1482, 'mental': 1483, 'pelicul': 1484, 'vuel': 1485, 'criminal': 1486, 'lpm': 1487, 'fij': 1488, 'caig': 1489, 'varied': 1490, 'presencial': 1491, 'subregion': 1492, 'julian': 1493, 'lps': 1494, 'estrateg': 1495, 'sembr': 1496, 'torr': 1497, 'papas': 1498, 'semej': 1499, '40': 1500, 'emprendedor': 1501, 'sesion': 1502, 'explor': 1503, 'adquier': 1504, 'crim': 1505, 'hop': 1506, 'poll': 1507, 'jamas': 1508, 'vin': 1509, 'siti': 1510, 'segun': 1511, 'log': 1512, 'testig': 1513, 'quej': 1514, 'pueblit': 1515, 'pion': 1516, 'netflix': 1517, 'humor': 1518, 'descarg': 1519, 'monit': 1520, 'turist': 1521, 'rip': 1522, 'sufr': 1523, 'nl': 1524, '301': 1525, 'etic': 1526, 'infiern': 1527, 'miser': 1528, 'asust': 1529, 'cab': 1530, 'castr': 1531, 'maldon': 1532, 'sujet': 1533, '77': 1534, 'noa': 1535, 'excus': 1536, 'prod': 1537, 'concienci': 1538, 'sancion': 1539, 'dio': 1540, 'pesc': 1541, 'pec': 1542, 'humill': 1543, 'aqui': 1544, 'dejam': 1545, 'bols': 1546, 'superior': 1547, 'liber': 1548, 'decret': 1549, 'edad': 1550, 'etap': 1551, 'mexic': 1552, 'penal': 1553, 'ami': 1554, 'intim': 1555, 'bici': 1556, 'plen': 1557, 'horari': 1558, 'long': 1559, 'prest': 1560, 'fitness': 1561, 'guard': 1562, 'polici': 1563, 'retom': 1564, 'embaj': 1565, 'enfoqu': 1566, 'privilegi': 1567, 'acces': 1568, 'inscribet': 1569, 'indoor': 1570, 'arrivals': 1571, 'fit': 1572, 'conf': 1573, 'baby': 1574, 'bleach': 1575, 'bruj': 1576, 'sold': 1577, 'cop': 1578, 'despiert': 1579, 'varon': 1580, 'eleccion': 1581, 'cuentan': 1582, 'matrimoni': 1583, 'medall': 1584, 'describ': 1585, 'colomabi': 1586, 'locur': 1587, 'cuest': 1588, 'monton': 1589, 'muñec': 1590, 'castill': 1591, 'capac': 1592, 'electron': 1593, 'dificultad': 1594, 'torreon': 1595, 'geni': 1596, 'articul': 1597, 'guerr': 1598, 'jov': 1599, '320': 1600, 'montaj': 1601, 'mid': 1602, 'on': 1603, 'pac': 1604, 'digestor': 1605, 'parezc': 1606, 'arep': 1607, 'paul': 1608, 'sever': 1609, 'f': 1610, '06': 1611, 'suci': 1612, 'vacacion': 1613, 'viol': 1614, 'llav': 1615, 'andre': 1616, 'ph': 1617, 'solt': 1618, 'bellisim': 1619, 'jesucrist': 1620, 'limpi': 1621, 'navarr': 1622, 'cantid': 1623, 'estaf': 1624, 'mov': 1625, 'dor': 1626, 'ambos': 1627, 'descar': 1628, 'jugador': 1629, 'miguel': 1630, 'cach': 1631, 'siguem': 1632, 'parroqui': 1633, 'diciembr': 1634, 'off': 1635, '29': 1636, 'valdez': 1637, 'cin': 1638, 'imperd': 1639, 'memori': 1640, 'your': 1641, 'ingres': 1642, 'nacion': 1643, 'cieg': 1644, 'secret': 1645, 'visitan': 1646, 'alvar': 1647, 'palaci': 1648, 'pintur': 1649, 'laurel': 1650, 'uñas': 1651, 'simplement': 1652, 'bust': 1653, 'mantien': 1654, 'dentist': 1655, 'cicl': 1656, 'frut': 1657, 'lourd': 1658, 'version': 1659, 'vibr': 1660, 'camaron': 1661, 'tradicional': 1662, 'perrit': 1663, 'whats': 1664, 'andar': 1665, 'tapaboc': 1666, 'nub': 1667, 'debut': 1668, 'opinion': 1669, 'tesor': 1670, 'tranqui': 1671, 'hijueput': 1672, 'estacion': 1673, 'recet': 1674, 'conserv': 1675, 'capitul': 1676, 'alcaldes': 1677, 'naaa': 1678, 'ilusion': 1679, 'sas': 1680, 'conexion': 1681, 'estrell': 1682, 'exact': 1683, 'zurd': 1684, 'cald': 1685, 'recuerdal': 1686, 'secretari': 1687, 'motor': 1688, 'escond': 1689, 'gratuit': 1690, 'joven': 1691, '72': 1692, 'cup': 1693, 'promov': 1694, 'pobrecit': 1695, 'amenaz': 1696, 'bard': 1697, 'farmaci': 1698, 'dj': 1699, 'montañ': 1700, 'comput': 1701, '98': 1702, 'ex': 1703, 'trafic': 1704, 'fundamental': 1705, 'corrupt': 1706, 'promocion': 1707, 'etc': 1708, 'destap': 1709, 'cak': 1710, 'compromet': 1711, 'tri': 1712, 'pip': 1713, 'festival': 1714, 'pie': 1715, 'entrar': 1716, 'spa': 1717, 'luly': 1718, 'matemat': 1719, 'ocasion': 1720, 'it': 1721, 'afirm': 1722, 'repit': 1723, 'anoch': 1724, 'escog': 1725, 'duerm': 1726, 'rued': 1727, 'telemedellin': 1728, 'consult': 1729, 'desesper': 1730, 'aprueb': 1731, 'nas': 1732, 'episodi': 1733, 'prefer': 1734, 'vacil': 1735, 'chist': 1736, 'andres': 1737, 'cochin': 1738, 'mami': 1739, 'extrem': 1740, 'discapac': 1741, 'dejal': 1742, 'imperi': 1743, '62': 1744, 'aviacion': 1745, 'halcon': 1746, 'pirotecn': 1747, 'ignaci': 1748, 'errad': 1749, 'lab': 1750, 'gabriel': 1751, 'interior': 1752, 'figur': 1753, 'laboral': 1754, 'ingles': 1755, 'ident': 1756, 'animal': 1757, 'gal': 1758, 'amd': 1759, 'nvidi': 1760, '2021': 1761, 'acced': 1762, 'almacentr': 1763, 'constant': 1764, 'laboratori': 1765, 'ft': 1766, 'altur': 1767, 'fer': 1768, 'stor': 1769, 'enlac': 1770, 'compar': 1771, 'fras': 1772, 'lif': 1773, 'cun': 1774, 'reactiv': 1775, 'oye': 1776, 'merd': 1777, 'visual': 1778, 'cultural': 1779, 'lol': 1780, 'bob': 1781, 'moren': 1782, 'zangan': 1783, 'jur': 1784, 'toyot': 1785, 'culi': 1786, 'obvi': 1787, 'lagrim': 1788, 'august': 1789, 'lid': 1790, 'apple': 1791, 'xiaomi': 1792, 'nobel': 1793, 'tenaz': 1794, 'terapi': 1795, 'albert': 1796, 'chef': 1797, 'joj': 1798, 'amam': 1799, 'habi': 1800, 'kit': 1801, 'ejercit': 1802, 'volunt': 1803, 'profesor': 1804, 'colect': 1805, 'jep': 1806, 'ofend': 1807, 'ram': 1808, 'aja': 1809, 'porfavor': 1810, 'clim': 1811, 'content': 1812, 'trump': 1813, 'elimin': 1814, 'chicharron': 1815, 'deci': 1816, 'javi': 1817, 'caiced': 1818, 'actual': 1819, 'projim': 1820, 'stil': 1821, 'sangr': 1822, 'vert': 1823, 'mach': 1824, 'lolan': 1825, 'senador': 1826, 'an': 1827, 'gallet': 1828, 'desculp': 1829, 'cabl': 1830, 'atent': 1831, 'tweets': 1832, 'tristez': 1833, 'alic': 1834, 'usar': 1835, 'cocain': 1836, 'ricard': 1837, 'obrer': 1838, 'dueñ': 1839, 'ocho': 1840, 'nativ': 1841, 'arkadi': 1842, 'decor': 1843, 'investig': 1844, 'hipocrit': 1845, 'maxim': 1846, 'armad': 1847, 'lin': 1848, 'guerrer': 1849, 'traj': 1850, 'alient': 1851, 'bro': 1852, 'alej': 1853, 'lent': 1854, 'ocup': 1855, 'equilibri': 1856, 'ud': 1857, 'doctor': 1858, 'dirig': 1859, 'instrument': 1860, 'hola': 1861, 'metr': 1862, 'hip': 1863, 'establec': 1864, 'central': 1865, 'fortalec': 1866, 'k': 1867, 'veras': 1868, 'indigen': 1869, 'oct': 1870, 'ideolog': 1871, 'indic': 1872, 'lam': 1873, 'mutual': 1874, '34': 1875, 'ome': 1876, 'daniel': 1877, 'juez': 1878, 'tent': 1879, 'nao': 1880, 'violenci': 1881, 'cent': 1882, 'vest': 1883, 'dobl': 1884, 'civil': 1885, 'convenc': 1886, 'apasion': 1887, 'ensay': 1888, 'ensal': 1889, 'criteri': 1890, 'nutib': 1891, 'fontan': 1892, 'reproductor': 1893, 'intelectual': 1894, 'comienz': 1895, 'land': 1896, 'ps': 1897, 'impid': 1898, 'my': 1899, 'curs': 1900, 'domin': 1901, 'despreci': 1902, 'inmund': 1903, 'ufffff': 1904, 'resum': 1905, 'polariz': 1906, 'homenaj': 1907, 'starbucks': 1908, 'mill': 1909, 'señal': 1910, 'reflej': 1911, 'hom': 1912, 'anterior': 1913, 'soport': 1914, 'impuest': 1915, 'tequendam': 1916, 'enfoc': 1917, 'vainill': 1918, 'panic': 1919, 'flash': 1920, 'dieg': 1921, 'cnc': 1922, 'homb': 1923, 'nad': 1924, 'otorg': 1925, 'pretend': 1926, 'taxis': 1927, 'hamburgues': 1928, 'hilton': 1929, 'rosari': 1930, 'ventaj': 1931, 'fiel': 1932, 'ne': 1933, 'reseñ': 1934, 'invict': 1935, 'fondant': 1936, 'minecraft': 1937, '3d': 1938, 'avanc': 1939, 'bagr': 1940, 'recarg': 1941, 'destructor': 1942, 'cariñ': 1943, 'goz': 1944, 'orto': 1945, 'paki': 1946, 'word': 1947, 'formul': 1948, 'amplif': 1949, 'ido': 1950, 'residencial': 1951, 'ilegal': 1952, 'teni': 1953, 'suen': 1954, 'bal': 1955, 'error': 1956, 'antigu': 1957, 'twitch': 1958, 'veg': 1959, 'solidari': 1960, 'facilit': 1961, 'rural': 1962, 'boy': 1963, 'debat': 1964, 'repent': 1965, 'basic': 1966, 'juli': 1967, 'crep': 1968, 'waffl': 1969, 'wauuu': 1970, 'disposit': 1971, 'terraz': 1972, 'horaci': 1973, 'tngo': 1974, 'na': 1975, 'ma': 1976, 'escribem': 1977, 'rcn': 1978, 'sigu': 1979, 'instant': 1980, 'brutal': 1981, 'bless': 1982, 'perec': 1983, 'integral': 1984, 'socializ': 1985, 'izquierd': 1986, 'compet': 1987, 'peluqu': 1988, 'te': 1989, 'botell': 1990, '140': 1991, 'rent': 1992, 'crioll': 1993, 'vet': 1994, 'ciclist': 1995, 'ecuador': 1996, 'nomas': 1997, 'abrir': 1998, 'tint': 1999, 'firulais': 2000, 'rumb': 2001, 'teatr': 2002, 'felip': 2003, 'marran': 2004, 'from': 2005, 'leg': 2006, 'tumb': 2007, 'academ': 2008, 'dr': 2009, 'traquet': 2010, 'observ': 2011, '122': 2012, 'patet': 2013, 'is': 2014, 'vergonz': 2015, 'tutor': 2016, 'cay': 2017, 'doñ': 2018, '49': 2019, 'coraj': 2020, 'vicky': 2021, 'aisl': 2022, 'hinch': 2023, 'lov': 2024, 'alert': 2025, 'artesanal': 2026, 'hdinglobal': 2027, 'mxo': 2028, 'porong': 2029, 'jef': 2030, 'psicolog': 2031, 'coron': 2032, 'encuentral': 2033, 'norueg': 2034, 'cordob': 2035, 'anarqu': 2036, 'fastidi': 2037, 'em': 2038, 'auron': 2039, 'busqued': 2040, 'weon': 2041, 'jam': 2042, 'cuatr': 2043, 'indescript': 2044, '2018': 2045, 'encierr': 2046, 'sagr': 2047, 'invert': 2048, 'tambi': 2049, 'mereng': 2050, 'brom': 2051, 'particul': 2052, '3er': 2053, 'afuer': 2054, 'reapertur': 2055, 'sorr': 2056, 'revis': 2057, 'rind': 2058, 'factur': 2059, '2da': 2060, 'horizont': 2061, 'metropolitan': 2062, 'nev': 2063, 'olor': 2064, 'oso': 2065, 'andan': 2066, 'rodill': 2067, 'are': 2068, 'audienci': 2069, 'edifici': 2070, 'rode': 2071, 'pretelt': 2072, '27': 2073, 'ordinari': 2074, 'encarg': 2075, 'mmmm': 2076, 'cd': 2077, 'zegn': 2078, 'veni': 2079, 'tio': 2080, 'tenes': 2081, 'resalt': 2082, 'and': 2083, 'encomiend': 2084, '3108123711': 2085, 'confes': 2086, 'enemig': 2087, 'jajajajajaj': 2088, 'notif': 2089, '37': 2090, 'discord': 2091, 'ctv': 2092, 'sindical': 2093, 'desactiv': 2094, 'noooooo': 2095, 'invenc': 2096, 'poblacion': 2097, 'eeuu': 2098, 'style': 2099, 'oid': 2100, 'tenert': 2101, 'volador': 2102, 'impresion': 2103, 'tigr': 2104, 'cc': 2105, 'desocup': 2106, 'mur': 2107, 'trag': 2108, 'tb': 2109, 'empec': 2110, 'cn': 2111, 'caus': 2112, 'ponert': 2113, 'doblet': 2114, 'zoom': 2115, 'uffff': 2116, 'beat': 2117, 'scoot': 2118, 'consejer': 2119, '316': 2120, 'apuñal': 2121, 'enferm': 2122, 'zev': 2123, 'tips': 2124, 'jardin': 2125, 'sonreir': 2126, 'queri': 2127, 'medicin': 2128, 'esquin': 2129, 'sueld': 2130, 'huell': 2131, 'pelot': 2132, 'labi': 2133, 'hous': 2134, 'sam': 2135, 'scorpion': 2136, 'servic': 2137, 'gusan': 2138, 'triunf': 2139, 'sint': 2140, 'engañ': 2141, 'polv': 2142, 'kamasutr': 2143, 'sov': 2144, 'virrey': 2145, 'conviert': 2146, 'pies': 2147, 'afrocolombian': 2148, 'automat': 2149, 'ana': 2150, 'aprob': 2151, 'distint': 2152, 'sabalet': 2153, 'tricolor': 2154, 'diganm': 2155, 'alrededor': 2156, 'aparezc': 2157, 'gast': 2158, 'tay': 2159, 'stere': 2160, 'conectat': 2161, 'xd': 2162, 'neg': 2163, 'sudor': 2164, 'design': 2165, 'movimient': 2166, 'gonzalez': 2167, 'pobrez': 2168, 'ali': 2169, 'cantin': 2170, 'anoth': 2171, 'alegri': 2172, 'j': 2173, 'neces': 2174, 'gratitud': 2175, 'dem': 2176, 'barat': 2177, 'ep': 2178, 'autop': 2179, 'promet': 2180, 'terron': 2181, 'ahhhhhhhh': 2182, 'john': 2183, 'ayudam': 2184, 'imbecil': 2185, 'marionet': 2186, '127': 2187, 'movist': 2188, '167': 2189, '265': 2190, 'poquit': 2191, 'bebes': 2192, 'intern': 2193, 'fueg': 2194, 'manual': 2195, 'auxili': 2196, 'pre': 2197, 'dient': 2198, 'sublim': 2199, 'sucursal': 2200, 'dieron': 2201, 'estres': 2202, 'g': 2203, 'certez': 2204, 'asistent': 2205, 'bloque': 2206, 'boss': 2207, 'femenin': 2208, 'toxic': 2209, 'bod': 2210, 'serv': 2211, 'minim': 2212, 'stick': 2213, 'manit': 2214, 'acordeon': 2215, 'cuc': 2216, 'rostr': 2217, 'gracios': 2218, 'reir': 2219, 'junior': 2220, 'miembr': 2221, 'gam': 2222, 'revel': 2223, 'alcanz': 2224, 'malvin': 2225, '2011': 2226, 'adios': 2227, 'nuny': 2228, 'reputon': 2229, 'terfacher': 2230, 'traser': 2231, 'flu': 2232, 'uberrim': 2233, 'afortun': 2234, 'existent': 2235, 'admit': 2236, 'jorg': 2237, 'disciplin': 2238, 'dist': 2239, 'vag': 2240, 'carcel': 2241, 'skin': 2242, 'distrital': 2243, '43': 2244, 'incident': 2245, 'peticion': 2246, 'asesor': 2247, 'omg': 2248, 'intens': 2249, '99': 2250, '126': 2251, '269': 2252, 'anot': 2253, 'apropi': 2254, 'advirt': 2255, 'bendit': 2256, 'separ': 2257, '45': 2258, 'union': 2259, 'antioqueñ': 2260, 'jej': 2261, 'soled': 2262, 'arranc': 2263, 'terc': 2264, 'falca': 2265, 'justif': 2266, 'arquitectur': 2267, 'pro': 2268, 'mamit': 2269, 'reduc': 2270, 'amarg': 2271, 'idiot': 2272, 'util': 2273, 'ivan': 2274, 'masiv': 2275, 'cienci': 2276, 'entorn': 2277, 'protest': 2278, 'registr': 2279, 'estup': 2280, 'aven': 2281, 'lar': 2282, 'piltraf': 2283, 'acas': 2284, '1er': 2285, 'de': 2286, 'enamorat': 2287, 'carolin': 2288, 'transmision': 2289, 'postr': 2290, 'mad': 2291, 'vegetarian': 2292, 'lisbo': 2293, 'vac': 2294, 'bosqu': 2295, 'divers': 2296, 'web': 2297, 'pech': 2298, 'conductor': 2299, 'convivent': 2300, 'guardi': 2301, 'democrat': 2302, 'pib': 2303, 'chavez': 2304, 'peñ': 2305, 'podes': 2306, 'miel': 2307, 'maquin': 2308, 'chavist': 2309, 'friday': 2310, 'concurs': 2311, 'radical': 2312, 'ajajajajaj': 2313, 'ari': 2314, 'ola': 2315, 'aspect': 2316, 'ataqu': 2317, 'posicion': 2318, 'camp': 2319, 'tortur': 2320, 'lony': 2321, 'echan': 2322, 'crack': 2323, 'dandol': 2324, 'kirchner': 2325, 'evolucion': 2326, 'nietzsch': 2327, 'shalom': 2328, 'imped': 2329, 'energet': 2330, 'aaaaa': 2331, 'aunq': 2332, 'masteriz': 2333, 'incomod': 2334, 'acus': 2335, 'rosal': 2336, 'genial': 2337, 'division': 2338, 'transport': 2339, 'correspond': 2340, 'admir': 2341, 'vieron': 2342, 'sincer': 2343, 'repuest': 2344, 'chap': 2345, 'curramb': 2346, 'insegur': 2347, 'azul': 2348, 'non': 2349, 'avail': 2350, 'hps': 2351, 'fabric': 2352, 'aka': 2353, 'recompens': 2354, 'fum': 2355, 'ilustr': 2356, 'grabacion': 2357, 'sell': 2358, '80': 2359, 'formacion': 2360, 'tendenci': 2361, 'cub': 2362, 'campesin': 2363, '2019': 2364, 'menor': 2365, 'expresident': 2366, 'popul': 2367, 'prader': 2368, 'cra': 2369, 'aguj': 2370, 'dizqu': 2371, 'atuend': 2372, 'gaf': 2373, 'priorid': 2374, 'consultori': 2375, 'chisit': 2376, 'chiquit': 2377, 'miami': 2378, 'deliri': 2379, 'aaaa': 2380, 'ejo': 2381, 'ponet': 2382, 'conform': 2383, 'yund': 2384, 'hummmmm': 2385, 'rodriguez': 2386, 'escenari': 2387, 'patron': 2388, 'holm': 2389, 'farcod': 2390, 'indirect': 2391, 'enorm': 2392, 'limpiez': 2393, 'outfit': 2394, 'noooo': 2395, 'ipes': 2396, 'exclus': 2397, 'bot': 2398, 'absurd': 2399, 'optim': 2400, 'transit': 2401, 'rellen': 2402, 'meiss': 2403, 'diabl': 2404, 'veam': 2405, 'sonri': 2406, 'milit': 2407, 'twit': 2408, 'zzz': 2409, 'pist': 2410, 'noticier': 2411, 'empat': 2412, 'insult': 2413, 'procur': 2414, 'cementeri': 2415, 'antoj': 2416, '3137434178': 2417, 'podran': 2418, 'gri': 2419, 'arrib': 2420, 'propon': 2421, 'judicializ': 2422, 'burr': 2423, 'ofert': 2424, 'colg': 2425, 'lig': 2426, 'mio': 2427, 'enoj': 2428, 'protej': 2429, 'piel': 2430, 'ajen': 2431, 'suprem': 2432, 'envenen': 2433, 'pol': 2434, 'turn': 2435, 'inept': 2436, 'finc': 2437, 'nieg': 2438, 'asesinat': 2439, 'matriarc': 2440, 'repas': 2441, 'reyn': 2442, 'escuchal': 2443, 'huel': 2444, 'peluqueri': 2445, 'memopel': 2446, '68': 2447, 'c13': 2448, 'carreter': 2449, 'pele': 2450, 'lend': 2451, 'barr': 2452, 'gring': 2453, 'pulmon': 2454, 'mision': 2455, 'o': 2456, 'pastor': 2457, 'caraj': 2458, 'desinform': 2459, 'bolsill': 2460, 'happy': 2461, 'pub': 2462, 'anto': 2463, 'convocatori': 2464, 'vel': 2465, 'american': 2466, 'spam': 2467, 'toy': 2468, 'vecin': 2469, '3044497524': 2470, 'sust': 2471, 'hit': 2472, 'latinoamer': 2473, 'tl': 2474, 'toopers': 2475, 'caes': 2476, 'party': 2477, 'catalog': 2478, 'darn': 2479, 'altas': 2480, 'pagin': 2481, 'pasal': 2482, 'almorz': 2483, 'devuelv': 2484, 'pao16': 2485, 'peaj': 2486, 'verdad': 2487, 'garc': 2488, 'robert': 2489, 'rebaj': 2490, 'ballen': 2491, 'asiq': 2492, 'vendedor': 2493, 'aguacat': 2494, 'mazamorr': 2495, 'clandestin': 2496, 'dmh': 2497, 'z6350bt': 2498, 'resolu': 2499, 'oliv': 2500, 'mon': 2501, 'golp': 2502, 'moned': 2503, 'temat': 2504, 'impact': 2505, 'localiz': 2506, 'bahi': 2507, 'amer': 2508, 'palmer': 2509, 'frances': 2510, 'fidel': 2511, 'degener': 2512, 'progres': 2513, 'belisari': 2514, 'expres': 2515, 'oir': 2516, 'autoriz': 2517, '100pre': 2518, 'escalofri': 2519, 'villeg': 2520, 'obtuv': 2521, 'eficaci': 2522, 'inmunoproteccion': 2523, 'comprob': 2524, 'sputnik': 2525, 'expect': 2526, 'tia': 2527, 'bus': 2528, 'pad': 2529, 'sergi': 2530, 'arboled': 2531, 'rutin': 2532, 'fantast': 2533, 'defiend': 2534, 'ciudadani': 2535, 'etiquet': 2536, 'lor': 2537, 'tribunal': 2538, 'iran': 2539, 'cuchillaz': 2540, 'traque': 2541, 'agost': 2542, 'savi': 2543, 'sra': 2544, 'medit': 2545, 'imit': 2546, 'grad': 2547, '200': 2548, 'pian': 2549, 'profund': 2550, 'jejejej': 2551, 'golpe': 2552, 'dol': 2553, 'billeter': 2554, 'gastritis': 2555, 'exigent': 2556, 'coach': 2557, 'grill': 2558, '12m': 2559, '6pm': 2560, 'disfrac': 2561, 'resent': 2562, 'idol': 2563, 'gimnasi': 2564, 'chin': 2565, 'alas': 2566, 'vertig': 2567, 'nov': 2568, 'leas': 2569, 'plomaz': 2570, 'cce': 2571, 'greys': 2572, 'reborn': 2573, 'valios': 2574, 'fed': 2575, 'vamooooo': 2576, 'getsemani': 2577, 'ornitorrinc': 2578, 'ban': 2579, 'narut': 2580, 'block': 2581, 'cooper': 2582, 'fom': 2583, 'louis': 2584, 'bec': 2585, 'saneamient': 2586, 'bue': 2587, 'tenazzzz': 2588, 'ti': 2589, 'erosary': 2590, 'acer': 2591, 'golaz': 2592, 'baldomer': 2593, 'simil': 2594, 'afeccion': 2595, 'intestinal': 2596, 'arriesg': 2597, 'ubic': 2598, 'out': 2599, 'tik': 2600, 'grey': 2601, 'busqu': 2602, 'afili': 2603, 'relat': 2604, 'lector': 2605, 'cer': 2606, '3101455': 2607, '3006549912': 2608, 'stromboli': 2609, 'jauregui': 2610, 'andrew': 2611, 'rescat': 2612, 'ap': 2613, 'alcob': 2614, 'clasif': 2615, 'diligent': 2616, 'bandej': 2617, 'gigant': 2618, 'edgar': 2619, 'bander': 2620, 'niet': 2621, 'taller': 2622, 'omm': 2623, 'desafi': 2624, 'posibil': 2625, 'elizabeth': 2626, 'parais': 2627, 'lavocad': 2628, 'finally': 2629, '10k': 2630, 'vain': 2631, 'tratamient': 2632, 'rionegr': 2633, '2016': 2634, 'amplific': 2635, 'rosc': 2636, 'juventud': 2637, 'manteng': 2638, 'vacilon': 2639, 'gigantesc': 2640, 'entrevist': 2641, 'clarid': 2642, 'element': 2643, 'occidental': 2644, 'ronc': 2645, 'mandandot': 2646, 'milen': 2647, 'arroz': 2648, 'kakegurui': 2649, 'rav': 2650, 'comand': 2651, 'presion': 2652, 'surt': 2653, 'aaa': 2654, 'imparcial': 2655, 'petard': 2656, 'carm': 2657, 'eddi': 2658, 'hal': 2659, 'manifiest': 2660, 'colocat': 2661, 'langost': 2662, 'guerriller': 2663, 'desastr': 2664, 'cancel': 2665, 'inferior': 2666, 'direction': 2667, 'fuerzit': 2668, 'smart': 2669, 'melani': 2670, 'celest': 2671, 'hagal': 2672, 'matern': 2673, 'carcas': 2674, 'frustr': 2675, 'ken': 2676, 'manizal': 2677, 'hnd': 2678, 'adorn': 2679, 'buenis': 2680, 'quinter': 2681, 'will': 2682, 'octob': 2683, 'adem': 2684, 'zoolog': 2685, 'ruby': 2686, 'ig': 2687, 'mamas': 2688, 'po': 2689, 'estructural': 2690, 'tiquet': 2691, 'ello': 2692, 'back': 2693, '83': 2694, 'levantat': 2695, 'alumbr': 2696, 'requier': 2697, 'chanc': 2698, 'lea': 2699, 'vendr': 2700, 'corre': 2701, 'siluet': 2702, 'cruc': 2703, 'cretin': 2704, 'sisi': 2705, 'ds': 2706, 'entran': 2707, 'higien': 2708, 'irrespet': 2709, 'selfis': 2710, 'except': 2711, 'webin': 2712, 'metropolis': 2713, 'femin': 2714, 'tribut': 2715, 'teresit': 2716, 'optic': 2717, 'disposicion': 2718, 'gucci': 2719, 'mij': 2720, 'bla': 2721, 'aust': 2722, 'cha': 2723, 'ermenegild': 2724, 'acost': 2725, 'sign': 2726, 'thank': 2727, 'next': 2728, 'skat': 2729, 'exalt': 2730, 'costeñ': 2731, 'guatil': 2732, 'oposicion': 2733, 'jamundi': 2734, 'dejel': 2735, '300': 2736, 'onzas': 2737, 'concejal': 2738, 'hacel': 2739, 'regional': 2740, 'altis': 2741, 'leon': 2742, 'levantart': 2743, 'sindicat': 2744, 'bipol': 2745, 'ci': 2746, 'week': 2747, 'latam': 2748, 'commons': 2749, 'tiern': 2750, 'infam': 2751, 'corral': 2752, 'asquer': 2753, '47': 2754, 'tembl': 2755, 'inuyash': 2756, 'ausenci': 2757, 'tog': 2758, 'mm': 2759, 'gallin': 2760, 'epm': 2761, 'sord': 2762, 'osori': 2763, 'cajon': 2764, 'denunci': 2765, 'magdalen': 2766, 'records': 2767, 'pedal': 2768, 'comp': 2769, 'invasion': 2770, 'pep': 2771, 'contagi': 2772, 'chat': 2773, 'entram': 2774, 'document': 2775, 'ole': 2776, 'ojit': 2777, 'horrend': 2778, 'simpat': 2779, 'billon': 2780, 'liliam': 2781, 'birthday': 2782, 'il': 2783, 'forn': 2784, 'ele': 2785, 'tabl': 2786, 'encend': 2787, 'telepacif': 2788, 'vali': 2789, 'eman': 2790, 'espald': 2791, 'bachat': 2792, 'mensual': 2793, '130': 2794, '2843114': 2795, 'rod': 2796, 'transmileni': 2797, 'costumbr': 2798, 'avisam': 2799, 'troch': 2800, 'rubius': 2801, 'tt': 2802, 'ancestral': 2803, 'blda': 2804, 'volkov': 2805, 'presidencial': 2806, 'juvenil': 2807, 'esteb': 2808, 'londoñ': 2809, 'maquillaj': 2810, 'rom': 2811, 'depront': 2812, 'ovied': 2813, 'asno': 2814, 'este': 2815, 'resident': 2816, 'subi': 2817, 'tumblr': 2818, 'verdur': 2819, 'fresc': 2820, 'pinochet': 2821, 'vigent': 2822, 'anatom': 2823, 'sanchez': 2824, 'inesper': 2825, 'cuerd': 2826, 'diamond': 2827, 'dab': 2828, 'salm': 2829, 'entrev': 2830, 'william': 2831, 'manuel': 2832, 'olivell': 2833, 'pesam': 2834, 'cami': 2835, 'nav': 2836, 'supon': 2837, 'aaron': 2838, 'cuidal': 2839, 'bogotan': 2840, 'hall': 2841, 'mins': 2842, 'violador': 2843, 'ddhh': 2844, 'fictici': 2845, 'boton': 2846, 'net': 2847, 'terren': 2848, 'apart': 2849, 'unf': 2850, 'desperdici': 2851, 'logic': 2852, 'ad': 2853, 'leal': 2854, 'apostol': 2855, 'arbol': 2856, 'mang': 2857, 'infanci': 2858, 'sel': 2859, 'vio': 2860, 'cercan': 2861, 'respect': 2862, 'trans': 2863, 'despech': 2864, 'cu': 2865, 'fotografiabotell': 2866, 'inclus': 2867, 'recog': 2868, 'pastill': 2869, 'neus': 2870, 'latin': 2871, 'cajit': 2872, 'prog': 2873, 'escritor': 2874, 'depend': 2875, 'tech': 2876, 'nt': 2877, '1600': 2878, 'joe': 2879, 'verdolag': 2880, 'inalcanz': 2881, 'negrit': 2882, 'fortun': 2883, 'vzla': 2884, 'regim': 2885, 'conden': 2886, 'surpris': 2887, 'ayudan': 2888, 'tbt': 2889, 'boch': 2890, 'fortuna1': 2891, 'veredit': 2892, 'remov': 2893, 'llant': 2894, 'relax': 2895, 'bris': 2896, 'coc': 2897, 'posibilit': 2898, 'cel': 2899, 'insta': 2900, 'atlet': 2901, 'derrot': 2902, 'tol': 2903, 'invad': 2904, 'caravan': 2905, 'explot': 2906, 'choclit': 2907, '700': 2908, 'calasanz': 2909, 'moviliz': 2910, 'abund': 2911, 'salvacion': 2912, '3pm': 2913, 'hug': 2914, 'veas': 2915, 'discusion': 2916, 'dejan': 2917, 'pizz': 2918, 'chuch': 2919, '33': 2920, 'judicial': 2921, 'persegu': 2922, 'we': 2923, 'cepill': 2924, 'acto': 2925, 'lal': 2926, 'conscienci': 2927, 'fans': 2928, 'demuestr': 2929, 'ratic': 2930, 'micr': 2931, 'hermosur': 2932, 'martinez': 2933, 'espiritu': 2934, 'adelant': 2935, 'besit': 2936, 'leo': 2937, 'competent': 2938, 'dubl': 2939, 'niñez': 2940, 'melon': 2941, 'circ': 2942, 'dav': 2943, 'cartagener': 2944, 'impec': 2945, 'byod': 2946, 'littl': 2947, 'cubr': 2948, 'sobr': 2949, 'horn': 2950, 'plastic': 2951, 'ida': 2952, 'sintoni': 2953, '106': 2954, 'contrari': 2955, 'var': 2956, 'mimit': 2957, 'iot': 2958, 'ñ': 2959, 'brillant': 2960, 'alimañ': 2961, 'top': 2962, 'contempl': 2963, 'resist': 2964, 'ancestr': 2965, 'bad': 2966, 'bunny': 2967, 'retir': 2968, 'calient': 2969, 'cuidan': 2970, 'drog': 2971, 'vias': 2972, 'masters': 2973, 'enan': 2974, 'verdug': 2975, 'irse': 2976, 'jajsjajsjajs': 2977, 'cartel': 2978, 'eps': 2979, 'fds': 2980, 'samanth': 2981, 'apto': 2982, 'amobl': 2983, '1198': 2984, 'particular': 2985, 'familiar': 2986, 'anual': 2987, 'bolud': 2988, 'coloc': 2989, 'adicional': 2990, 'presupuest': 2991, 'molin': 2992, 'suscribet': 2993, 'maurici': 2994, 'satrap': 2995, 'faj': 2996, 'atorr': 2997, '3143952369': 2998, 'tiktok': 2999, 'aport': 3000, 'incluyent': 3001, 'conocel': 3002, 'plant': 3003, 'direccion': 3004, 'buendi': 3005, 'novel': 3006, 'aere': 3007, 'grandez': 3008, 'confiabl': 3009, 'inclusion': 3010, 'consultor': 3011, 'veal': 3012, '10pm': 3013, 'quiero': 3014, 'arener': 3015, 'contrat': 3016, 'they': 3017, 'simpl': 3018, 'avis': 3019, 'afan': 3020, '97': 3021, 'kr': 3022, 'letrer': 3023, 'labur': 3024, 'cabalg': 3025, 'antioqi': 3026, 'emma': 3027, 'patrici': 3028, 'valentin': 3029, 'teres': 3030, 'mai': 3031, 'pit': 3032, 'trost': 3033, 'leonard': 3034, 'fabi': 3035, 'hector': 3036, 'hurt': 3037, '10am': 3038, 'densid': 3039, 'wifi': 3040, 'hablam': 3041, 'obstacul': 3042, 'agremi': 3043, 'robled': 3044, 'desadapt': 3045, 'sostien': 3046, 'preguntel': 3047, 'pantall': 3048, 'doll': 3049, 'verdian': 3050, 'presagi': 3051, 'tiran': 3052, 'azar': 3053, 'ceboll': 3054, 'federal': 3055, 'tud': 3056, 'cruis': 3057, 'pos': 3058, 'jejej': 3059, 'cruising': 3060, 'desing': 3061, 'ren': 3062, 'becerr': 3063, 'convirt': 3064, 'aficion': 3065, 'piqu': 3066, 'provech': 3067, 'traduc': 3068, 'encerr': 3069, 'pelus': 3070, 'chanch': 3071, '04': 3072, 'canad': 3073, 'sext': 3074, 'fundador': 3075, 'rios': 3076, 'ton': 3077, 'eh': 3078, 'boston': 3079, 'light': 3080, 'sill': 3081, 'deveng': 3082, 'añit': 3083, 'momon': 3084, 'voc': 3085, 'bomb': 3086, 'ce': 3087, 'tost': 3088, 'aceit': 3089, 'especi': 3090, 'riki': 3091, 'carit': 3092, 'serenat': 3093, 'grat': 3094, 'dian': 3095, 'usmini': 3096, 'legal': 3097, 'visibl': 3098, 'escol': 3099, 'cuot': 3100, 'engrandec': 3101, 'guaidiot': 3102, 'cart': 3103, 'equid': 3104, 'cientif': 3105, 'regl': 3106, 'asum': 3107, 'plasm': 3108, 'mez': 3109, 'altamiran': 3110, 'arco': 3111, 'mlb': 3112, 'coleg': 3113, 'podras': 3114, 'descuent': 3115, 'estereotip': 3116, 'gasos': 3117, 'soberan': 3118, 'ocult': 3119, 'revolu': 3120, 'aspir': 3121, 'permanent': 3122, 'wahl': 3123, '120': 3124, 'organizacional': 3125, 'smir': 3126, 'regalit': 3127, 'milagr': 3128, 'platzi': 3129, 'callens': 3130, 'jefesot': 3131, 'ñer': 3132, 'ced': 3133, 'porr': 3134, 'florest': 3135, 'escucham': 3136, 'vicent': 3137, 'cur': 3138, 'lavand': 3139, 'distraig': 3140, 'pr': 3141, 'che': 3142, 'vayans': 3143, 'congel': 3144, 'dignid': 3145, 'arriet': 3146, 'acordeoner': 3147, 'entendi': 3148, 'ati': 3149, 'adi': 3150, 'culiaw': 3151, 'calzon': 3152, 'calori': 3153, 'pop': 3154, 'cortes': 3155, 'arrastr': 3156, 'rodader': 3157, 'lesbian': 3158, 'expert': 3159, 'capaz': 3160, 'referent': 3161, 'amistad': 3162, 'injustici': 3163, 'disminu': 3164, 'benefici': 3165, 'rentabl': 3166, 'wowwwwwww': 3167, '1000': 3168, 'agricol': 3169, 'deleit': 3170, 'reviv': 3171, 'friedrich': 3172, 'rend': 3173, 'cim': 3174, 'dimit': 3175, 'tuli': 3176, 'orang': 3177, 'casit': 3178, 'tes': 3179, 'mensajer': 3180, 'egres': 3181, 'mk': 3182, 'muev': 3183, 'nooooo': 3184, '53': 3185, 'postal': 3186, 'hazm': 3187, 'templ': 3188, 'admin': 3189, 'atc': 3190, 'vulner': 3191, 'ente': 3192, 'gestor': 3193, 'tipic': 3194, 'depresion': 3195, 'perez': 3196, 'cicatriz': 3197, 'jajajajajaajajaj': 3198, 'cae': 3199, 'fil': 3200, 'agroveterinari': 3201, 'nutri': 3202, 'energy': 3203, 'snack': 3204, 'juguet': 3205, 'suplement': 3206, 'gall': 3207, 'nutrit': 3208, 'proteic': 3209, 'juzg': 3210, 'factor': 3211, 'emergent': 3212, 'programat': 3213, 'oest': 3214, 'manch': 3215, 'montan': 3216, 'aut': 3217, 'bronc': 3218, 'monsalv': 3219, 'reunion': 3220, 'sec': 3221, 'problemat': 3222, '3135170471': 3223, '5k': 3224, 'last': 3225, 'cason': 3226, 'coloni': 3227, 'heter': 3228, 'fac': 3229, 'boqueron': 3230, 'chipaqu': 3231, 'black': 3232, 'ampli': 3233, 'domiciliari': 3234, '116': 3235, 'inaugur': 3236, 'intercambi': 3237, 'bals': 3238, 'abri': 3239, 'relaj': 3240, 'religion': 3241, 'villan': 3242, 'pet': 3243, 'fijat': 3244, 'dart': 3245, 'tatu': 3246, 'baz': 3247, 'proteccion': 3248, 'aguacer': 3249, 'altos': 3250, 'todavi': 3251, 'diagnost': 3252, 'pastel': 3253, 'portafoli': 3254, 'glorios': 3255, 'nicolas': 3256, 'comunal': 3257, 'anecdot': 3258, 'nazc': 3259, 'pacient': 3260, 'mortal': 3261, 'genuflex': 3262, 'caen': 3263, 'gavill': 3264, 'alfombr': 3265, 'bars': 3266, 'concentr': 3267, 'traz': 3268, 'gastronom': 3269, 'encuentran': 3270, 'friends': 3271, 'plazolet': 3272, 'avem': 3273, 'vib': 3274, 'nach': 3275, 'piercings': 3276, '4189003': 3277, '1233': 3278, 'oblig': 3279, 'aclar': 3280, 'hermosoooo': 3281, 'frit': 3282, 'chul': 3283, 'borrel': 3284, 'patit': 3285, 'derram': 3286, 'asoci': 3287, 'fragil': 3288, 'abandon': 3289, 'sostenibil': 3290, 'ayudart': 3291, 'lot': 3292, 'ed': 3293, 'sen': 3294, 'carden': 3295, 'llanadit': 3296, 'legaliz': 3297, 'ayudenm': 3298, 'johnnys': 3299, 'emos': 3300, 'temor': 3301, 'promedi': 3302, '86': 3303, 'forj': 3304, '350': 3305, '180': 3306, 'detien': 3307, 'ciri': 3308, 'discut': 3309, 'pont': 3310, 'devolv': 3311, 'autonom': 3312, 'borracher': 3313, 'loyol': 3314, 'mayori': 3315, 'confeccion': 3316, 'mexican': 3317, 'spotify': 3318, 'paquet': 3319, 'septiembr': 3320, 'wassap': 3321, '3226480227': 3322, '1940': 3323, 'añadidur': 3324, 'brav': 3325, 'abord': 3326, 'hny': 3327, 'chonch': 3328, 'norm': 3329, 'inversion': 3330, 'prox': 3331, 'when': 3332, 'reloj': 3333, 'paisaj': 3334, 'sinergi': 3335, 'bu': 3336, 'fantas': 3337, 'capuch': 3338, 'ambiental': 3339, 'diviert': 3340, 'estir': 3341, 'sabin': 3342, 'fa': 3343, 'so': 3344, 'valient': 3345, 'valent': 3346, 'barcelon': 3347, 'imaginens': 3348, 'canast': 3349, 'vitrin': 3350, 'dramat': 3351, 'ansied': 3352, 'productor': 3353, 'perfeccion': 3354, 'bandoler': 3355, 'evangel': 3356, 'aureli': 3357, 'vinil': 3358, 'autoestim': 3359, 'coments': 3360, 'complac': 3361, 'text': 3362, 'dea': 3363, 'cucarach': 3364, 'modal': 3365, 'armas': 3366, 'basquet': 3367, 'kambi': 3368, 'delant': 3369, 'almacen': 3370, 'mader': 3371, 'pase': 3372, 'embals': 3373, '2014': 3374, '71': 3375, 'subsecretari': 3376, 'financi': 3377, 'kg': 3378, 'idiom': 3379, 'relev': 3380, 'estorb': 3381, 'geograf': 3382, 'tramit': 3383, 'afianz': 3384, 'tok': 3385, 'autoexam': 3386, 'alcanc': 3387, 'veterinari': 3388, 'amarill': 3389, 'simp': 3390, 'fb': 3391, 'hack': 3392, '7pm': 3393, 'solist': 3394, 'pepit': 3395, 'quint': 3396, 'premium': 3397, 'tocinet': 3398, 'div': 3399, 'chapiner': 3400, 'cob': 3401, 'qme': 3402, 'barbar': 3403, 'donacion': 3404, 'escriben': 3405, 'this': 3406, 'filtr': 3407, 'patrocin': 3408, 'pesim': 3409, 'territorial': 3410, 'lapiz': 3411, 'cabron': 3412, 'wattp': 3413, 'acos': 3414, 'fanat': 3415, 'influyent': 3416, '1994': 3417, 'metal': 3418, 'emoji': 3419, 'onde': 3420, 'dudos': 3421, 'sainet': 3422, 'escrit': 3423, 'secuestr': 3424, 'goc': 3425, 'fan': 3426, 'caler': 3427, 'eventual': 3428, 'gris': 3429, 'echeverri': 3430, 'corrient': 3431, 'bernard': 3432, 'icri': 3433, 'unicorni': 3434, 'macaren': 3435, 'tuit': 3436, 'chot': 3437, 'aquel': 3438, 'ray': 3439, 'digal': 3440, 'day': 3441, 'huy': 3442, 'soberbi': 3443, 'sueltal': 3444, 'relajat': 3445, 'neuron': 3446, 'intuicion': 3447, 'winsports': 3448, 'camufl': 3449, 'departament': 3450, '63': 3451, '9a': 3452, '041': 3453, 'ayuden': 3454, 'alcaldi': 3455, 'pacienci': 3456, 'andam': 3457, 'venen': 3458, 'prens': 3459, 'd1': 3460, 'csj': 3461, 'acredit': 3462, 'batall': 3463, 'selen': 3464, 'competit': 3465, 'depur': 3466, 'finaliz': 3467, '3ra': 3468, 'choc': 3469, 'mosquer': 3470, 'solidar': 3471, 'xxi': 3472, 'ricoo': 3473, 'porqueri': 3474, 'remix': 3475, 'vis': 3476, 'strong': 3477, 'led': 3478, 'box': 3479, 'gig': 3480, 'derroc': 3481, 'biciclet': 3482, 'stalk': 3483, 'salced': 3484, 'los': 3485, 'irish': 3486, 'olivi': 3487, 'unim': 3488, 'lasall': 3489, 'diaz': 3490, 'cai': 3491, 'ey': 3492, 'tomat': 3493, 'vient': 3494, 'ajust': 3495, 'rancherit': 3496, 'bienest': 3497, 'mediocr': 3498, 'irme': 3499, 'expresion': 3500, 'juicios': 3501, 'calor': 3502, 'circunst': 3503, 'potencial': 3504, 'silv': 3505, 'deud': 3506, 'coherent': 3507, 'desmoviliz': 3508, 'contamin': 3509, 'aeronaut': 3510, 'navid': 3511, 'guap': 3512, 'barc': 3513, 'parasit': 3514, 'inglaterr': 3515, '85': 3516, 'viejit': 3517, 'laberint': 3518, 'monument': 3519, 'arosemen': 3520, '1983': 3521, 'guarimb': 3522, 'itagui': 3523, 'ns': 3524, 'madur': 3525, 'chinchulin': 3526, 'valg': 3527, 'patriot': 3528, 'consider': 3529, 'titular': 3530, 'creal': 3531, 'anochec': 3532, 'garant': 3533, 'despach': 3534, 'smartphon': 3535, 'penelop': 3536, 'crecimient': 3537, '3002863577': 3538, 'sexual': 3539, 'polac': 3540, 'sonroj': 3541, 'coaxial': 3542, 'alpin': 3543, 'suet': 3544, 'uniform': 3545, 'patinaj': 3546, 'cne': 3547, 'credencial': 3548, 'techmerin': 3549, 'sneak': 3550, 'homicidi': 3551, 'taqueri': 3552, '117': 3553, '104': 3554, '08': 3555, 'tdt': 3556, 'olvidat': 3557, 'jsjsj': 3558, 'win': 3559, 'ejecut': 3560, 'editor': 3561, 'crehan': 3562, 'consig': 3563, 'tabu': 3564, 'hazt': 3565, 'rub': 3566, 'minis': 3567, 'exam': 3568, 'santrich': 3569, 'optimiz': 3570, 'cl': 3571, 'tang': 3572, 'gatic': 3573, 'benz': 3574, 'peo': 3575, 'news': 3576, 'cri': 3577, 'arrepent': 3578, 'mond': 3579, 'ame': 3580, 'expuls': 3581, 'anunc': 3582, 'pajar': 3583, 'culpabl': 3584, 'uwu': 3585, 'letr': 3586, 'echar': 3587, 'platic': 3588, 'fratern': 3589, 'hambrient': 3590, 'radiodifusor': 3591, 'mafios': 3592, 'siet': 3593, 'vei': 3594, 'bc': 3595, 'bloqs': 3596, 'abort': 3597, 'manipul': 3598, 'teams': 3599, 'garci': 3600, 'republ': 3601, 'sazon': 3602, 'torn': 3603, 'gaby': 3604, 'wok': 3605, 'voleibol': 3606, 'bbc': 3607, 'lei': 3608, 'gros': 3609, 'chorr': 3610, 'x2': 3611, 'ternur': 3612, 'sepulcr': 3613, 'bocagrand': 3614, 'vih': 3615, 'guys': 3616, 'corpor': 3617, 'destitu': 3618, 'joaquin': 3619, 'advers': 3620, 'cultiv': 3621, '23': 3622, 'adicion': 3623, 'curul': 3624, 'reduzc': 3625, 'mamert': 3626, 'daudet': 3627, 'jhon': 3628, 'bray': 3629, 'brun': 3630, 'alambr': 3631, 'supong': 3632, 'abuelit': 3633, 'meees': 3634, 'extradicion': 3635, 'irte': 3636, 'sd': 3637, 'insomni': 3638, 'frass': 3639, 'opto': 3640, 'pass': 3641, 'pasit': 3642, 'haras': 3643, 'bbu': 3644, 'vicepresident': 3645, 'ufffffffff': 3646, 'different': 3647, 'gemel': 3648, 'cosech': 3649, 'haban': 3650, 'rit': 3651, 'mds': 3652, 'burl': 3653, 'tony': 3654, 'stark': 3655, 'archiv': 3656, 'niquita': 3657, 'jair': 3658, 'convien': 3659, 'espectacular': 3660, 'clasific': 3661, 'deh': 3662, 'anit': 3663, 'pepin': 3664, 'aloj': 3665, 'sonr': 3666, 'burdett': 3667, 'higgins': 3668, '1930': 3669, 'pez': 3670, 'motoriz': 3671, 'bost': 3672, 'naveg': 3673, '1080p': 3674, 'renuev': 3675, 'esplendor': 3676, 'fraganci': 3677, 'cedr': 3678, 'liban': 3679, 'jsjs': 3680, 'crezc': 3681, 'tramp': 3682, 'tachir': 3683, 'redom': 3684, 'barin': 3685, 'cristobal': 3686, 'industri': 3687, 'muel': 3688, 'majestu': 3689, '258': 3690, '8939': 3691, 'retrecher': 3692, 'aver': 3693, 'culit': 3694, 'incult': 3695, 'enseri': 3696, 'trap': 3697, 'doctrin': 3698, 'retardatari': 3699, 'perseguidor': 3700, 'vengat': 3701, 'abus': 3702, 'girls': 3703, 'aplaus': 3704, 'candidat': 3705, 'tenazzz': 3706, 'dement': 3707, 'desautoriz': 3708, 'cabin': 3709, 'cagaz': 3710, 'wap': 3711, 'soon': 3712, 'alter': 3713, 'pritiau': 3714, 'solari': 3715, 'visad': 3716, 'aju': 3717, 'conjug': 3718, 'sender': 3719, 'quincuagesim': 3720, 'sarit': 3721, 'ñap': 3722, 'dn': 3723, 'argir': 3724, 'finit': 3725, 'cascaron': 3726, 'inmortal': 3727, 'sutil': 3728, 'gta': 3729, 'porcion': 3730, 'pasooo': 3731, 'yoooooo': 3732, '217': 3733, '31octubr': 3734, 'king': 3735, 'amandot': 3736, 'dediques': 3737, 'cancerolog': 3738, 'habr': 3739, 'corazoncit': 3740, 'caden': 3741, 'beltran': 3742, 'misioner': 3743, 'demoni': 3744, 'kdkdkdkkdkd': 3745, 'pervers': 3746, 'existencial': 3747, 'liebr': 3748, 'empoder': 3749, 'caz': 3750, 'aguil': 3751, 'opresor': 3752, 'exij': 3753, '820': 3754, 'primis': 3755, 'society': 3756, 'pidanl': 3757, 'ntra': 3758, 'mul': 3759, 'eusebi': 3760, 'calong': 3761, 'reves': 3762, 'chicag': 3763, 'bull': 3764, 'reinic': 3765, 'windows': 3766, '60': 3767, 'desagrad': 3768, 'dirty': 3769, 'talking': 3770, 'einstein': 3771, 'superal': 3772, 'turbac': 3773, 'hagansel': 3774, 'lucc': 3775, 'bowlopolisc': 3776, 'vern': 3777, 'intact': 3778, 'lajadorooo': 3779, 'reproch': 3780, 'arreglensel': 3781, 'alab': 3782, 'tequil': 3783, 'sap': 3784, 'intenab': 3785, 'coutinh': 3786, 'exhibicion': 3787, 'ritmic': 3788, 'popular': 3789, 'agreg': 3790, 'db': 3791, 'driv': 3792, 'a7': 3793, 'colegial': 3794, 'troik': 3795, 'rus': 3796, 'veneci': 3797, 'viendom': 3798, 'escarch': 3799, 'aerial': 3800, 'hoop': 3801, 'sirwct': 3802, 'jakdjsjjs': 3803, '3012179612': 3804, 'sien': 3805, 'sobrevivi': 3806, 'jajsjsj': 3807, 'extrañart': 3808, 'cruzart': 3809, 'catastr': 3810, 'multiproposit': 3811, 'conveni': 3812, 'catastral': 3813, 'hermosisim': 3814, 'oierd': 3815, 'ooooo': 3816, 'user': 3817, 'cadaverit': 3818, 'possit': 3819, 'corrig': 3820, 'gua': 3821, 'slos': 3822, 'pariu': 3823, 'sabryn': 3824, 'chistesit': 3825, 'ñoñ': 3826, '81': 3827, 'atan': 3828, 'financier': 3829, 'olmi': 3830, 'tuite': 3831, 'estrat': 3832, 'meng': 3833, 'descomplic': 3834, 'gadget': 3835, 'religi': 3836, 'click': 3837, 'pray': 3838, 'brazalet': 3839, 'interfaz': 3840, 'crucifij': 3841, 'rastre': 3842, 'sincroniz': 3843, 'jajaajajajaj': 3844, 'ortogonal': 3845, 'mamasit': 3846, 'escoj': 3847, 'esooo': 3848, 'fier': 3849, 'llevas': 3850, 'tak': 3851, 'mutualmovil': 3852, 'madree': 3853, 'domingoski': 3854, 'upsssss': 3855, 'comprension': 3856, 'dens': 3857, 'vueltic': 3858, 'giovanni': 3859, 'britanicolandi': 3860, 'almuerz': 3861, 'fiordi': 3862, 'salomon': 3863, 'estrib': 3864, 'sakjs': 3865, 'past': 3866, 'minyard': 3867, 'insoport': 3868, 'pims21': 3869, 'copropiedad': 3870, 'clph': 3871, 'propied': 3872, 'horizontal': 3873, 'villanuev': 3874, 'canin': 3875, 'pelud': 3876, '420': 3877, 'encuest': 3878, 'pic': 3879, 'natill': 3880, 'manj': 3881, 'jer': 3882, 'barberi': 3883, 'capeng': 3884, 'guaro': 3885, 'jeepet': 3886, 'patrocini': 3887, 'sangucheri': 3888, 'calorcit': 3889, 'berni': 3890, 'down': 3891, 'lagun': 3892, 'quiloto': 3893, 'zumbahu': 3894, 'panc': 3895, 'never': 3896, 'replante': 3897, 'aban': 3898, 'kostk': 3899, 'diagonal': 3900, 'ingredient': 3901, 'disfori': 3902, 'deposit': 3903, 'facu': 3904, 'trep': 3905, 'skateboard': 3906, 'adoroo': 3907, 'fisiolog': 3908, 'qat': 3909, 'amart': 3910, 'antioqiu': 3911, 'amir': 3912, 'baraj': 3913, 'kenwood': 3914, 'atesor': 3915, 'individual': 3916, 'felizzzz': 3917, 'crac': 3918, 'mandal': 3919, 'homofob': 3920, 'repost': 3921, 'exquisit': 3922, 'strudel': 3923, 'deshac': 3924, 'extraordinari': 3925, 'probatori': 3926, 'concepcion': 3927, 'racional': 3928, 'tacañ': 3929, 'cardiobox': 3930, 'duplex': 3931, 'aduccion': 3932, 'preparens': 3933, 'pior': 3934, 'tenebr': 3935, 'llevader': 3936, 'asqueor': 3937, 'eput': 3938, 'feik': 3939, 'aweon': 3940, 'revocatori': 3941, 'masterchef': 3942, 'choch': 3943, 'kajdjaj': 3944, 'niz': 3945, 'qier': 3946, 'pinturit': 3947, '76': 3948, 'positiv': 3949, 'valu': 3950, 'coelh': 3951, 'acompañi': 3952, 'habiert': 3953, '24h': 3954, '3014780658': 3955, '3113984010': 3956, '3052339796': 3957, 'gooooool': 3958, '310': 3959, '363': 3960, '8997': 3961, 'quiwor': 3962, 'ki': 3963, 'mastic': 3964, 'siguir': 3965, 'eavemari': 3966, 'lass': 3967, '1955': 3968, 'animacion': 3969, 'asheiji': 3970, 'billi': 3971, 'eilish': 3972, 'select': 3973, 'abajondi': 3974, 'sis': 3975, 'einpr': 3976, 'cntest': 3977, 'hre': 3978, 'cafam': 3979, 'melg': 3980, 'mutil': 3981, 'dany': 3982, 'run': 3983, 'oriflam': 3984, 'contactam': 3985, '3217133171': 3986, 'tedi': 3987, 'admitil': 3988, 'fifth': 3989, 'harmony': 3990, 'alcohol': 3991, 'hna': 3992, 'piraquiv': 3993, 'ministerial': 3994, 'idmji': 3995, 'alejat': 3996, 'cepillens': 3997, 'mugrientls': 3998, 'remat': 3999, 'lloradit': 4000, 'noral': 4001, 'cabecill': 4002, 'protagoniz': 4003, 'chichis': 4004, 'sirvient': 4005, 'borrador': 4006, 'pronunc': 4007, 'puts': 4008, 'bag': 4009, 'redond': 4010, 'gancini': 4011, 'labr': 4012, 'compact': 4013, 'funcional': 4014, 'vocal': 4015, 'stereotyp': 4016, 'nicaragu': 4017, 'aceptari': 4018, 'zverev': 4019, 'theam': 4020, 'schwartm': 4021, 'televident': 4022, 'espn': 4023, 'talk': 4024, 'about': 4025, 'parameters': 4026, 'tomorrow': 4027, '17th': 4028, 'empeñ': 4029, 'discrecion': 4030, 'otakuuuuu': 4031, 'solcit': 4032, 'shfkwjfkjs': 4033, 'meditaaaa': 4034, 'odegaard': 4035, 'jovic': 4036, 'bucl': 4037, 'siganl': 4038, 'sa': 4039, 'ito': 4040, '2010': 4041, 'lofiu': 4042, 'verdos': 4043, 'marquesin': 4044, '1945': 4045, 'cult': 4046, '61': 4047, 'erig': 4048, 'byron': 4049, 'saldarriag': 4050, 'pereir': 4051, 'mort': 4052, 'pnl': 4053, 'welcom': 4054, 'allur': 4055, 'sucialust': 4056, 'arg': 4057, 'parejit': 4058, 'esperal': 4059, 'bby': 4060, 'unet': 4061, 'torne': 4062, 'bill': 4063, 'jim': 4064, 'factory': 4065, 'chingart': 4066, 'confies': 4067, 'loaiz': 4068, '125': 4069, 'vladim': 4070, 'acciontv': 4071, 'noved': 4072, 'visibil': 4073, 'throwback': 4074, 'patrimoni': 4075, 'reim': 4076, 'solit': 4077, 'ames': 4078, 'coincident': 4079, 'salchichon': 4080, 'moron': 4081, 'asist': 4082, 'tribun': 4083, 'lejan': 4084, 'retrat': 4085, 'permitet': 4086, 'agradecer': 4087, 'etimolog': 4088, 'crusing': 4089, 'fullmorb': 4090, 'amabl': 4091, 'chever': 4092, 'curry': 4093, 'querr': 4094, '78': 4095, 'wearing': 4096, 'crown': 4097, 'rej': 4098, 'hamp': 4099, 'prostitu': 4100, 'fach': 4101, 'chaquet': 4102, 'hibern': 4103, 'descurb': 4104, 'crwri': 4105, 'per': 4106, 'evrvdad': 4107, 'puef': 4108, 'reit': 4109, 'camell': 4110, 'gir': 4111, 'codisc': 4112, 'picon': 4113, 'arbitraj': 4114, 'grissy': 4115, 'solicitor': 4116, 'artes': 4117, 'porter': 4118, 'fibr': 4119, 'garsi': 4120, 'suramerican': 4121, 'colinit': 4122, 'engo': 4123, 'viñ': 4124, 'percimon': 4125, 'acari': 4126, 'yugul': 4127, 'cutt': 4128, 'pircing': 4129, 'mutu': 4130, 'elogi': 4131, 'dogm': 4132, 'mesi': 4133, 'bomboner': 4134, 'niqui': 4135, 'consistent': 4136, 'persistent': 4137, 'automotiv': 4138, 'ois': 4139, 'sabot': 4140, 'helois': 4141, 'atrevet': 4142, 'estonsal': 4143, 'rebuev': 4144, 'vantat': 4145, 'destroy': 4146, 'polar': 4147, 'fern': 4148, 'grut': 4149, 'remord': 4150, 'max': 4151, 'g4': 4152, 'universitari': 4153, 'ucv': 4154, 'seccion': 4155, 'masacr': 4156, 'bugalagrand': 4157, 'militar': 4158, 'apag': 4159, 'ceb': 4160, 'previst': 4161, 'vf': 4162, 'buritic': 4163, '240': 4164, 'increment': 4165, 'yel': 4166, 'disturb': 4167, 'ate': 4168, 'quand': 4169, 'lusofon': 4170, 'imbanac': 4171, 'atra': 4172, 'movich': 4173, 'hotels': 4174, 'siganm': 4175, 'sinton': 4176, 'protagon': 4177, 'analit': 4178, 'ia': 4179, 'memor': 4180, 'licens': 4181, 'kdkdkkdkdkd': 4182, 'precisei': 4183, 'semestr': 4184, 'emtelc': 4185, 'vencedor': 4186, 'pescam': 4187, 'suplic': 4188, 'icorsid': 4189, 'kkdkddkdkdk': 4190, 'gueb': 4191, 'crush': 4192, 'nervios': 4193, 'salirrrr': 4194, 'dept': 4195, 'dolient': 4196, 'residual': 4197, 'camarograf': 4198, 'cupul': 4199, 'nikon': 4200, 'd5300': 4201, 'galaxy': 4202, 'a51': 4203, 'clam': 4204, 'vivenci': 4205, 'asus': 4206, 'groseri': 4207, 'ct': 4208, 'autuori': 4209, 'dediqu': 4210, 'arteri': 4211, 'fluvial': 4212, 'malecon': 4213, '38': 4214, 'uraban': 4215, 'quinceañer': 4216, 'abrumador': 4217, 'gustab': 4218, 'alquil': 4219, 'boler': 4220, 'flaquit': 4221, 'garraf': 4222, '114': 4223, 'carull': 4224, 'mesur': 4225, 'siestit': 4226, 'postrimeri': 4227, '1990': 4228, 'berlin': 4229, 'intermed': 4230, 'lachaut': 4231, 'jajj': 4232, 'chistos': 4233, 'astronom': 4234, 'distr': 4235, 'exguerriller': 4236, 'arrend': 4237, 'official': 4238, 'jev': 4239, 'jahsjsjsj': 4240, 'autoamenaz': 4241, 'vibor': 4242, 'starts': 4243, 'highway': 4244, 'gourmet': 4245, 'estandar': 4246, 'orejit': 4247, 'iti': 4248, 'mamain': 4249, 'maqui': 4250, 'portic': 4251, 'cansador': 4252, 'cba': 4253, 'disp': 4254, 'perimetral': 4255, 'cajitaabo': 4256, '7836342': 4257, 'yuri': 4258, 'buenaventur': 4259, 'terribl': 4260, 'usam': 4261, 'insum': 4262, 'cobsent': 4263, 'waldy': 4264, 'posesion': 4265, 'fijens': 4266, 'tiraron': 4267, 'guadalup': 4268, 'presentam': 4269, 'tikit': 4270, '55': 4271, 'gastroenterolog': 4272, 'rex': 4273, 'cinic': 4274, 'careverg': 4275, 'delanter': 4276, 'jsjsjsj': 4277, 'colise': 4278, 'xux': 4279, 'suroest': 4280, 'antioquen': 4281, 'arnes': 4282, 'divinaaaaa': 4283, 'aggg': 4284, 'xfavor': 4285, 'temaz': 4286, 'c5m': 4287, 'atardecer': 4288, 'trabajanding': 4289, 'shadow': 4290, 'sun': 4291, 'famosisim': 4292, 'chach': 4293, 'chop': 4294, 'colombi': 4295, 'pancak': 4296, 'merlin': 4297, 'narni': 4298, 'jajsjjsjs': 4299, 'deprim': 4300, 'serotonin': 4301, 'inmediat': 4302, 'temp': 4303, 'insect': 4304, 'lisonj': 4305, 'fde': 4306, 'gorr': 4307, 'lims': 4308, 'tropican': 4309, 'pretenci': 4310, 'japones': 4311, 'sundoku': 4312, 'enfermed': 4313, 'sintom': 4314, 'caos': 4315, 'cabuyal': 4316, 'montoy': 4317, 'rockford': 4318, 'fosgat': 4319, 'p2d12': 4320, 'monolog': 4321, 'abrupt': 4322, 'nid': 4323, 'cazzu': 4324, 'aguapanelit': 4325, 'flacuchent': 4326, 'galliner': 4327, 'corregidur': 4328, 'expid': 4329, 'suspension': 4330, 'agust': 4331, 'teoric': 4332, 'rebeld': 4333, 'concert': 4334, 'pso': 4335, 'ingustici': 4336, 'taping': 4337, 'rvr1995': 4338, 'irem': 4339, 'mci': 4340, 'topp': 4341, 'gorri': 4342, 'interrupcion': 4343, 'aragon': 4344, 'mzo': 4345, 'horasss': 4346, 'octogonal': 4347, 'lut': 4348, 'incorpor': 4349, 'som': 4350, 'bling': 4351, 'fumig': 4352, 'bodri': 4353, 'mitic': 4354, 'london': 4355, 'calling': 4356, 'giv': 4357, 'enough': 4358, 'markhyuck': 4359, 'wayuu': 4360, 'contestam': 4361, 'xxiii': 4362, 'garago': 4363, 'boyac': 4364, 'teitor': 4365, 'gel': 4366, 'antibacterial': 4367, 'bazurt': 4368, 'retransmision': 4369, 'cej': 4370, 'norbert': 4371, 'sedddddd': 4372, 'favs': 4373, 'beso': 4374, 'mujeron': 4375, 'tmh': 4376, 'esencial': 4377, 'merley': 4378, 'tirenl': 4379, 'marlen': 4380, 'dietrich': 4381, 'informat': 4382, 'torombol': 4383, 'lacay': 4384, 'hamponil': 4385, 'interinat': 4386, 'laz': 4387, 'cucut': 4388, 'moyan': 4389, 'mom': 4390, 'alcantarill': 4391, 'camit': 4392, 'arigat': 4393, 'deck': 4394, 'pergol': 4395, '70a': 4396, 'aeww': 4397, 'escogent': 4398, 'ovejit': 4399, 'fascin': 4400, 'potabl': 4401, 'grav': 4402, 'apeg': 4403, 'noel': 4404, 'luj': 4405, 'jud': 4406, 'sustent': 4407, 'tesis': 4408, 'revision': 4409, 'doki': 4410, 'entras': 4411, 'estilach': 4412, 'satelit': 4413, 'filaa': 4414, 'deteccion': 4415, 'raic': 4416, 'iguan': 4417, 'suav': 4418, 'perl': 4419, '2vleyend': 4420, 'abdom': 4421, 'cader': 4422, 'sres': 4423, 'polideport': 4424, 'valdr': 4425, 'neon': 4426, '3127804658': 4427, 'muchisimooo': 4428, 'asteroid': 4429, 'portatil': 4430, 'televisor': 4431, 'uber': 4432, 'eats': 4433, 'chatbot': 4434, 'wuer': 4435, 'distraccion': 4436, 'chill': 4437, 'antig': 4438, 'comiemdl': 4439, 'tempest': 4440, 'enbals': 4441, 'lit': 4442, 'glandul': 4443, 'mamari': 4444, 'catedr': 4445, 'licenciatur': 4446, 'mary': 4447, 'grues': 4448, 'poet': 4449, 'narrador': 4450, 'peli': 4451, 'im': 4452, 'sobbing': 4453, 'carambol': 4454, 'terf': 4455, 'tranki': 4456, 'miram': 4457, 'juac': 4458, 'pachec': 4459, 'got': 4460, 'designat': 4461, 'chauu': 4462, 'pavlov': 4463, 'firmin': 4464, 'pipoc': 4465, 'meat': 4466, 'consul': 4467, '58': 4468, 'jajsjsjs': 4469, 'minion': 4470, 'con': 4471, 'gruñon': 4472, 'experimental': 4473, 'mae': 4474, 'greg': 4475, 'cia': 4476, 'emocional': 4477, 'proceder': 4478, 'cien': 4479, 'estercoler': 4480, 'travesur': 4481, 'comel': 4482, 'riquisim': 4483, 'beatl': 4484, 'amat': 4485, 'indumil': 4486, 'extermin': 4487, 'metastas': 4488, 'mud': 4489, 'meloju': 4490, 'arcil': 4491, 'us': 4492, 'inversor': 4493, 'graciasss': 4494, 'frijolit': 4495, 'incapac': 4496, 'dier': 4497, 'infeliz': 4498, 'tolki': 4499, 'ares': 4500, 'jajsjdbabs': 4501, 'bk': 4502, 'agujer': 4503, 'inicial': 4504, 'franklin': 4505, 'brit': 4506, 'piscin': 4507, 'qo': 4508, 'esas': 4509, 'preguntit': 4510, 'hern': 4511, 'sigm': 4512, 'fc': 4513, 'imagen': 4514, 'correspondient': 4515, 'bolit': 4516, 'aislamient': 4517, 'mic': 4518, 'pand': 4519, 'forev': 4520, '4ta': 4521, 'riñon': 4522, 'festivooo': 4523, 'empiec': 4524, 'precauci': 4525, 'espej': 4526, 'taman': 4527, 'imprim': 4528, 'patinet': 4529, 'incentiv': 4530, 'desnutr': 4531, 'pasiv': 4532, 'detuv': 4533, 'mcafe': 4534, 'creador': 4535, 'antivirus': 4536, 'estafarazon': 4537, 'titi': 4538, 'fiat': 4539, 'fantoch': 4540, 'misional': 4541, '4pm': 4542, '52': 4543, 'hijit': 4544, 'floricient': 4545, 'abrim': 4546, 'apadrin': 4547, 'llaman': 4548, 'envian': 4549, 'firenz': 4550, 'intermin': 4551, 'leccion': 4552, 'mourinh': 4553, 'antioqu': 4554, 'obisp': 4555, 'testimoni': 4556, 'decidet': 4557, 'doli': 4558, 'descansa': 4559, 'jimin': 4560, 'curat': 4561, 'respald': 4562, '193': 4563, 'acta': 4564, 'fundacional': 4565, 'naooooo': 4566, 'socorr': 4567, 'hav': 4568, 'fun': 4569, 'grisal': 4570, 'owo': 4571, 'parrill': 4572, 'tenf': 4573, 'trngo': 4574, 'eomp': 4575, 'sartenaz': 4576, 'cepilm': 4577, 'cornament': 4578, 'cancill': 4579, 'today': 4580, 'raviolis': 4581, 'conscient': 4582, 'alimentari': 4583, 'clausur': 4584, 'caramel': 4585, 'bnos': 4586, 'pwrodn': 4587, 'cousin': 4588, 'ii': 4589, 'benedict': 4590, 'xvi': 4591, 'tecit': 4592, 'mao': 4593, 'stickers': 4594, 'seminari': 4595, 'princip': 4596, 'greci': 4597, 'electronic': 4598, 'honey': 4599, 'rolex': 4600, 'pups': 4601, 'xal': 4602, 'fabul': 4603, 'rn': 4604, 'diplom': 4605, 'fernandit': 4606, 'propus': 4607, 'fotic': 4608, 'tambal': 4609, 'incertidumbr': 4610, 'exterior': 4611, 'ajajkasjajakasjkjasjk': 4612, 'x4': 4613, 'intrascendent': 4614, 'playstation': 4615, 'boe': 4616, 'emili': 4617, 'escob': 4618, 'gaviri': 4619, 'clip': 4620, 'capuccin': 4621, 'cerd': 4622, 'desidi': 4623, 'onu': 4624, 'oea': 4625, 'cambial': 4626, 'hrs': 4627, 'andab': 4628, 'guayab': 4629, 'mooan': 4630, 'xx': 4631, 'capri': 4632, 'caraball': 4633, 'ejecu': 4634, 'traigal': 4635, 'humans': 4636, 'descontamin': 4637, 'ecolog': 4638, 'manifest': 4639, 'cobard': 4640, 'hampon': 4641, 'temer': 4642, 'consiguient': 4643, 'colonial': 4644, 'ubicacion': 4645, 'froz': 4646, 'deep': 4647, 'dish': 4648, 'calent': 4649, 'disfrutas': 4650, 'ollas': 4651, 'envuelt': 4652, 'ff': 4653, 'aa': 4654, 'cuy': 4655, '0fm': 4656, '2x3': 4657, 'rubi': 4658, 'qu': 4659, 'relaxx': 4660, 'sag': 4661, 'epic': 4662, '1960': 4663, 'amañ': 4664, 'lds': 4665, 'vicevers': 4666, 'muuch': 4667, 'suerte': 4668, 'festej': 4669, 'intel': 4670, 'miiii': 4671, 'amorrrr': 4672, 'unir': 4673, 'ibag': 4674, 'vd': 4675, 'ibe': 4676, 'challeng': 4677, '290': 4678, 'hugooooooooo': 4679, 'porraaaaaaaaaa': 4680, 'biferi': 4681, '109': 4682, 'indig': 4683, 'ztudi': 4684, 'tranquilidad': 4685, 'aiot': 4686, 'explos': 4687, 'artificial': 4688, 'ecosistem': 4689, 'jeje': 4690, 'registrat': 4691, 'funcrec': 4692, 'wendi': 4693, 'terciopel': 4694, 'poliest': 4695, 'zap': 4696, 'hediond': 4697, 'jajaajajajajaajaj': 4698, 'mereci': 4699, 'raivaaa': 4700, 'reeleccion': 4701, 'olvides': 4702, 'renov': 4703, 'ese': 4704, 'inyect': 4705, 'ime': 4706, 'conduct': 4707, 'guardian': 4708, 'guardabosqu': 4709, 'documental': 4710, 'oriental': 4711, 'peaton': 4712, 'royal': 4713, 'casin': 4714, 'thai': 4715, 'dram': 4716, 'tailandes': 4717, 'fool': 4718, 'quir': 4719, 'triplet': 4720, 'lir': 4721, 'centimetr': 4722, 'musc': 4723, 'manborecord': 4724, 'involucr': 4725, 'chafarot': 4726, 'ez': 4727, 'dilem': 4728, 'puntual': 4729, 'sanch': 4730, 'shakespear': 4731, 'gimen': 4732, 'dusand': 4733, 'bucay': 4734, 'producion': 4735, 'mortifiqu': 4736, 'amoo': 4737, '365': 4738, 'membres': 4739, 'jajsjajsj': 4740, 'ios': 4741, 'vaganci': 4742, '028': 4743, 'particpacion': 4744, 'entons': 4745, 'frisolit': 4746, 'rumber': 4747, 'presum': 4748, 'pt': 4749, 'minet': 4750, 'plebiscit': 4751, 'inexistent': 4752, 'fastrack': 4753, 'maton': 4754, 'lectur': 4755, 'liceth': 4756, 'referendum': 4757, 'enjuici': 4758, 'expresidentesjudicializ': 4759, 'lavader': 4760, 'lord': 4761, 'year': 4762, 'all': 4763, 'blessings': 4764, 'pcx': 4765, 'asunt': 4766, 'siniestr': 4767, 'quibrel': 4768, 'nooooooo': 4769, 'escud': 4770, 'omce': 4771, 'lev': 4772, 'inmobiliari': 4773, 'automotric': 4774, 'vdd': 4775, 'lu': 4776, 'darm': 4777, 'stalkeart': 4778, 'pesso': 4779, 'frost': 4780, 'sulliv': 4781, 'odiari': 4782, 'sucrett': 4783, 'rosaa': 4784, 'durmient': 4785, 'echais': 4786, 'culia': 4787, 'hahahahh': 4788, 'kuzm': 4789, 'vamon': 4790, 'antiviral': 4791, 'sgtes': 4792, 'extasis': 4793, 'bindasaffon': 4794, 'who': 4795, 'be': 4796, 'rendimient': 4797, 'fam': 4798, 'malos': 4799, 'maños': 4800, 'pifi': 4801, 'himn': 4802, 'calicant': 4803, 'pirotecni': 4804, 'avec': 4805, 'kakashi': 4806, 'chiom': 4807, 'lon': 4808, 'anuari': 4809, 'dilat': 4810, 'fellini': 4811, 'sorrentin': 4812, 'elirtem': 4813, 'cualessss': 4814, 'kra': 4815, 'n72': 4816, '208': 4817, '3603600': 4818, 'dafn': 4819, 'danix': 4820, 'agustin': 4821, 'roci': 4822, 'daian': 4823, 'ambar': 4824, 'natach': 4825, 'tizian': 4826, 'kimey': 4827, 'veron': 4828, 'aylen': 4829, 'iar': 4830, 'emils': 4831, 'virgi': 4832, 'estefani': 4833, 'descansaa': 4834, 'retirat': 4835, 'detras': 4836, 'dicicion': 4837, 'qn': 4838, 'nobi': 4839, 'estoi': 4840, 'dicembr': 4841, '1998': 4842, 'cantant': 4843, 'realm': 4844, '7i': 4845, 'camion': 4846, 'adoptam': 4847, 'fuklif': 4848, 'fecod': 4849, 'titiriter': 4850, 'promuev': 4851, 'destruccion': 4852, 'inmens': 4853, 'ilimit': 4854, 'fuckboy': 4855, 'misit': 4856, 'presio': 4857, 'todopoder': 4858, 'prevalec': 4859, 'mangueare': 4860, 'soci': 4861, 'bastoner': 4862, 'distincion': 4863, 'dcto': 4864, 'yf': 4865, 'stan': 4866, 'llorsmd': 4867, 'intervin': 4868, 'favorec': 4869, 'samp': 4870, 'manriqu': 4871, 'arrepi': 4872, 'ufff': 4873, 'ohh': 4874, 'twitter': 4875, 'adrenalin': 4876, 'desnud': 4877, 'chevy': 4878, 'spark': 4879, 'gt': 4880, 'merque': 4881, 'ajetr': 4882, 'infinix': 4883, 'lexic': 4884, 'rebusc': 4885, 'incomprend': 4886, 'incondicional': 4887, 'ganador': 4888, 'ibm': 4889, 'premis': 4890, 'vacunan': 4891, 'descuid': 4892, 'climat': 4893, 'gorgoj': 4894, 'avellan': 4895, 'galan': 4896, 'holand': 4897, 'olivar': 4898, 'autocuid': 4899, 'pij': 4900, 'coding': 4901, 'tunal': 4902, 'montevide': 4903, 'telesur': 4904, 'racism': 4905, '100th': 4906, 'trb': 4907, 'registration': 4908, 'annual': 4909, 'meeting': 4910, 'archienemig': 4911, 'calabaz': 4912, 'asochefs': 4913, 'ocamp': 4914, 'restant': 4915, 'baloc': 4916, 'beyrut': 4917, 'citrin': 4918, 'llaner': 4919, 'empan': 4920, 'fantasi': 4921, 'mendig': 4922, 'santi': 4923, 'tierrit': 4924, 'chelse': 4925, 'moving': 4926, 'terrot': 4927, 'terminal': 4928, 'picapiedr': 4929, 'personit': 4930, 'inedit': 4931, 'volvi': 4932, 'tranquis': 4933, 'finqiis': 4934, 'tmbn': 4935, 'cortenl': 4936, 'pak': 4937, 'ariel': 4938, 'divinooooo': 4939, 'scrr': 4940, 'slc': 4941, 'fotrogaf': 4942, 'moteli': 4943, 'arta': 4944, 'suscrib': 4945, 'dou': 4946, 'cachit': 4947, 'farol': 4948, 'lunit': 4949, '88': 4950, 'alfred': 4951, 'gutierrez': 4952, 'jummm': 4953, 'emborrach': 4954, 'puntit': 4955, 'apunt': 4956, 'embarg': 4957, 'tont': 4958, 'resurreccion': 4959, 'fucion': 4960, 'discern': 4961, 'modric': 4962, 'ensambl': 4963, 'arab': 4964, 'armar': 4965, 'anticip': 4966, 'nojombreeeee': 4967, 'estari': 4968, 'piol': 4969, 'lenguetaz': 4970, 'casabrav': 4971, 'semipeofesional': 4972, 'gom': 4973, 'hangout': 4974, 'brech': 4975, 'desped': 4976, 'cl96': 4977, 'proced': 4978, 'miraflor': 4979, 'desalojar': 4980, 'samurays': 4981, 'piercing': 4982, 'sie': 4983, 'superacualqui': 4984, 'sentimi': 4985, 'nocturn': 4986, 'oh': 4987, 'resumen': 4988, 'hallazg': 4989, 'simposi': 4990, 'transparent': 4991, 'chupapij': 4992, 'paramilitar': 4993, 'pulcr': 4994, 'chac': 4995, 'predi': 4996, 'esoo': 4997, 'grital': 4998, 'selv': 4999}\n"
     ]
    }
   ],
   "source": [
    "print(str(word_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'sagemaker-pytorch-2020-11-15-00-34-08-601'"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make tests with the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'0.9496775269508362'"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediccion=\"Y recuerda qué hay que sonreirle a la vida\".encode('utf-8')\n",
    "predictor.predict(prediccion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'9.243911335943267e-05'"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediccion=\"Me encanta el futbol y la política jajaja\".encode('utf-8')\n",
    "predictor.predict(prediccion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'5.642675387207419e-05'"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediccion=\"Te amo mucho mi mami hermosa\".encode('utf-8')\n",
    "predictor.predict(prediccion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'0.7962983846664429'"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediccion=\"Y entonces me pregunto ¿Es conveniente tanta indiferencia?\".encode('utf-8')\n",
    "predictor.predict(prediccion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-pytorch-2020-11-15-00-34-08-328'"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The model to be deployed in some moment\n",
    "model.name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
